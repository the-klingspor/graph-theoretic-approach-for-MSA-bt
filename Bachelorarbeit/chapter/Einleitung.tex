\chapter{Einleitung und Motivation}
\label{ch:einleitung}

Das berechnen von multiplen \emph{Sequenzalignments} ist eine fundamentale Technik, die eine Vielzahl von Anwendungsgebieten in der Biologie, aber auch in anderen Disziplinen wie dem \emph{Natural Language Processing} hat. Wir werden im Laufe dieses Kapitels zunächst etwas darüber kennenlernen was \emph{Alignments} eigentlich sind  und wo ihre Hauptanwendungsgebiete liegen. Dann führen wir mit dem Algorithmus von Needleman-Wunsch einen Standardansatz für paarweise \emph{Alignments} ein. Am Beispiel dieses Algorithmus beschäftigen wir uns mit der Komplexität des \emph{multiple sequence Alignment}-Problems und stellen fest, dass es für Zuweisungen zwischen mehr als nur einigen wenigen Sequenzen nicht zielführend ist diese mathematisch exakt zu berechnen. Um diesem Problem Herr zu werden, lernen wir im Laufe der Bachelorarbeit zwei ausgefeilte Heuristiken für multiple \emph{Sequenzalignments} ein. Zunächst lernen wir DIALIGN kennen, einen Algorithmus, der anders als Needleman-Wunsch nicht auf der Basis von einzelnen Symbolen \emph{Alignments} konstruiert \citep{mdw96}. Stattdessen werden ganze Segmente als Bausteine der Zuweisungen benutzt. Der zweite Algorithmus ist der graphtheoretische Ansatz von \cite{cpm10}. Dieser basiert zwar auch auf DIALIGN, hat aber den Anspruch für Situationen bei denen die Heuristik von DIALIGN falsche Entscheidungen trifft, bessere Ergebnisse zu liefern. Exemplarisch wird danach ein wichtiger Schritt des Verfahrens programmatisch umgesetzt. Dabei wird mit der Programmiersprache C++ und der \enquote{Boost Graph Library} gearbeitet.

\section{Einführung und Anwendungsgebiete}

Ziel von \emph{Sequenzalignments} ist es für eine Menge von Zeichenketten aus einem endlichen Alphabet Zuordnungen zwischen den einzelnen Symbolen zu finden, sodass möglichst ähnliche einzelne Symbole oder ganze Abschnitte einander zugeordnet sind. Man versucht auf diese Weise funktionelle, strukturelle oder evolutionäre Ähnlichkeiten zu finden. Ein Beispiel für relevante strukturelle Ähnlichkeiten sind Proteinsequenzen. Wenn Proteine aus ähnlichen Aminosäuren in vergleichbaren Reihenfolgen aufgebaut sind, dann kann man davon ausgehen, dass diese auch eine ähnliche 3D-Struktur und ähnliche Funktionen haben, selbst wenn sie in unterschiedlichen Organismen vorkommen. Im Laufe der Evolution verändern sich aufgrund von Mutationen die DNA und die Proteine von Arten. Diese Vorgänge sind die Ursache für den beispiellosen Reichtum an Lebewesen auf der Welt und mit Hilfe von \emph{Sequenzalignments} kann man nachvollziehen wie diese Entwicklung vonstatten gegangen ist. Zu den häufigsten Mutationsarten bei Genmutationen (im Gegensatz zu Genommutationen und Chromosomenmuationen) gehören Punktmutationen, bei denen eine einzelne DNA-Base durch eine andere ersetzt wird, sowie Deletionen und Insertionen, bei denen ganze Abschnitte einer Sequenz gelöscht oder eingefügt wurden. Glücklicherweise haben unsere \emph{Alignments} Möglichkeiten genau diese Situationen abzubilden. Informell könnte man sagen, dass man bei einer Zuweisung die Elemente der Eingabestrings einander so zuordnet, dass jedem Symbol genau ein Symbol jeder anderen Sequenz oder eine neu eingefügte Lücke, Gap genannt, zugeordnet ist. Dabei darf die Reihenfolge der Elemente nicht verändert werden.

Betrachten wir dazu zwei kleine Beispiele von Wörtern, die häufig falsch geschrieben werden:

\ttfamily
\begin{center}
\begin{tabular}{ccc}
		OR-GINAL & \hspace{2cm} & SYLVESTER \\
		ORIGINAL & \hspace{2cm} & SILVESTER
\end{tabular}
\end{center}
\normalfont

Im ersten Fall wurde bei der falschen Schreibweise ein benötigter Buchstabe weggelassen. Damit es trotzdem zu einer passenden Zuordnung der anderen Buchstaben kommt, wurde in die erste Sequenz eine Lücke (-) eingefügt. Im evolutionären Kontext wäre dies ein Beispiel für eine Deletion. Im zweiten Beispiel wurde ein Buchstabe durch einen anderen, fehlerhaften ersetzt. Das ist ein klassisches Beispiel für eine Punktmutation oder einen Einzelnukleotid-Polymorphismus.

Die Berechnung eines \emph{Sequenzalignments} ist in vielen Fällen der erste Schritt einer \emph{Sequenzanalyse} in der Molekularbiologie \cite{cpm10}. Diese Analysen dienen unter anderem dazu zu bestimmen, ob Sequenzen miteinander verwandt sind (\emph{Homologie}), zum Bestimmen von Markergenen oder um direkt von der Sequenz auf die molekulare Struktur zu schließen. 

Ein zweites großes Einsatzgebiet des \emph{multiple sequence Alignment}-Problems ist das \emph{Natural Language Processing}, also der maschinellen Verarbeitung menschlicher Sprache \citep{s10}. Sätze, Wörter oder Ausdrücke können aligniert werden, um mechanisch Sätze zu übersetzen oder Texte zusammenzufassen. Noch einen Schritt weiter geht das alignieren von \emph{Phonemen}, wo es beispielsweise darum geht von der textuellen Darstellung auf die Aussprache zu schließen oder andersrum Sprache textuell darzustellen. Obwohl viele dieser Anwendungen nur auf zwei Sequenzen arbeiten, wie beispielsweise einen Text und seiner Übersetzung, gibt es auch Fälle bei denen multiple \emph{Alignments} nötig sind. Dazu gehören unter anderem Vergleiche von Texten, die in anderen Worten den selben Inhalt wiedergeben, oder von gleichbedeutenden Worten aus unterschiedlichen Sprachen der selben Sprachfamilie. Bei der Sprachentwicklung gibt es interessante Parallelen zu den evolutionären Vorgängen in Genomen. Im Kontext dieser Bachelorarbeit werden wir uns jedoch im Folgenden auf Anwendungen in der molekularen Bioinformatik beschränken.  

\section{Der Algorithmus von Needleman-Wunsch}

Einer der ersten Algorithmen zur Berechnung von paarweisen \emph{Alignments} war der von \cite{nw70}. Dieser weist Zuweisungen auf Symbolebene zwischen zwei Sequenzen Werte zu und das Ziel ist es mit Hilfe von dynamischer Programmierung die Summe dieser Werte zu maximieren. Wir werden in den nächsten Abschnitten zunächst das Paradigma der dynamischen Programmierung kennenlernen, bevor wir es beim Algorithmus von Needleman-Wunsch benutzen. Unter Verwendung des Algorithmus lässt sich danach die Komplexität des \emph{multiple sequence Alignment}-Problems verdeutlichen, die uns den Anlass gibt in den nächsten Kapiteln zwei leistungsstarke Heuristiken zu betrachten.

\subsection{Dynamische Programmierung}

Die dynamische Programmierung ist ein Prinzip zum algorithmischen Lösen eines Optimierungsproblems. Dazu wird ein größeres Problem unter Zuhilfenahme der Lösungen von sich überschneidenden Teilproblemen gelöst, wobei die zuvor berechneten Lösungen in einer Tabelle gespeichert werden. Durch die Wiederverwendung der bereits gelösten Teilprobleme lässt sich auf diese Weise die oft exponentielle Laufzeit eines naiven Algorithmus auf polynomielle Laufzeit verringern. Dabei muss man beachten, ob es für den jeweiligen Kontext angemessen ist den höheren Speicherbedarf aufgrund der zu speichernden Werte für die verbesserte Laufzeit in Kauf zu nehmen. Oft wird die dynamische Programmierung mit dem \emph{divide and conquer}-Prinzip verwechselt. Beide Paradigmen darauf basieren ein Problem in kleinere Teilprobleme zu zerlegen. Der Hauptunterschied zwischen ihnen ist, dass das Problem bei \emph{divide and conquer} in disjunkte Teilprobleme zerlegt wird, statt in sich überlappende \citep{clrs09}. Denken wir beispielsweise an Mergesort zurück: hier sortiere ich ein Feld, indem ich immer größer werdende disjunkte Teilfelder miteinander verschmelze.

In der Regel stellt man bei der dynamischen Programmierung zunächst eine Rekursionsgleichung auf mit deren Hilfe sich das Problem beschreiben lässt. Im Gegensatz zur \emph{Memoisation} wird diese Rekursionsgleichung jedoch nicht direkt und \emph{top-down} umgesetzt. Stattdessen werden \emph{bottom-up} zunächst die Basisfälle berechnet und darauf aufbauend immer größere Teilprobleme gelöst. Die Berechnung erfolgt dabei aber nichtsdestoweniger der Rekursionsformel entsprechend. Aufgrund der direkten Umsetzung der Rekursionsgleichung sind die Korrektheitsbeweise der Algorithmen der dynamischen Programmierung oft sehr einfach und aus der Korrektheit der Formel folgt meistens automatisch die des ganzen Algorithmus.

Dynamische Programmierung wurde in den 1940er-Jahren von Richard Bellman in Stanford und später bei der Denkfabrik RAND Corporation entwickelt. Nach ihm ist auch das \emph{Bellmannsche Optimalitätsprinzip} benannt, das besagt, dass man bei vielen Optimierungsproblemen die optimalen Lösungen von Teilproblemen benutzen kann, um die optimale Lösung des eigentlichen Problems zu berechnen. Warum Bellman den Begriff \enquote{dynamische Programmierung} gewählt hat, ist unklar. In seiner Autobiographie \enquote{Eye of the Hurricane} erklärt er \citep{b84}:

\begin{quotation}
	An interesting question is, Where did the name, dynamic programming, come from? The 1950s were not good years for mathematical research. We had a very interesting gentleman in Washington named Wilson. He was Secretary of Defense, and he actually had a pathological fear and hatred of the word research. I’m not using the term lightly; I’m using it precisely. His face would suffuse, he would turn red, and he would get violent if people used the term research in his presence. You can imagine how he felt, then, about the term mathematical. The RAND Corporation was employed by the Air Force, and the Air Force had Wilson as its boss, essentially. Hence, I felt I had to do something to shield Wilson and the Air Force from the fact that I was really doing mathematics inside the RAND Corporation. What title, what name, could I choose? In the first place I was interested in planning, in decision making, in thinking. But planning, is not a good word for various reasons. I decided therefore to use the word “programming”. I wanted to get across the idea that this was dynamic, this was multistage, this was time-varying. I thought, let's kill two birds with one stone. Let's take a word that has an absolutely precise meaning, namely dynamic, in the classical physical sense. It also has a very interesting property as an adjective, and that is it's impossible to use the word dynamic in a pejorative sense. Try thinking of some combination that will possibly give it a pejorative meaning. It's impossible. Thus, I thought dynamic programming was a good name. It was something not even a Congressman could object to. So I used it as an umbrella for my activities.
\end{quotation}

Ob diese Geschichte wirklich war ist, ist fraglich, denn die erste Arbeit Bellmans, die den Begriff benutzt, wurde bereits 1952 veröffentlicht, obwohl der oben genannte Charles Wilson erst ein Jahr später Verteidigungsminister wurde. Anderen Aussagen zufolge wurde der Begriff analog zur linearen Programmierung von George Dantzig gewählt, dem Erfinder des Simplex-Verfahrens \citep{rn09}. Dieser war ungefähr zur selben Zeit bei RAND beschäftigt. Das Adjektiv \enquote{dynamisch} bezieht sich dabei auf die künstliche Einfügung von Zeit in ein statisches Problem \citep{b57}. Genauer gesagt ist damit gemeint, dass die Reihenfolge der Durchführung von Berechnungen von Bedeutung ist: zunächst müssen die optimalen Lösungen der sich überlappenden Teilprobleme berechnet werden, bevor ich diese zur optimalen Lösung des eigentlichen Problems zusammensetzen kann.

\subsection{Der Algorithmus}

Der Algorithmus von Needleman-Wunsch ist ein \emph{Alignierer} auf der Basis von einzelnen Symbolen \citep{nw70}. Da dieses Kapitel einen eher motivierenden Charakter hat, werden wir den Algorithmus auf einer etwas informaleren Ebene betrachten. Zunächst lernen wir dafür eine etwas einfachere Definition eines \emph{Alignments} kennenlernen, die wir im nächsten Kapitel durch eine komplexere, aber äquivalente ergänzen, die sich insbesondere auch für multiple eignet, die aus mehr als zwei Sequenzen bestehen.

\begin{definition}[Alignment (Needleman-Wunsch)]
	Seien $S_1[1,\dots, n]$ und $S_2[1,\dots,m]$ zwei Zeichenketten über einem endlichen Alphabet. Eine Relation $\mathcal{R}$ zwischen Symbolen dieser beiden Sequenzen ist genau dann ein \emph{Alignment}, wenn für alle Paare von Zweiertupeln $S_1[i],S_2[j]$ und $S_1[i'],S_2[j']$ aus $\mathcal{R}$ gilt, dass aus $i < i'$ auch $j < j'$ folgt. Mit anderen Worten: es gibt keine überkreuzten Zuweisungen.
\end{definition}

Unser Ziel ist es jetzt aus allen möglichen \emph{Alignments} von $S_1$ und $S_2$ das beste zu finden. Dazu brauchen wir eine Möglichkeit die Güte von \emph{Alignments} zu vergleichen. Wenn zwei Symbole $s = S_1[i]$ und $s' = S_2[j]$ einander zugewiesen werden, dann weisen wir diesen ein Gewicht $\alpha_{s,t}$ zu, abhängig von der Ähnlichkeit der beiden Symbole. Oft wird hier nur zwischen Übereinstimmungen und Abweichungen unterschieden, aber in manchen Kontexten wie beispielsweise Proteinsequenzen mag es auch andere Möglichkeiten geben. Genauer widmen wir uns diesem Thema in Abschnitt \ref{subsec:subs_matr}. Wird hingegen eine Lücke in eine der beiden Sequenzen eingefügt, dann ziehen wir dann Kosten in der Höhe $\delta$ ab (sog. \emph{Gap Penalty}).

\begin{definition}[Score (Needleman-Wunsch)]
	Gegeben seien zwei Sequenzen $S_1$ und $S_2$ und ein \emph{Alignment} $\mathcal{R}$, sowie die \emph{Ähnlichkeitswerte} $\alpha$ und  der \emph{Gap Penalty} $\delta$. Dann definieren wir:
	
	\begin{equation}
		score(\mathcal{R},S_1,S_2) \coloneqq \sum_{(s,t)\in \mathcal{R}}{\alpha_{s,t}} - \sum_{s : \nexists t : (s,t)\in \mathcal{R}}{\delta} - \sum_{t : \nexists s : (s,t)\in \mathcal{R}}{\delta}
	\end{equation}
\end{definition}

Der \emph{Score} ist für ein \emph{Alignment} beim Algorithmus von Needleman-Wunsch also als die Summe aller \emph{Ähnlichkeitswerte} von einander zugewiesenen Symbolen der beiden Sequenzen definiert, von denen die \emph{Gap Penalties} aller eingefügten Lücken abgezogen werden. Das Ziel wird es jetzt sein eine Rekursionsgleichung aufzustellen mit deren Hilfe man diesen \emph{Score} maximieren kann. Der maximale \emph{Score} eines \emph{Alignments} gibt uns ein Maß für die Ähnlichkeit zweier Sequenzen an: je höher er ist, desto mehr gleiche oder ähnliche Symbole wurden einander zugewiesen und desto weniger Lücken mussten wir in die Sequenzen einfügen.

\begin{beispiel}
	Betrachten wir als kleines Beispiel zwei \emph{Alignments} des Worts \enquote{Original} in richtiger und fehlerhafter Schreibweise. Hierbei gilt $\alpha_{i,j} = 1$ für $i \neq j$ und $\alpha_{i,i} = 0$, sowie $\delta = 2$.
	
	\footnotesize
	\begin{center}
	\begin{tikzcd}
	O \arrow[d, no head] & R \arrow[d, no head] & G \arrow[d, no head] & I \arrow[d, no head] & N \arrow[d, no head] & A \arrow[d, no head] & L \arrow[d, no head] & - \\
	O & R & I & G & I & N & A & L
	\end{tikzcd}
	\end{center}
	\normalsize
	
	Wie man sieht haben wir zwei Übereinstimmungen (O und R), fünf Abweichungen und eine eingefügte Lücke in die erste Sequenz. Der \emph{Score} dieses \emph{Alignments} beträgt also $2\cdot 1 - 2 = 0$. Nun zum zweiten:
	
	\footnotesize
	\begin{center}
		\begin{tikzcd}
		O \arrow[d, no head] & R \arrow[d, no head] & - & G \arrow[d, no head] & I \arrow[d, no head] & N \arrow[d, no head] & A \arrow[d, no head] & L \arrow[d, no head] \\
		O & R & I & G & I & N & A & L
		\end{tikzcd}
	\end{center}
	\normalsize
	
	Hier haben wir sieben Übereinstimmungen, keine Abweichung und wiederum eine Lücke. Der sich ergebende \emph{Score} ist somit $5$, was ein deutlich besseres Maß für die Ähnlichkeit beider Sequenzen darstellt.
\end{beispiel}

Die Art der Beschreibung und die Zwischenschritte  sind im Folgenden an \cite{kt05} angelehnt, die den Algorithmus von Needleman-Wunsch modern aufbereitet haben. Anders als \cite{nw70} berechnen sie jedoch nicht das maximale Gewicht eines \emph{Alignment}, sondern stattdessen die maximalen Kosten, wobei die Zuweisung zwischen gleichen Symbolen geringe Kosten hat und \emph{Gap Penalties} addiert statt subtrahiert werden. Das entspricht der Minimierung der sogenannten \emph{Editierdistanz} von Levenshtein, einem äquivalenten Problem. Das Ergebnis ist letztendlich das gleiche, aber ich orientiere mich hierbei an der originalen Veröffentlichung, weil es später bei DIALIGN auch darum gehen wird den (dort leicht anders definierten) \emph{Score} zu maximieren.

Zunächst starten wir mit der einfachen Feststellung, dass die letzten Elemente von $S_1$ und $S_2$, $S_1[n]$ und $S_2[m]$, entweder miteinander aligniert sind oder das nicht der Fall ist. Diese Aussage gilt aber auch für alle Teilsequenzen, die nicht über die ganze gehen und das bietet uns einen Ansatz für die dynamische Programmierung. 

\begin{lemma}
	Sei $\mathcal{R}$ ein \emph{Alignment} von $S_1$ und $S_2$. Falls $(n,m) \notin \mathcal{R}$ gilt, dann ist $S_1[n]$ oder $S_2[m]$ kein Element der jeweils anderen Sequenz zugeordnet. 
\end{lemma}

\begin{beweis}
	Angenommen es gilt $(n,m) \notin \mathcal{R}$ und es existieren Indizes $i < n$ und $j < m$ für die gilt $(i,m) \in \mathcal{R}$ und $(n,j) \in \mathcal{R}$. Dann überkreuzen sich diese beiden Zuweisungen und das ist ein Widerspruch zu unserer Definition eines  \emph{Alignments}.
\end{beweis}

Dieses Lemma können wir jetzt zu einem ersten Ansatz für die Rekursionsformel zur Berechnung des maximalen \emph{Scores} umformulieren, denn bei einem optimalen \emph{Alignment} tritt genau eine der folgenden drei Situationen ein:

\begin{enumerate}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item $(n,m) \in \mathcal{R}$
	\item $\nexists\: j \in \{1 \leq j < m\}$ mit $(n,j) \in \mathcal{R}$ - $S_1[n]$ ist nicht zugewiesen
	\item $\nexists\: i \in \{1 \leq i < n\}$ mit $(i,m) \in \mathcal{R}$ - $S_2[m]$ ist nicht zugewiesen
\end{enumerate}

Sei $OPT(i,j)$ der maximale \emph{Score} der Teilsequenzen $S_1[1,\dots,i]$ und $S_2[1,\dots,j]$. $OPT$ können wir in Anlehnung an die drei Fälle oben rekursiv berechnen. Entweder alignieren wir die Elemente an den Stellen $i$ und $j$ miteinander oder $S_1[i]$ wird nicht zugeordnet oder $S_2[j]$ wird nicht zugeordnet. Im zweiten und dritten Fall muss dann in der jeweils einen anderen Sequenz eine Lücke eingefügt werden.

\begin{enumerate}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item $OPT(i,j) = OPT(i-1,j-1) + \alpha_{S_1[i],S_2[j]}$
	\item $OPT(i,j) = OPT(i-1,j) - \delta$
	\item $OPT(i,j) = OPT(i,j-1) - \delta$
\end{enumerate}

$OPT$ lässt sich dann maximieren, indem man über die drei möglichen Fälle das Maximum berechnet. Damit ergibt sich auch die Rekursionsgleichung, die wir dann zur Berechnung des optimalen \emph{Scores} der ganzen Sequenzen mit dynamischer Programmierung benutzen können. Für den Fall, dass eine Teilsequenz die Länge 0 hat, müssen wir so viele Lücken einfügen, wie die andere Teilsequenz lang ist. $(i,j) \in \mathcal{R}$ gilt genau dann, wenn bei $OPT(i,j)$ der erste Fall gewählt wurde.

\begin{korollar}
	Es gelte $1 \leq i \leq n$ und $1 \leq j \leq m$. Dann folgt für den maximalen \emph{Score} $OPT(i,j)$ der Teilsequenzen bis zu den Indizes $i$ und $j$:
	\begin{equation}
	\begin{split}
		OPT(i,j) & = \max\{OPT(i-1,j-1) + \alpha_{S_1[i],S_2[j]}, OPT(i-1,j) - \delta, OPT(i,j-1) - \delta\} \\
		OPT(i,0) & = i\cdot \delta \\
		OPT(0,j) & = j\cdot \delta 
	\end{split}
	\end{equation}
\end{korollar}

Diese Rekursionsformel können wir direkt in einem Algorithmus münden lassen. Wie man sieht ist dieser anders als die Rekursionsgleichung nicht \emph{top-down}, sondern \emph{bottom-up} formuliert. Alle möglichen Einträge in der Matrix $O[1,\dots,n][1,\dots,m]$ werden unter Verwendung der zuvor berechneten Teilprobleme berechnet und gespeichert. 

\begin{algorithm}
	\caption{Algorithmus für die Berechnung des maximalen \emph{Scores} zweier Sequenzen $S_1$ und $S_2$ unter Verwendung von Ähnlichkeitswerten $\alpha$ und \emph{Gap Penalty} $\delta$}
	\label{alg:opt_nw}
	\begin{algorithmic}[1]
		\Procedure{OptSequenceAlignment}{$S_1, S_2, \alpha, \delta$}
		\State {$n \gets |S_1|$}
		\State {$m \gets |S_2|$}
		\State Lege Array $O[0,\dots,n][0,\dots,m]$ an.
		\For {$i = 0 \textbf{ to } n$} \Comment {Fülle $S_2$ mit Lücken}
			\State {$O[i][0] \gets i\cdot \delta$}
		\EndFor
		\For {$j = 0 \textbf{ to } m$} \Comment {Fülle $S_1$ mit Lücken}
			\State {$O[0][j] \gets j\cdot \delta$}
		\EndFor
		\For {$i = 0 \textbf{ to } n$}
			\For {$j = 0 \textbf{ to } m$}
				\State {$O[i][j] \gets \max\{O[i-1,j-1] + \alpha_{S_1[i],S_2[j]}, O[i-1,j] - \delta, O[i,j-1] - \delta\}$}
			\EndFor
		\EndFor
		\State {\textbf{return} $O[n][m]$}
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

Bis jetzt haben wir lediglich den Wert einer optimalen Lösung bestimmt, aber noch nicht diese optimale Lösung selbst. Das geschieht durch einen einfachen Backtrackingprozess bei dem wir mit $O[n][m]$ starten. Für $O[i][j]$ müssen wir dann nur die Einträge $O[i-1][j-1]$, $O[i-1][j]$ und $O[i,j-1]$ betrachten, um festzustellen, ob $(i,j) \in \mathcal{R}$ oder in welche der beiden Sequenzen in diesem Schritt eine Lücke eingefügt wurde. Ist $O[i][j] - \alpha_{S_1[i-1],S_2[j-1]} = O[i-1][j-1]$, dann kann ich $(i-1,j-1)$ zum \emph{Alignment} hinzufügen. Stimmt hingegen $O[i][j] - \delta = O[i-1,j]$, dann wurde an dieser Stelle eine Lücke in $S_1$ eingefügt. Der Fall einer Lücke in $S_2$ funktioniert analog. Wie man sieht ist es auch möglich, dass zwei oder alle drei dieser Fälle eintreten. In diesem Fall gibt es mehr als ein mögliches perfektes paarweises \emph{Alignment}. \improvement{Noch ein kleines Beispiel mit einer Tabelle?}

\begin{lemma}
	Für zwei Sequenzen $S_1$ und $S_2$ kann der \emph{Score} eines optimalen \emph{Alignments} $\mathcal{R}$ in $\oh(n\cdot m)$ Zeit und $\oh(n\cdot)$ Speicherplatz berechnet werden.
\end{lemma}

\begin{beweis}
	Die Korrektheit des Algorithmus \ref{alg:opt_nw} folgt aus der Korrektheit der Rekursionsgleichung. Die Laufzeit ergibt sich aus den zwei ineinander geschachtelten for-Schleifen. Diese laufen über je $n$ beziehungsweise $m$ Indizes, ohne dass diese innerhalb der Schleifenläufe verändert werden. Jeder Schleifendurchlauf hat konstante Kosten, da nur das Maximum von $\oh(1)$ Zahlen bestimmt werden muss, die zuvor in konstanter Zeit berechnet wurden.
\end{beweis}

\begin{korollar}
	Für zwei Sequenzen $S_1$ und $S_2$ kann ein optimales \emph{Alignments} $\mathcal{R}$ in $\oh(n\cdot m)$ Zeit und $\oh(n\cdot)$ Speicherplatz berechnet werden.
\end{korollar}

\begin{beweis}
	Wie zuvor gezeigt kann in der selben Zeit- und Speicherkomplexität der \emph{Score} eines optimalen \emph{Alignments} berechnet werden. Mit einem einfachen Backtrackingprozess kann man jetzt feststellen, welche Zuweisungen Teil eines dazugehörigen \emph{Alignments} sind. Dafür betrachte ich wie oben beschrieben für den Tabelleneintrag $O[i][j]$ die Einträge  $O[i-1][j-1]$, $O[i-1][j]$ und $O[i,j-1]$. Man stellt fest, dass in jedem Schritt mindestens einer der beiden Indizes gesenkt wird. Das bedeutet, dass nach höchstens $\oh(n+m)$ Schritten alle Zuweisungen oder Lücken bestimmt wurden. Jeder einzelne Schritt ist in konstanter Zeit möglich, weil jeweils lediglich drei Tabelleneinträge betrachtet werden müssen. 
\end{beweis}

Dan Hirschberg hat einen Algorithmus entwickelt, der den Algorithmus von Needleman-Wunsch mit Hilfe eines \emph{divide and conquer}-Ansatzes in $\oh(n+m)$ Speicherplatz umsetzt \citep{h75}. Diese Verbesserung kann bei langen Sequenzen einen großen Unterschied in der Laufzeit machen, weil es zu weniger Seitenfehlern kommt. Auf diesen Algorithmus möchte ich hier nicht weiter eingehen, aber wir werden im kommenden Kapitel einen ähnlichen Algorithmus zum speicherplatzeffizienten berechnen von segmentbasierten paarweisen \emph{Alignments} kennenlernen.

\section{Komplexität}

Als nächstes widmen wir uns der Komplexität des \emph{multiple sequence Alignment}-Problems. Diese werden wir nicht formal beweisen, aber anhand des gerade kennengelernten Algorithmus von Needleman-Wunsch anschaulich motivieren.

Man kann die Modellierung nach Needleman-Wunsch auch als Graphen interpretieren, bei dem der Algorithmus einen längsten Pfad durch diesen Graphen findet. Der Graph ist dabei ein tabellenartiger planarer Graph, bei dem alle Knoten mit den dreien nach rechts und unten verbunden sind, falls es diese gibt. Auf den diagonalen Kanten stehen dabei die Gewichte für das alignieren zweier Symbole der Sequenzen und auf den waage- und senkrechten $-\delta$ für das Einfügen einer Lücke.

\footnotesize
\begin{center}
\begin{tikzcd}[/tikz/commutative diagrams/sep=large]
	O[0,0] \arrow[r] \arrow[d] \arrow[rd] & ... \arrow[d] \arrow[rd] & ... \arrow[d] \arrow[r] & O[0,m] \arrow[d] \\
	... \arrow[r] \arrow[rd] & O[i-1,j-1] \arrow{rd}[near start, sloped]{\alpha_{S_1[i-1],S_2[j-1]}} \arrow{d}{\delta} \arrow{r}{\delta} & O[i-1,j] \arrow[r] \arrow[rd] \arrow{d}{\delta} & ... \\
	... \arrow[d] \arrow[r] \arrow[rd] & O[i,j-1] \arrow[d] \arrow[rd] \arrow{r}{\delta} & O[i,j] \arrow[d] \arrow[rd] \arrow[r] & ... \arrow[d] \\
	O[n,0] \arrow[r] & ... & ... \arrow[r] & O[n,m]
\end{tikzcd}
\end{center}
\normalsize

Grundsätzlich lässt sich damit das Vorgehen des Algorithmus von Needleman-Wunsch zum alignieren von einer Menge $S = \{S_1,\dots,S_n\}$ von Sequenzen erweitern. Dazu benötigt man dann aber eine $n$-dimensionale Matrix mit $l_1\cdot \dots \cdot l_n$ Einträgen, wobei $l_i$ die Länge der Sequenz $S_i$ ist, beziehungsweise einen Graphen mit derselben Anzahl an Knoten. Setzt man $l_{max} \coloneqq \max\{l_1,\dots,l_n\}$, dann muss man $\oh(l_{max}^n)$ Einträge der Matrix berechnen. Durch die höhere Anzahl an Sequenzen steigen auch die Kosten für die Berechnung eines einzelnen Eintrags. Betrachten wir beispielsweise die Berechnung eines Eintrages der Tabelle für drei Sequenzen. In diesem Schritt habe ich die Möglichkeit in keine der Sequenzen eine Lücke einzufügen und alle drei Symbole miteinander zu alignieren (1 Möglichkeit), in eine der Sequenzen eine Lücke einzufügen (3 Möglichkeiten) oder in zwei der Sequenzen eine Lücke einzufügen (3 Möglichkeiten). In alle Sequenzen eine Lücke einzufügen ergibt in diesem Kontext keinen Sinn, aber man erkennt trotzdem, dass die Anzahl an Möglichkeiten in jedem Schritt in der Größe der Potenzmenge von $S$, also $\oh(2^n)$ liegt. Somit folgt eine Laufzeit von $\oh(2^n\cdot l_{max}^n)$ für die Berechnung eines optimalen multiplen \emph{Alignments} mit dem Algorithmus von Needleman-Wunsch. \cite{wj94} haben formal bewiesen, dass es nicht möglich ist unter angemessenen Einschränkungen ein multiples \emph{Alignment} in deterministisch polynomieller Zeit zu berechnen. Das \emph{multipe sequence Alignment}-Problem ist somit \emph{NP-schwer} mit der Komplexität $\oh(n^l)$.

Aufgrund dieser Erkenntnis ist es im Allgemeinen nicht möglich mathematisch exakte multiple \emph{Alignments} zu berechnen. Wenn man bedenkt, dass es für manche \emph{Sequenzanalysen} nötig ist hunderte Sequenzen, die oft mehr als tausend Zeichen lang sind, miteinander zu vergleichen, ist es mit der oben genannten Laufzeit illusorisch Needleman-Wunsch zu benutzen,. Stattdessen sind wir dazu gezwungen Heuristiken zu entwickeln, die in angemessener Zeit eine möglichst gute Annäherung an das perfekte Ergebnis liefern. Mit DIALIGN von \cite{mdw96} und der graphtheoretischen Erweiterung von \cite{cpm10} werden wir dafür zwei leistungsstarke Heuristiken kennenlernen und analysieren.










