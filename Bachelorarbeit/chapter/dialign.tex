\chapter{Das DIALIGN-Verfahren}
\label{ch:DIALIGN}
In diesem Kapitel lernen wir zunächst das DIALIGN-Verfahren für multiple Sequenzalignments nach Morgenstern et al. kennen\cite{mdw96}. Der verwendete Algorithmus wurde im Laufe der Zeit auf verschiedene Weisen angepasst und verbessert. In dieser Arbeit wird die Version 2.2 vorgestellt, die die neueste direkte Weiterentwicklung der ursprünglichen Veröffentlichung ist. Mit DIALIGN-TX gibt es zwar auch noch einen moderneren Nachfolger, aber bei diesem handelt es sich aufgrund von größeren Änderungen, um einen anderen Algorithmus \cite{skm08}.
 
Anders als der im letzten Kapitel vorgestellte Algorithmus von Needleman-Wunsch aligniert DIALIGN keine einzelnen Symbole, sondern gleich ganze Segmente der Eingabesequenzen. Das hat zum einen den Vorteil, dass man auf die Kosten zum Einfügen von Lücken verzichten kann und dadurch weitgehend von benutzerdefinierten Eingaben unabhängig wird. Zum anderen ist man so in der Lage, sowohl global als auch lokal verwandte Sequenzen einander auszurichten: Liegen in einem Bereich der Sequenzen keine Segmente vor, die einander ähnlich sind, dann verzichtet man darauf, diese sich gegenseitig zuzuweisen und sie werden nicht Teil des Alignments. 

DIALIGN	kann genau wie Needleman-Wunsch im Sinne der jeweiligen Zielfunktion mathematisch optimale paarweise Alignments berechnen. Anders als bei letzterem, kann man aber auch mit Hilfe einer Heuristik für drei oder mehr Sequenzen effizient multiple Alignments bestimmen. Der Algorithmus funktioniert im weitesten Sinne wie folgt:

\begin{algorithm}
	\caption{DIALIGN-Algorithmus zur Berechnung eines multiplen Alignments einer Menge von Sequenzen $S = \{S_1,\dots,S_n\}$}
	\label{alg:dialign}
	\begin{algorithmic}[1]
		\Require Menge $S$ von Sequenzen mit $|S| = n$
		\Procedure{DIALIGN}{$S$}
		\State Weise allen möglichen Fragmenten $f$ ein Gewicht $w^*(f)$ zu \label{dialign:weights}
		\State \begin{varwidth}[t]{\linewidth}
			Berechne mit dynamischer Programmierung alle möglichen ${n}\choose{2}$ paarweisen\par
			\hskip\algorithmicindent Alignments aus $S$
			\end{varwidth} \label{dialign:pair}
		\State Sortiere alle Fragmente der paarweisen Alignments nach ihrem Gewicht als $f_{1, \dots, n}$
		\State $A \gets \emptyset$ \Comment{Initialisiere Ausgabe für Alignment}
		\For{$i = 1$ \textbf{ to } $n$} 
			\If{$f_i$ ist zu allen bisher gewählten Fragmenten \emph{konsistent}} \label{dialign:konsistenz}
				\State $A \gets A \cup \{f_i\}$\Comment{Füge $f_i$ zum \emph{Alignment} hinzu} 
			\EndIf
		\EndFor
		\State \textbf{return} $A$
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

Unter \emph{Konsistenz} können wir uns zunächst informell vorstellen, dass es bei einer Zuweisung weder zu Überkreuzungen kommt, noch dazu, dass ein Symbol einer Sequenz gleichzeitig mehreren einer anderen zugewiesen wird.

\section{Theoretische Grundlagen}\label{sec:theo}

Um multiple Sequenzalignments genauer zu verstehen und die dazu nötigen Algorithmen analysieren zu können, brauchen wir einige Definitionen. Diese sind \cite{mdw96}, \cite{am00} und \cite{cpm10} entnommen. Sei dazu im Folgenden eine $n$-stellige Menge von Sequenzen $S$ über einem endlichen Alphabet gegeben. Wir bezeichnen die Länge der $i$-ten Sequenz als $L_i$.

\begin{definition}[Stelle und Stellenraum\cite{cpm10}]
	Eine \emph{Stelle} ist ein Tupel $(i,p)$, bei dem $i \in \{1,\dots,n\}$ die Sequenz und $p\in \{1,\dots,L_i\}$ die Position eines Zeichens innerhalb dieser Sequenz angibt. 
	
	\noindent Als \emph{Stellenraum} bezeichnen wir die Menge aller Stellen über unseren Sequenzen $S$: $\mathcal{S} \coloneqq \{(i,p)\mid 1 \leq i \leq n, 1 \leq p \leq L_i \}$.
	
	\noindent Der Einfachheit identifizieren wir die \emph{Stellen} der $i$-ten Sequenz als $\mathcal{S}_i$. Auf dem \emph{Stellenraum} existiert eine Halbordnung `$\preceq$', wobei $(i,p) \preceq (i',p')$ genau dann gilt, falls $i=i'$ und $p\leq p'$ gelten.
\end{definition}

Nachdem Alignments und \emph{Konsistenz} bis jetzt nur umgangssprachlich vorgestellt wurden, werden wir diese Begriffe nun formalisiert.

\begin{definition}[Alignment und Konsistenz\cite{mdw96}]
	Ein \emph{Alignment} $\mathcal{A}$ ist eine Äquivalenzrelation auf der Menge $\mathcal{S}$, die das folgende \emph{Konsistenzkriterium} erfüllt. Sei zunächst $\mathcal{R}$ eine beliebige binäre Relation auf $\mathcal{S}$. Wir können diese mit `$\preceq$' zu der Präordnung (auch Quasiordnung genannt) $\preceq_{\mathcal{R}}=(\preceq \cup \mathcal{R})_t$ erweitern, also einer zweistelligen Relation, die reflexiv und transitiv, aber nicht antisymmetrisch ist. Hierbei bezeichnet $\mathcal{X}_t$ die transitive Hülle einer Relation $\mathcal{X}$. 
	
	Wir bezeichnen $\mathcal{R}$ als \emph{konsistent}, wenn $\preceq_{\mathcal{R}}=(\preceq \cup\: \mathcal{R})_t$ die natürliche Ordnung auf jeder Sequenz erhält, also $x \preceq_{\mathcal{R}} y \implies x \preceq y$ für alle $x,y \in S_i und 1\leq i\leq n$ gilt. Außerdem nennen wir eine Menge von Relationen $\{\mathcal{R}_1, \dots, \mathcal{R}_n\}$ \emph{konsistent}, wenn ihre Vereinigung $\cup_i \mathcal{R}_i$ \emph{konsistent} ist, sowie ein Paar $(x,y) \in \mathcal{S}^2$ \emph{konsistent} mit einer Relation $\mathcal{R}$, falls $\mathcal{R} \cup \{(x,y)\}$ \emph{konsistent} ist.
	
	Für ein Alignment $\mathcal{A}$ und $(x,y) \in \mathcal{S}^2$ gilt $x\mathcal{A}y$ genau dann, wenn die Stellen $x$ und $y$ durch $\mathcal{A}$ aligniert werden oder identisch sind.
\end{definition}

Im Folgenden wollen wir zwei Beispiele betrachten, um das Konzept der Konsistenz und Alignments besser zu veranschaulichen. Informell können wir uns ein Alignment als eine Relation vorstellen, bei der es weder zu einer Überkreuzung von Zuweisungen kommt, noch zu Fällen, bei denen ein Symbol (transitiv) gleichzeitig mehreren Symbolen aus einer einzigen anderen Sequenz zugewiesen ist.

\begin{beispiel}
	\begin{center}
	\begin{tikzcd}[/tikz/commutative diagrams/sep=tiny, show background rectangle]
		a_1 \arrow[rrdd, no head, bend left] & a_2 & a_3 & a_4 & a_5 \\
		b_1 \arrow[d, no head] & b_2 & b_3 & b_4 \arrow[lu, no head] & b_5 \\
		c_1 & c_2 & c_3 & c_4 \arrow[u, no head] & c_5
	\end{tikzcd}\captionof{figure}{Beispiel eines Alignments}\label{bsp:alignment}
	\end{center}	
	Für alle Stellen in Abbildung \ref{bsp:alignment}, die aus der selben Sequenz stammen, gilt $x \preceq_{\mathcal{R}} y \implies x \preceq y$, wie beispielsweise für $a_1$ und $a_5$: $a_1 \mathcal{A} c_3, c_3 \preceq c_4, c_4 \mathcal{A} b_4, b_4 \mathcal{A} a_3$ und $a_3 \preceq a_5$. Es folgt $a_1 \preceq_{\mathcal{R}} a_5$. Also ist die Relation auf $\mathcal{S}$ konsistent und somit ein Alignment.
	
	\begin{center}
	\begin{tikzcd}[/tikz/commutative diagrams/sep=tiny,show background rectangle]
		a_1 \arrow[rdd, no head] & a_2 & a_3 & a_4 \arrow[rdd, no head] & a_5 \\
		b_1 & b_2 & b_3 \arrow[ru, no head] & b_4 & b_5 \\
		c_1 \arrow[ruu, no head] & c_2 & c_3 & c_4 & c_5 \arrow[u, no head]
	\end{tikzcd}\captionof{figure}{Beispiel für eine binäre Relation auf $\mathcal{S}$, die kein Alignment ist.}\label{bsp:no_alignment}
	\end{center}
	In Abbildung \ref{bsp:no_alignment} handelt es sich um kein Alignment, denn die Konsistenz ist gleich an mehreren Stellen verletzt. Erstens gilt $a_2 \preceq_{\mathcal{R}} a_1$, denn $a_2 \mathcal{A} c_1, c_1 \preceq c_2$ und $c_2 \mathcal{A} c_1$. Da aber $c_1 \preceq c_2$ gilt, erhält die Relation die natürliche Ordnung auf der ersten Sequenz nicht. Der Grund ist hier die Überkreuzung von mehreren Zuweisungen. Des Weiteren gilt $b_5 \preceq_{\mathcal{R}} b_3$, weil $b_5 \mathcal{A} c_5, c_5 \mathcal{A} a_4$ und $a_4 \mathcal{A} b_3$, aber $b_5 \npreceq b_3$. Hier ist das Problem eine transitive Mehrfachzuweisung von mehreren Symbolen der einen Sequenz auf das gleiche einer anderen (sowohl $b_3$ als auch $b_5$ stehen in Relation zu beispielsweise $a_4$). 
\end{beispiel}

Es lässt sich zeigen, dass eine Relation $\mathcal{A}$ genau dann ein Alignment ist, wenn es möglich ist, zwischen den alignierten Symbolen Lücken einzufügen, sodass genau die einander zugewiesenen in Spalten untereinander stehen. Deshalb bezeichnet man die Äquivalenzklassen $[x]_{\mathcal{A}} = \{y \in \mathcal{S} \colon x\mathcal{A}y \}$ von $\mathcal{A}$ auch als \emph{(Zuweisungs-)Spalten}. Man kann sich leicht überlegen, dass das bei Überkreuzungen und transitiven Mehrfachzuweisungen nicht möglich ist. Im ersten Beispiel \ref{bsp:alignment} von oben würde das so aussehen:

\begin{beispiel}
	\begin{center}
	\begin{tikzcd}[/tikz/commutative diagrams/sep=tiny, show background rectangle]
		- & - & A_1 \arrow[dd, no head] & a_2 & A_3 \arrow[d, no head] & a_4 & a_5 \\
		b_1 & B_2 \arrow[d, no head] &  & b_3 & B_4 \arrow[d, no head] & b_5 & - \\
		c_1 & C_2 & C_3 & - & C_4 & c_5 & -
	\end{tikzcd}
	\end{center}
Alle Symbole, die Teil einer Zuweisungsspalte sind, also einer Äquivalenzklasse mit mehr als einer Stelle, wurden als Großbuchstabe dargestellt, während die nicht-alignierten kleingeschrieben wurden.
\end{beispiel}

Da DIALIGN ein segmentbasiertes Alignmentverfahren ist, brauchen wir noch eine Bezeichnung für eine paarweise, lückenlose Zuweisung von direkt aufeinanderfolgenden Elementen zweier Sequenzen.

\begin{definition}[Fragment\cite{mdw96}]
	Gegeben seien zwei Sequenzen $S_1$ und $S_2$ und ein Alignment $\mathcal{A}$ auf diesen Sequenzen. Dann definieren wir das Fragment mit Länge $l$, das an den Stellen $i$ in $S_1$ und $j$ in $S_2$ endet mit $1 \leq i \leq l(S_1), 1 \leq j \leq l(S_2)$ und $i - l \geq 0 \leq j - l$, als $f_{i,j,l}$, wenn $S_1[i-k] \, \mathcal{A} \, S_2[j-k]$ für alle $0 \leq k \leq l - 1$ gilt. 
\end{definition}

Manchmal werden Fragmente auch als \emph{Diagonals} bezeichnet, weil sie in der Matrix des Needleman-Wunsch-Verfahrens als Diagonale von mehreren aufeinanderfolgenden einander zugeordneten Symbolen stehen würden. Wir können unter einem Alignment auch eine Kette von zueinander konsistenten Fragmenten verstehen.

\section{Gewichtsfunktionen und Substitutionsmatrizen}

Weil es nicht unser Ziel ist ein beliebiges Alignment zu berechnen, sondern ein möglichst gutes, müssen wir in Schritt \ref{dialign:weights} von Algorithmus \ref{alg:dialign} zunächst ein Maß für die Ähnlichkeit von zwei Sequenzen festlegen. Dieses kann dann in den nächsten Abschnitte mit Hilfe von dynamischer Programmierung maximiert werden, um möglichst gute Alignments zu konstruieren.

\subsection{Gewichtsfunktionen in DIALIGN 1}

Um zwei Fragmente miteinander vergleichen zu können, müssen wir die Ähnlichkeit zwischen ihnen quantifizieren. Je ähnlicher sich zwei Fragmente sind, desto eher können wir davon ausgehen, dass sie einen gemeinsamen evolutionären Ursprung haben und als desto wichtiger schätzen wir sie für unser Alignment ein. In der ersten Variante von DIALIGN hat man eine starre stochastische Gewichtsfunktion benutzt, indem man davon ausging, dass alle Symbole gleichverteilt mit Wahrscheinlichkeit $p = 0{,}25$ für DNA und $p = 0{,}05$ für Proteine auftreten \cite{mdw96}. Das liegt daran, dass es vier verschiedene Nukleinsäuren in der DNA und zwanzig Standard-Aminosäuren gibt. 

Wir untersuchen die Ähnlichkeit der zwei Abschnitte eines Fragments, indem wir zuerst die Anzahl an Übereinstimmungen zählen. Danach wird die Wahrscheinlichkeit dafür berechnet, wie wahrscheinlich es ist, dass ein Fragment aus zufällig gewählten Symbolen eine gleich hohe oder höhere Anzahl an Übereinstimmungen hat. Ist die Wahrscheinlichkeit hoch, dann ist das gewählte Fragment vermutlich Zufall. Ist die Wahrscheinlichkeit für die Anzahl an Übereinstimmungen aber sehr gering, dann ist es sehr unwahrscheinlich, dass die Ähnlichkeit reine Koinzidenz ist und es liegt vermutlich eine Verwandtschaft der Abschnitte vor\cite{mdw96}. Dafür sei nun ein Fragment $f$ der Länge $l$, mit $m$ in beiden Sequenzen übereinstimmenden Symbolen gegeben. Dann lautet aufgrund der Gleichverteilung die Wahrscheinlichkeit, dass ein solches Fragment der Länge $l$ $m$ oder mehr Übereinstimmungen hat, wie folgt:

\begin{equation}\label{eq:prob_old}
	P(l,m) = \sum_{i=m}^{l} {l \choose i} \cdot p^i \cdot (1-p)^{l-i}
\end{equation}

DIALIGN 1 benutzt als Gewichtsfunktion den negativen Logarithmus von $P(l,m)$. Dadurch ergibt sich ein umso höheres Gewicht, je niedriger die Wahrscheinlichkeit ist, dass das vorliegende Fragment zufällig entstanden ist. Ziel wird es im Folgenden sein die Summe der Gewichte aller Fragmente eines Alignments zu maximieren. Diese bezeichnen wir wieder als \emph{Score} des Alignments.

\begin{equation}\label{eq:weight_old}
	w(f) \coloneqq -\ln(P(l,m))	
\end{equation}

\subsection{Substitutionsmatrizen}\label{subsec:subs_matr}

Es hat sich jedoch bei der Untersuchung von Proteinsequenzen herausgestellt, dass diese Gewichtsfunktion nicht immer zielführend ist. Nicht alle Aminosäuren sind gleich ähnlich und die Übergangswahrscheinlichkeiten zwischen ihnen können dramatisch verschieden sein. So ist beispielsweise eine Veränderung von Arginin zu Lysin recht wahrscheinlich, während jene von Tryptophan zu Glycin nur sehr selten vorkommt \cite{p13}. 

Deswegen verwenden wir genau wie bei Needleman-Wunsch Matrizen von Werten $\alpha$, die die Ähnlichkeit von oder die Übergangswahrscheinlichkeit zwischen Symbolen angibt. Eine solche Matrix $\alpha$ bezeichnen wir als \emph{Substitutionsmatrix} und auch mit ihrer Hilfe kann das Gewicht von Fragmenten berechnet werden. Sei dazu $f_{i,j,l}$ ein Fragment aus den zwei Sequenzen $S_1$ und $S_2$ und $M$ eine Substitutionsmatrix. Dann berechnet sich das Gewicht von $f_{i,j,l}$ als die Summe der paarweisen Ähnlichkeitswerte:

\begin{equation}
	w(f_{i,j,l}) \coloneqq \sum_{k=1}^{l} M[i\!-\!l\!+\!k,j\!-\!l\!+\!k]
\end{equation}

Dieses Vorgehen hat einige Vorteile gegenüber der alten Gewichtsberechnung \eqref{eq:prob_old}. Zum einen lässt sich das Gewicht eines Fragments $f_{i,j,l}$ sehr einfach berechnen, wenn das Gewicht des Fragments $f_{i-1,j-1,l-1}$ bereits bekannt ist, indem man einen einzigen Ähnlichkeitswert zur Summe hinzu addiert. Zum anderen kann man die Berechnung vieler Gewichte frühzeitig abbrechen, wenn eine Teilsumme der Ähnlichkeitswerte negativ ist. Dann weiß man, dass ein Alignment mit höherem Score berechnen werden kann, wenn man diesen Teil des Fragments weglässt. Diese beiden Eigenschaften werden wir uns im nächsten Abschnitt über die effiziente Berechnung der paarweisen Alignments zunutze machen.

Nun wollen wir Substitutionsmatrizen und die Theorie dahinter genauer betrachten. Das werden wir anhand der von \cite{hh92} entwickelten BLOcks SUbstitution Matrix (BLOSUM) tun, da andere verbreitete Substitutionsmatrizen ähnlich entstanden sind. Die Matrizen wurden empirisch bestimmt, indem man sich Blöcke von Proteinmotiven anguckt hat, bei denen ein korrektes Alignment bekannt war. Als Block bezeichnen wir einen längeren, zusammenhängenden alignierten Bereich ohne gelöschte oder eingefügte Segmente. Für die Berechnung eines Eintrags der Matrix $M_{i,j}$ brauchen wir die Wahrscheinlichkeiten  $q_i$ und $q_j$, mit der die beiden Aminosäuren auftreten, sowie die Wahrscheinlichkeit $p_{i,j}$, dass gerade diese beide Aminosäuren miteinander aligniert werden.

\begin{equation}
	M_{i,j} \coloneqq \frac{1}{\lambda} \log\bigg( \frac{p_{i,j}}{q_i\cdot q_j} \bigg)
\end{equation}

Der Korrekturterm $\lambda$ wird benutzt, um die Werte auf ganze Zahlen zu runden, die weniger anfällig für Rundungsfehler und andere Ungenauigkeiten in der Computerarithmetik sind. Diese Vorgehensweise wird, da man den Logarithmus einer Wahrscheinlichkeit berechnet, als \emph{log-odd}-Verfahren bezeichnet. Der Eintrag $M_{i,j}$ gibt ein Maß für die Wahrscheinlichkeit an, dass das betrachtete Paar in einem Alignment aus genau diesen beiden Aminosäuren auftritt. Die Wahrscheinlichkeit für eine längere Folge aufeinanderfolgender Paare wird mit der Summe der Einträge berechnet. Das funktioniert aufgrund der Rechenregeln des Logarithmus: $\log(p_1 \cdot p_2) = \log(p_1) + \log(p_2)$. Für die Berechnung der ursprünglichen Wahrscheinlichkeiten reicht es die Summe der Ähnlichkeitswerte zu exponenzieren. 

\cite{hh92} haben mehrere Substitutionsmatrizen entwickelt. Die Zahl hinter jeder BLOSUM gibt die Ähnlichkeit der zur Berechnung der Matrix verwendeten Proteinsequenzen an. Für die BLOSUM62 wurden beispielsweise nur Blöcke benutzt, bei denen es eine Ähnlichkeit von höchstens 62\% gab. Im Allgemeinen wird dazu geraten, BLOSUMs mit geringen Suffixen wie beispielsweise BLOSUM45 zum Alignieren von entfernt verwandten, mit großen wie BLOSUM80 für eng verwandte und BLOSUM62 für durchschnittlich eng verwandte Sequenzen zu benutzen. Im Anhang\ref{anh:BLOSUM62} befindet sich die BLOSUM62 von Henikoff und Henikoff aus der Originalveröffentlichung.

Bei DNA wird meistens nur eine zwischen Treffern und Nichttreffern unterschieden. Als Substitutionsmatrix entspräche dies der Einheitsmatrix. Dies hat aber den Nachteil, dass alle Fragmente positive Gewichte haben und damit potentiell für unser Alignment in Betracht kommen. Besser sind positive Werte für ähnliche und negative für sehr unähnliche Abschnitte, weil sich so der Rechenaufwand verringern lässt. Außerdem kann man mit Matrizen, die dem Einsatzgebiet angepasst sind, oft bessere Ergebnisse erzielen. Nach Pearson sind die Ähnlichkeiten zwischen zu vergleichenden DNA-Sequenzen deutlich größer, als bei Proteinen\cite{p13}. Sie betragen zwischen homologen menschlichen DNA-Abschnitten etwa 99,9\% und bei proteinkodierenden Regionen zwischen Mensch und Maus immer noch 80\%, während Ähnlichkeiten von unter 50\%, anders als bei Proteinen, quasi nicht mehr zu entdecken sind. Untersuchungen haben ergeben, dass die Substitutionsmatrix mit (+1/-3) für Treffer und Nichttreffer bei Sequenzen mit 99\% Übereinstimmung die besten Alignments liefern. Diese Matrix bestraft Punktmutationen sehr stark, weil es in einem Fragment dreimal so viele Treffer wie Nichttreffer geben muss, für eine positives Gewicht. Bei 90\% Übereinstimmung liefert die (+2/-3)-Matrix die besten Ergebnisse und bei 70\% die (+5/-4)-Matrix.

Es lässt sich nicht abstreiten, dass die Wahl der richtigen Substitutionsmatrix dem Henne-Ei-Problem ähnelt: um die Ähnlichkeit von zwei Sequenzen zu bestimmen, müssen wir sie mit der passenden Matrix alignieren. Für die Wahl der richtigen Substitutionsmatrix sollten wir jedoch wissen, wie ähnlich sich die beiden Sequenzen sind.

Wann genau sich die Berechnung der Gewichte in DIALIGN verändert hat, steht leider in keiner Veröffentlichung, auch wenn sie bereits in \cite{mdw96} als kommende Ergänzung in Betracht gezogen wurde. Spätestens bei DIALIGN TX, der neuesten Version des Algorithmus, wird diese Technik jedoch angewendet \cite{DIALIGNTX}. Dort dient eine modifizierte BLOSUM 62, die nur nicht-negative Werte enthält, als Matrix für Proteinsequenzen, während bei DNA lediglich die Einheitsmatrix benutzt wird.

\subsection{Gewichtsfunktionen in DIALIGN 2} 

In der ursprünglichen Version von DIALIGN gab es einen benutzerdefinierten Parameter $T$, der das minimale Gewicht eines in Betracht zu nehmenden Fragments angab. Dieser wurde eingeführt, damit nicht kleine, zufällige Übereinstimmungen ihren Weg in das Alignment finden. Das Wichtigste für ein gutes Alignment ist, dass verwandte, also homologe, Abschnitte miteinander aligniert werden. Fast genauso wichtig ist es aber, dass es zu keinen Zuordnungen kommt, wenn keine Verwandtschaft vorliegt. Bei Tests mit DIALIGN 1 hat man jedoch festgestellt, dass ein Großteil der ausgewählten Fragmente nur knapp über der Gewichtsgrenze $T$ lagen und wenn diese gesenkt wurde, sank auch das Gewicht der Fragment \cite{mahd98}. 

Das liegt daran, dass die Gewichtsfunktion $w$ einem langen Fragment $f$ quasi das gleiche Gewicht zuordnet, wie die Summe der Gewichte der Teilfragmente $f_1, \dots, f_n$, wenn $f$  auf diese aufgeteilt wird. Das sorgt dafür, dass sich oft bessere Scores ergeben, wenn größere Fragmente aufgeteilt und dazwischen einzelne Regionen mit geringen Übereinstimmungen weggelassen werden, statt die großen Fragmente selbst auszuwählen. Neben der Abhängigkeit vom willkürlichen Parameter $T$ und der Tendenz kleine, unbedeutende Übereinstimmungen auszuwählen, hat dies auch den Nachteil, dass die rechenintensive Aktualisierung der Konsistenzgrenzen öfter durchgeführt werden muss. 

Deshalb ist man in DIALIGN 2 dazu übergegangen, statt der Wahrscheinlichkeit $P(l,m)$, dass in einem Fragment der Länge $l$ mindestens $m$ Übereinstimmungen auftreten, zu berechnen, wie wahrscheinlich es ist, dass in den beiden Gesamtsequenzen $S_1$ und $S_2$ mit Längen $l_1$ respektive $l_2$ überhaupt eine Sequenz mit Länge $l$ und $m$ Übereinstimmungen auftritt. 

\begin{equation}
	P^*(l,m) \approx l_1\cdot l_2\cdot P(l,m)
\end{equation}

Als neue Gewichtsfunktion $w^*$ ergibt sich dann mit $K \coloneqq \log(l_1) + \log(l_2)$:

\begin{equation}
	w^*(f) \coloneqq w(f) - K
\end{equation}

Wenn man $f$ nun in $f_1, \dots f_n$ aufteilt, wird der Korrekturterm $K$ nicht nur einmal, sondern $n$-mal abgezogen. Das sorgt dafür, dass tendenziell längere Fragmente ausgewählt werden \cite{m99}. Ein weiterer Vorteil ist, dass der Erwartungswert des Gewichts eines zufälligen Fragments nicht mehr 1, sondern 0 ist. Dadurch haben alle Abschnitte mit unterdurchschnittlicher Ähnlichkeit automatisch negative Gewichte und wir haben eine einfache und schnelle Möglichkeit zu entscheiden, ob ein Fragment weiter für unser Alignment in Betracht gezogen werden muss.

Wie sich der Effekt von $w^*$ auswirkt, wenn eine Substitutionsmatrix benutzt wird, die einem zufälligen Fragment im Schnitt ein negatives Gewicht zuordnet, müsste man empirisch feststellen. Möglicherweise ist es in dem Fall besser, auf den Korrekturterm $K$ zu verzichten und nur mit einer Substitutionsmatrix wie beispielsweise BLOSUM62 zu arbeiten. Mit einer (+2/-3)-Matrix ergibt sich beispielsweise ein Erwartungswert von $E(w(f_{i,j,l})) = \big( \frac{3}{4}\cdot(-3) + \frac{1}{4}\cdot2 \big) \cdot l = -\frac{7}{4}\cdot l$ für ein zufälliges DNA-Fragment der Länge $l$. Ein anderer Ansatz verbindet die Substitutionsmatrix mit dem Korrekturterm $K$, indem wir wie DIALIGN TX eine Substitutionsmatrix benutzen, die aber keine negativen Werte enthält. Dafür ziehen wir aber weiterhin $K$ vom Gewicht ab.
 
\section{Paarweise Alignments mit dynamischer Programmierung}

Nachdem wir uns jetzt genauer mit den Gewichten von Fragmenten beschäftigt haben, können wir uns der Berechnung der paarweisen Alignments mit Hilfe von dynamischer Programmierung widmen. Dabei beziehen wir uns, außer wenn anders gekennzeichnet, auf die speichereffiziente Umsetzung aus DIALIGN 2.2, die in \cite{m02} vorgestellt wurde. 

Wie bei dynamischer Programmierung üblich, stellen wir zunächst eine Rekursionsgleichung auf. Sei dazu $Sc[i,j]$ der maximal mögliche Score aller Fragmente bis zu den Elementen $S_1[i]$ und $S_2[j]$ zweier Sequenzen $S_1$ und $S_2$. An dieser Stelle tritt sehr ähnlich zu Needleman-Wunsch eine von drei Situationen auf: Die ersten beiden Möglichkeiten sind, dass wir die Stelle $(1,i)$ oder die Stelle $(2,j)$ nicht zu unserem Alignment hinzufügen. Oder aber wir wählen ein Fragment $f_{i,j,l}$ aus, das in $(i,j)$ endet. In diesem Fall wählen wir genau das aus, welches den Score aller in $(i,j)$ endenden Alignments maximiert. Welcher der drei Fälle der richtige ist, um den höchstmöglichen Score bis $(i,j)$ zu berechnen, erfahren wir, indem das Maximum von ihnen bestimmt wird.

\begin{equation}\label{eq:dp_score2}
	Sc[i,j] = \max
	\begin{cases}
		Sc[i-1,j], \\
		Sc[i,j-1], \\
		\max_{l\geq 1}\{Sc[i\!-\!l,j\!-\!l] + w^*(f_{i,j,l})\}
	\end{cases}
\end{equation}

\begin{satz}[{\cite{m02}}]
	Mit der obigen Rekursionsgleichung \eqref{eq:dp_score2} lässt sich ein optimales paarweises Alignment zweier Sequenzen mit Längen $L_1$ und $L_2$ in $\oh(L^3)$ Zeit und $\oh(L^2)$ Speicherplatz berechnen für $L = \max(L_1, L_2)$. Außerdem gilt für die Menge der möglichen Fragmente $F{:} |F| \in \oh(L^3)$.
\end{satz}
	
\begin{beweis}
	Insgesamt müssen wir $L_1 \cdot L_2 \in \oh(L^2)$-viele Tabelleneinträge berechnen, die wir im Allgemeinen auch gleichzeitig im Speicher vorhalten. Für jeden zu berechnenden Eintrag $Sc[i,j]$ brauchen wir Zugriffe auf $(\min(i,j) + 2)$-viele Einträge in der Matrix und müssen $\min(i,j)$ Gewichte neu berechnen. Dabei dominiert die Berechnung der Gewichte, wobei jedes Gewicht nur genau einmal berechnet werden muss (für den Score des Tabelleneintrags, in dem das Fragment endet). Im schlimmsten Fall gilt $L_1 = L_2$. Dann gibt es Fragmente der Länge 1 mit jeweils $L$ möglichen Endpunkten in $S_1$ und $S_2$, der Länge zwei mit jeweils $L-1$ möglichen Endpunkten und so weiter. Die Anzahl aller Fragmente $|F| = \sum_{k=0}^{L-1}(L-k)^2 = \frac{1}{6} \cdot L(2L^2+3L+1) \in \oh(L^3)$ und die naiv berechnete Anzahl der Zugriffe ist $\sum_{k=0}^{L-1}(L-k)^2\cdot k = \frac{1}{12} \cdot (L-1)L^2(L+1) \in \oh(L^4)$. Glücklicherweise kann man das Gewicht jedes Fragments $f_{i,j,l}$ in $\oh(1)$ Zeit aus $f_{i,j,l-1}$ berechnen, denn $w^*(f_{i,j,l}) = w^*(f_{i,j,l-1}) + M[i\!-\!l\!+\!1, j\!-\!l\!+\!1]$, wodurch sich die Laufzeit auf $\oh(L^3)$ verkleinern lässt.
\end{beweis}

Um nicht nur den Score eines perfekten paarweisen Alignments berechnen zu können, sondern auch dieses Alignment selbst, müssen wir zunächst noch einige Definitionen einführen. Zuerst definieren wir für ein Fragment $f \in F$ das \emph{Präfixgewicht} $W(f)$, das die maximale Summe der Gewichte einer Kette $f_1 \ll \dots \ll f_M=f$ von aufeinanderfolgenden Fragmenten bezeichnet, die mit $f$ endet. Wir können uns dieses Gewicht als maximalen Score eines paarweisen Alignments vorstellen, in dem $f$ als letztes Fragment vorkommt.

\begin{equation}\label{eq:praefixgewicht1}
	W(f) \coloneqq \max \left\{ \sum_{k=0}^{M} w^*(f_k) : f_1 \ll \dots \ll f_M=f \right\}
\end{equation}

\begin{definition}[Vorgänger\cite{m02}]
	Sei $f_1 \ll \dots \ll f_M$ eine Kette von Fragmenten, die das Maximum der vorherigen Gleichung erreicht. Dann bezeichnen wir $P(f) = f_{M-1}$ als den \emph{Vorgänger} von $f$. Außerdem sei $Pr[i,j]$ das letzte Fragment einer optimalen Kette aus \eqref{eq:praefixgewicht1}, die spätestens in $(i,j)$ endet. 
\end{definition}

Jetzt können wir für ein Fragment $f \in F$, das in $(i,j)$ startet, das Gesamtgewicht und den Vorgänger genau definieren. Das Präfixgewicht ist genau das Gewicht von $f$ addiert mit dem Score der Fragmente, die vor $f$ stehen. $P(f)$ und $Pr[i,j]$ sind streng genommen nicht wohldefiniert und es könnte mehrere Fragmente mit diesen Eigenschaften geben. Wie auch schon in DIALIGN 1 wählen wir dann das in den Sequenzen am weitesten rechts stehende aus \cite{mdw96}.

\begin{equation}\label{eq:praefixgewicht2}
	W(f) = Sc[i\!-\!1,j\!-\!1]+w^*(f)
\end{equation}

Der Vorgänger von $f$ ist das letzte Element einer Kette von Fragmenten, die vor $f$ enden.

\begin{equation}\label{eq:vorgaenger}
	P(f) = Pr[i\!-\!1,j\!-\!1]
\end{equation}

Damit können wir jetzt Rekursionsgleichung \eqref{eq:dp_score2} mit unseren neuen Definitionen umformulieren, denn der dritte Fall der obigen Gleichung ist genau das maximale Präfixgewicht eines Fragments, das in $(i,j)$ endet. Diese Umformulierung erlaubt uns mit Algorithmus \ref{alg:dialign} eine speichereffiziente Berechnung von paarweisen Alignments.

\begin{equation}\label{eq:praefixgewicht3}
	Sc[i,j] = \max
		\begin{cases}
		Sc[i\!-\!1,j], \\
		Sc[i,j\!-\!1], \\
		\max{W(f): f\: \text{endet in}\: (i,j)}
	\end{cases}	
\end{equation}

Analog zu den Fällen von $Sc[i,j]$ können wir jetzt auch $Pr[i,j]$ setzen. Das letzte Fragment einer optimalen Kette bis $(i,j)$ ist das selbe wie bei $(i-1,j)$ beziehungsweise $(i,j-1)$, wenn diese in keinem dieser beiden Stellenpaare endet. Endet sie hingegen in $(i,j)$, dann ist das gesuchte Fragment das, welches das Präfixgewicht aller in $(i,j)$ endenden Fragmente maximiert.

\begin{equation}\label{eq:vorgaenger2}
	Pr[i,j] =
		\begin{cases}
			Sc[i-1,j], & \text{falls}\: Sc[i,j] = Sc[i\!-\!1,j]\\
			Sc[i,j-1], & \text{falls}\: Sc[i,j] = Sc[i,j\!-\!1]\\
			\hat{f},   & \text{falls}\: Sc[i,j] = \max{\{W(f) : f\: \text{endet in}\: (i,j)\}}
		\end{cases}	
\end{equation}

Hier gilt $\hat{f} = \operatorname{argmax}\{W(f) : f\: \text{endet in}\: (i,j) \}$. Jetzt stehen uns alle Informationen zur Verfügung, um neben dem Score einer optimalen Kette von Fragmenten auch diese selbst zu berechnen. Zunächst sei $f_{\max} = \operatorname{argmax}_{f\in F}(W(f))$ das letzte Element dieser Kette. Man erhält es, indem man sich das letzte Element einer optimalen Kette anguckt, die bis ganz ans Ende von $S_1$ und $S_2$ reichen kann: $f_{\max} = Pr[L_1,L_2]$. Mit einem Backtrackingalgorithmus sind wir nun in der Lage, das optimale paarweise Alignment zu berechnen, indem wir mit $f_{\max}$ starten und immer den direkten Vorgänger des aktuellen Fragments auswählen.

\begin{equation}\label{eq:backtracking}
	f_0 = f_{\max}\: \text{und}\: f_{k+1} = P(f_k)
\end{equation} 

Wenn es keinen solchen Nachfolger mehr gibt, dann wurde die Menge von aufeinanderfolgenden Fragmenten gefunden, die den Score maximiert und somit ein gutes paarweises Alignment liefert.

\subsection{Speichereffiziente Berechnung der paarweisen Alignments}\label{subsec:psa}

In diesem Abschnitt beschäftigen wir uns mit einer sehr speichereffizienten und schnellen Umsetzung des soeben gesehenen Ansatzes. Speichereffizienz ist wichtig, weil die zu alignierenden Sequenzen sehr lang werden können. Die Verringerung des benötigten Speichers erlaubt die volle Ausnutzung von kleinem, aber schnellem Speicher in der Speicherhierarchie und die Vermeidung von kostenintensiven Seitenfehlern.

Zunächst beschränken wir die maximale Länge eines Fragments $l_{\max}$ auf eine kleine, feste Zahl, beispielsweise 40. Je nach gewünschter Genauigkeit und benötigter Geschwindigkeit kann man diesen Wert vergrößern oder verkleinern. Auch wenn diese Einschränkung den maximal zu erreichenden Score senkt und wir daher keine perfekten Alignments mehr berechnen, hat $l_{\max}$ in der Praxis kaum einen Einfluss auf die Güte der Ergebnisse. Das liegt daran, dass wir im Fall von geringen Ähnlichkeiten zwischen Sequenzen nur selten Fragmente mit Längen haben, die $l_{\max}$ überschreiten und im Fall von sehr ähnlichen Sequenzen können wir lange Fragmente auch in mehrere kleinere in der Größenordnung unserer Begrenzung aufteilen. Wir werden zeigen, dass mit dieser Einschränkung ein paarweises Alignment in $\oh(L^2)$ Zeit und $\oh(L+N_{\max})$ Speicherplatz berechnet werden kann, wobei $N_{\max}$ die Anzahl an gleichzeitig gespeicherten Fragmenten ist, die durch $|F|$ begrenzt wird \cite{m02}.

\begin{algorithm}[H]
	\caption{Speichereffizientes paarweises DIALIGN}
	\label{alg:speichereffizient}
	\begin{algorithmic}[1]
		
		\Require Zwei Sequenzen $S_1$ und $S_2$ mit den Längen $L_1$ und $L_2$
		\Procedure{pairwiseAlignment}{$S_1$, $S_2$, $l_{\max}$}
		\For{$i \gets 0$}{$L_1$}
		\State $Sc[i,0] \gets 0$
		\EndFor
		\For{$j \gets 1$ \textbf{to} $L_2$}\label{algl:start_loop}
		\For{$i \gets 1$ \textbf{to} $L_1$}
		\For{$l \gets 1$ \textbf{to} $l_{\max}$}\label{algl:fragmentgewichte}
		\State $W(f_{i+l,j+l,l}) \gets w^*(f_{i+l,j+l,l}) + Sc[i\!-\!1,j\!-\!1]$\label{algl:praefixgew}
		\State $P(f_{i+l,j+l,l}) \gets Pr[i\!-\!1,j\!-\!1]$\label{algl:vorgaenger}
		\State $F_{j+l} \gets F_{j+l} \cup {f_{i+l.j+l,l}}$\Comment{{\small Speichere Fragment für Spalte, in der es endet}}\label{algl:fragmentliste}
		\EndFor
		\State
		$Sc[i,j] = \max
		\begin{cases}
		Sc[i\!-\!1,j], \\
		Sc[i,j\!-\!1], \\
		\max{W(f): f\: \text{endet in}\: (i,j)}
		\end{cases}$\label{algl:praefix}
		\State Setze $Pr[i,j]$ analog zu $Sc[i,j]$
		\State Lösche $Sc[i,j\!-\!1]$ und $Pr[i,j\!-\!1]$\Comment{{\small Lösche alte Spalteneinträge}}\label{algl:del_frags}
		\ForAll{$f_{i,j,k} \in F_j$ mit $f \neq Pr[i,j]$}
		\State lösche $F_{i,j,k}$\Comment{{\small Lösche die, die in keiner opt. Kette in $(i,j)$ enden}}
		\EndFor
		\EndFor
		\EndFor\label{algl:end_loop}
		\State $f_0 \gets Pr[L_1,L_2]$
		\While{$f_k \neq \text{NIL}\:$}\Comment{{\small Backtracking, um Alignment zu bestimmen}}
		\State $f_{k+1} \gets P(f_{k})$
		\State $k \gets k+1$
		\EndWhile 
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

Der Algorithmus \ref{alg:speichereffizient} geht die Scorematrix $Sc$ Spalte für Spalte von links nach rechts durch (Zeile \ref{algl:start_loop} bis \ref{algl:end_loop}). An jeder Position $(i,j)$ berechnet er mit \eqref{eq:praefixgewicht2} und \eqref{eq:vorgaenger} $W(f)$ und $P(f)$ für alle Fragmente $f \in \{f_{i+k,j+k,k} : 1 \leq k \leq l_{\max}\}$, die an der Stelle $(i,j)$ beginnen (Zeile \ref{algl:praefixgew} und \ref{algl:vorgaenger}). Dabei speichern wir Verweise auf $W(f)$ und $P(f)$ in den Listen $F_{j+k}$, die mit der Spalte $j+k$ assoziiert werden, in denen die jeweiligen Fragmente enden. Alles, was wir dafür an Informationen benötigen, sind $Sc[i\!-\!1,j\!-\!1]$ und $Pr[i\!-\!1,j\!-\!1]$. Deshalb müssen wir nicht permanent die ganze Matrix vorhalten, sondern benötigen nur die zuletzt berechnete und die aktuelle Spalte für $Sc$ und $Pr$, also vier eindimensionale Arrays der Länge $L_1$.

Bevor wir zur $(j+1)$-ten Spalte übergehen, berechnen wir alle Einträge von 1 bis $i$ für die $j$-te Spalte. Dazu greifen wir auf die Werte der vorhergehenden Spalte $(j-1)$ und auf die zuvor gespeicherten Listen aller Fragmente $F_j$ zu , die in der $j$-ten Spalte enden, wobei wir die Formeln \eqref{eq:praefixgewicht3} und \eqref{eq:vorgaenger2} benutzen. Man kann sich überlegen, dass für jeden Eintrag $(i,j)$ höchstens $l_{\max} \in \oh(1)$ Fragmente gespeichert wurden. Sobald wir mit der Berechnung der $j$-ten Spalte fertig sind, können wir die Werte von $Pr[i,j-1]$ und $Sc[i,j-1]$ für $1 \leq i \leq L_1$ löschen.

Diesen Vorgang wiederholen wir, bis wir schlussendlich auch alle Werte der letzten, also $L_2$-ten, Spalte berechnet haben. Dann kennen wir mit $Sc[L_1,L_2]$ den Score des paarweisen Alignments und können mithilfe der Backtrackingprozedur \eqref{eq:backtracking} die Fragmente, aus denen es besteht, bestimmen. Dazu brauchen wir die Mengen $F_j$, deren Einträge aber glücklicherweise nicht alle dauerhaft gespeichert werden müssen. Sobald $Sc[i,j]$ und $Pr[i,j]$ für eine Position $i,j)$ berechnet wurden, können wir alle Fragmente, die dort enden, löschen, abgesehen von $Pr[i,j]$, für das immer noch in Frage kommt, Teil der optimalen Kette von Fragmenten zu sein (Zeile \ref{algl:del_frags}). Sollte $Pr[i,j]$ nicht in $(i,j)$ enden, können wir sogar alle Einträge aus $F_j$ löschen, die in Zeile $i$ enden.

Da wir wissen, dass nur Fragmente mit positiven Gewichten Teil unseres Alignments sein können, sind wir in der Lage die Mengen $F_j$ von gespeicherten Fragmenten weiter einzuschränken. Ist die Teilsumme von Ähnlichkeitswerten bis zu einem bestimmten Punkt negativ, können wir den Durchlauf von Zeile \algref{alg:speichereffizient}{algl:fragmentgewichte} sofort abbrechen, weil wir wissen, dass wir ein besseres Alignment finden, wenn wir den Teil mit der negativen Summe von Gewichten ignorieren. Außerdem gibt es zwei Situationen bei denen wir die Berechnung der Gewichte für Fragmente zwar nicht abbrechen, aber wissen, dass das aktuell betrachtete Element nicht gespeichert werden muss:

\begin{itemize}
	\item Bei negativem Gewicht: Es kann beispielsweise sein, dass $w(f)$ zwar positiv ist, aber $w^* = w(f)-K < 0$ gilt. Dann kann dieses Fragment den Score zwar nicht erhöhen, aber möglicherweise ist es Teil eines größeren Fragments, das zum finalen optimalen Alignment gehört.
	\item Wenn das Gewicht kleiner ist, als das größte bisher gefundene eines Fragments, das in $(i,j)$ startet. In diesem Fall wissen wir, dass Ersteres auf jeden Fall ein besseres Alignment liefern würde.
	\item Bei DNA, weil es dort nur Übereinstimmungen oder Abweichungen zwischen einzelnen Basen gibt: Wenn das Residuenpaar direkt hinter dem Ende des aktuellen Fragments einen positiven Ähnlichkeitswert hat, bedeutet das, dass dieses auf jeden Fall bessere Ergebnisse liefert und wir das aktuelle nicht speichern müssen. Im Programm können wir dies so umsetzen, dass wir das Fragment $f_{i+l,j+l,l}$ erst dann zu $F_{j+l}$ hinzufügen, wenn wir im nächsten Durchlauf der Schleife in Zeile \algref{alg:speichereffizient}{algl:fragmentgewichte} für die jeweilige Zeile kein Fragment mit einem größeren Gewicht finden. Auf diese Art und Weise suchen wir quasi nach lokalen Maxima der Fragmentgewichte und speichern nur diese. Bei Proteinsequenzen funktioniert dieses Vorgehen nicht, weil es sein könnte, dass es für eins der beiden Symbole weiter hinten in der jeweils anderen Sequenz einen besseren Partner mit höherem Ähnlichkeitswert gibt. In diesem Fall müssen wir das zuerst gefundene, kürzere Fragment speichern und gegebenenfalls später zum Alignment hinzufügen. 
\end{itemize}

Guckt man sich Zeile \algref{alg:speichereffizient}{algl:praefix} genauer an, stellt man fest, dass man gar nicht alle Fragmente kennen muss, die in $(i,j)$ enden. Es reicht das zu kennen, welches das Präfixgewicht $W(f)$ aller dort endenden Ketten maximiert. Anstatt alle dieser Fragmente in $F_j$ zu speichern reicht es zu überprüfen, ob der dritte Fall von Zeile \algref{alg:speichereffizient}{algl:praefix} eintritt und erst dann in Zeile \algref{alg:speichereffizient}{algl:fragmentliste} zu sichern. Das bedeutet, dass wir keine ganze Liste von Fragmenten für jede Stelle unserer Tabelle speichern müssen, sondern nur ein einziges.

Widmen wir uns nun $N_{\max}$, der Anzahl an Fragmenten, die maximal gleichzeitig gespeichert werden. Diese Anzahl wird gleich für die Berechnung des Speicherbedarfs benötigt. Die Anzahl an gesicherten Fragmenten, die wir noch nicht für $Sc[i,j]$ betrachtet haben, beträgt $l_{\max} \cdot L_1 \in \oh(L)$, weil wir für jede der nächsten $l_{\max}$ Spalten und dort jede der $L_1$-vielen Zeilen das Fragment speichern, das $W(f)$ für alle dort endenden maximiert. Zusätzlich wird die Reihe von Vorgängern für jeden aktuellen Tabelleneintrag der Spalte gesichert, indem wir in $Pr[i,j]$ einen Verweis auf das letzte Fragment einer optimalen Kette für die Teilsequenzen bis zu den Stellen $i$ und $j$ in den beiden Sequenzen speichern (Zeile \algref{algl:speichereff}). Dieses wiederum speichert einen Pointer auf seinen eigenen Vorgänger und so weiter. Im schlimmsten Fall befinden wir uns in der letzten Spalte der Tabelle und die in den Einträgen endenden optimalen Ketten sind alle unabhängig voneinander. Dann kann es sein, dass diese jeweils aus $\oh(L_2)$ nah aufeinanderfolgenden Fragmenten der Länge $\oh(1)$ bestehen. In diesem Fall ist $N_{\max} \in \oh(L^2)$, genau wie der insgesamt benötigte Speicherplatz. In der Praxis kann man aber erwarten, dass $N_{\max}$ deutlich kleiner ist. 

\cite{m02} hat sein Verfahren mit verschiedenen Sequenzen getestet. Dabei hat er festgestellt, dass $N_{\max}$ für unabhängige zufällig erstellte Sequenzen im Vergleich zur Größe $L$ zu vernachlässigen ist. Selbst wenn sehr ähnliche Sequenzen miteinander aligniert wurden, befand sich $N_{\max}$ in der Größenordnung von $L \cdot l_{\max}$. So gesehen bietet dieser Ansatz einen großen Vorteil gegenüber der naiven Umsetzung der Rekursionsformel für paarweise Alignments.

\subsection{Laufzeit}

\begin{satz}[\cite{m02}]
	Ein paarweises optimales Alignment zwischen zwei Sequenzen $S_1$ und $S_2$ mit Längen $L_1$ und $L_2$, gegeben eine maximale Fragmentlänge $l_{\max} \in \oh(1)$, lässt sich in $\oh(L^2)$ Zeit berechnen für $L = \max\{L_1, L_2\}$.
\end{satz}

\begin{beweis}
	Das Allozieren des Speicherplatzes für die vier Tabellenspalten (je zwei für $Sc[i,j]$ und $Pr[i,j]$) und das Initialisieren der ersten Spalten benötigt $\oh(L)$ Zeit. Das Berechnen der Vorgänger und Präfixgewichte sowie das Speichern in $F_{j'}$ der in $(i,j)$ startenden Fragmente benötigt pro Tabelleneintrag $\oh(1)$ Zeit, da ihre Länge durch $l_{\max}$ beschränkt ist. $Sc[i,j]$ und $Pr[i,j]$ lassen sich auch jeweils in konstanter Zeit berechnen, da wir nur das Maximum von drei Werten bestimmen müssen. Sollte nicht das Fragment gewählt werden, welches das Präfixgewicht aller in $(i,j)$ endenden Fragmente maximiert, löschen wir diesen einzelnen Eintrag in $\oh(1)$ Zeit. Dies wird für jeden möglichen der $L_1 \cdot L_2 \in \oh(L^2)$ Tabelleneinträge berechnet, was auch die Laufzeit der geschachtelten for-Schleifen ist.
	
	Der Backtrackingprozess zur Berechnung des optimalen Alignments ist in $\oh(L)$ Zeit möglich, da wir lediglich der Kette von Verweisen auf den jeweiligen Vorgänger folgen müssen, bis wir am Anfang der Sequenzen angelangt sind. Weil die Länge jedes Fragments in $\oh(1)$ ist, kann es somit bis zu $\oh(L)$ Fragmente im Alignment geben. Bei den Verweisen auf die Vorgänger kann es zu keinen Zyklen kommen, weil der Vorgänger auf jeden Fall endet, bevor das gerade betrachtete Element beginnt. Somit folgt die behauptete Laufzeit von $\oh(L^2)$.
\end{beweis}

Da wir Alignments zwischen allen ${n}\choose{2}$ $\in \oh(n^2)$-vielen Paaren mit jeweils $\oh(L^2)$ Laufzeit berechnen müssen, erhalten wir für die paarweisen Alignments insgesamt eine Laufzeit von $\oh(n^2\cdot L^2)$.

\subsection{Beispiel zur Berechnung paarweiser Alignments} 
Um das DIALIGN-Verfahren, das diese Bachelorarbeit behandelt, genauer zu verstehen, widmen wir uns jetzt einem Beispiel mit vier DNA-Sequenzen. Zu diesen werden wir im Lauf der Kapitel immer wieder zurückkehren und an ihnen die verschiedenen Schritte von DIALIGN und dem graphtheoretischen Ansatz von Corel et al. der Reihe nach durchführen.

\ttfamily
\begin{enumerate}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item ADGTCTCA
	\item GTCADCTCA
	\item TATCADGG
	\item DGTCADATC
\end{enumerate}
\normalfont
Als erstes berechnen wir nach dem oben beschriebenen Algorithmus ein paarweises Alignment zwischen den ersten beiden Sequenzen. Dazu nehmen wir eine Substitutionsmatrix mit $+3$ für Übereinstimmungen und $-1$ für Abweichungen. Der Korrekturterm $K = \ln(L_i) + \ln(L_j)$ aus unserer Gewichtsfunktion $w^*$ beträgt für alle Sequenzpaare gerundet 4. Um die Übersichtlichkeit zu wahren, werden hier nur ein Zwischenschritt und das Endergebnis vorgestellt. Das komplette Beispiel befindet sich in Anhang \ref{anh:beispiel_psa}.

Für jedes Symbol der zweiten Sequenz wird der Reihe nach jedes Symbol der ersten Sequenz betrachtet. Dabei werden zunächst Fragmente für später im Feld $F_{j'}[i']$ gespeichert, die an der aktuellen Stelle $(i,j)$ starten. Um Speicherplatz zu sparen, wird ihr Präfixgewicht mit dem des aktuell gespeicherten Element verglichen und falls es höher ist, stattdessen gesichert (Schleife beginnend bei Zeile \ref{algl:fragmentgewichte}). Danach wird der Score $Sc[i][j]$ gesetzt, indem das Fragment betrachtet wird, das an in $(i,j)$ endet und das maximale Präfixgewicht hat. Ist dieses höher, als der Score, wenn man das letzte Element einer der beiden Teilsequenzen ignoriert ($Sc[i-1,j]$ oder $Sc[i,j-1]$), dann wird dieses Fragment gespeichert. Ist das nicht der Fall, dann wird es verworfen und stattdessen der maximale benachbarte Tabelleneintrag übernommen (Zeile \ref{algl:praefix}). Betrachten wir die Tabelle für $j=2$:

\begin{tabular}{|r|cc|cc|l|}
	\hline
	& \multicolumn{2}{c|}{\multirow{2}{*}{$Sc[i,j]$}} & \multicolumn{2}{c|}{\multirow{2}{*}{$Pr[i,j]$}} & \multicolumn{1}{c|}{\texttt{ADGTCTCA}}\\
	& \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{1}{c|}{\texttt{G\textcolor{red}{T}CADCTCA}} \\
	\hline \hline
	\diagbox{i}{j} & 1 & 2 & 1 & 2 & Hier beginnende Fragmente und Kommentare\\
	\hline
	0 & 0 & 0 & NIL & NIL & \\
	1 & " & " &  "  &  "  & \\
	2 & " & " &  "  &  "  & \\
	3 & " & " &  "  &  "  & \\
	4 & " & \textcolor{red}{2} &  "  & \textcolor{red}{$f_{4,2,2}$} & $F_3[5]$ wird nicht aktualisiert. \\
	5 & " & " &  "  &  "  & \\
	6 & " & " &  "  &  "  & $F_4[8]=\{f_{4,8,3},W(f=5,P(f)=\text{NIL})\}$\\
	7 & " & " &  "  &  "  & \\
	8 & " & " &  "  &  "  & \\
	\hline
\end{tabular}

Das gerade betrachtete Symbol ist das \texttt{T} an zweiter Stelle der zweiten Sequenz. Für $i=4$ wird $F_3[5]$ nicht aktualisiert. In $(4,2)$ startet zwar das Fragment ${\texttt{TC}}\choose{\texttt{TC}}$ mit Gewicht 2, aber an der Stelle ist bereits das Fragment ${\texttt{GCT}}\choose{\texttt{GTC}}$ mit höherem Präfixgewicht gesichert. Stattdessen wird aber in $F_4[8]$ das Fragment $f_{4,8,3}$ ${\texttt{TCA}}\choose{\texttt{TCA}}$ vorgemerkt. Dieses hat ein Präfixgewicht von 5 aufgrund von drei Übereinstimmungen und keiner Abweichung. Weil es kein Fragment mit positivem Gewicht gab, das vor $(6,2)$, dem Startpunkt von $f_{4,8,3}$, endete, wird kein Vorgänger gesetzt. 
		
Nachdem alle in Fragmente betrachtet wurden, die in der zweiten Spalte starten, werden die Einträge der Scores und Vorgänger aktualisiert. Aktuell sind diese noch leer. An der Stelle $(4,2)$ endet das Fragment  ${\texttt{GT}}\choose{\texttt{GT}}$ mit Präfixgewicht 2. Diesen Score speichern wir und übernehmen ihn auch für die unteren Tabelleneinträge der zweiten Spalte, weil kein dort endendes Fragment mit höherem Präfixgewicht gefunden wurde.

\addvbuffer[8pt]{\begin{tabular}{|r|cc|cc|l|}
	\hline
	& \multicolumn{2}{c|}{\multirow{2}{*}{$Sc[i,j]$}} & \multicolumn{2}{c|}{\multirow{2}{*}{$Pr[i,j]$}} & \multicolumn{1}{c|}{\texttt{ADGTCTCA}}\\
	& \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{1}{c|}{\texttt{GTCADCTC\textcolor{red}{A}}} \\
	\hline \hline
	\diagbox{i}{j} & 8 & 9 & 8 & 9 & Hier beginnende Fragmente und Kommentare \\
	\hline
	0 & 0 & 0 & NIL & NIL & \\
	1 & " & " &  "  &  "  & \\
	2 & 2 & 2 &  $f_{2,5,2}$  &  $f_{2,5,2}$  & \\
	3 & " & " &  "  &  "  & \\
	4 & 4 & 4 &  $f_{4,7,4}$  &  $f_{4,7,4}$  & \\
	5 & 7 & 7 &  $f_{5,8,5}$  &  $f_{5,8,5}$  & \\
	6 & " & " &  "  &  "  & \\
	7 & " & " &  "  &  "  & \\
	8 & " & \textcolor{red}{10} &  "  &  \textcolor{red}{$f_{9,8,4}$} & \\
	\hline
\end{tabular}}
\normalsize	

Für $(i,j) = (8,9)$ wird ein neues Fragment mit höchstem Präfixgewicht gefunden. Das zuvor gespeichert Fragment ${\texttt{ADGTC}}\choose{\texttt{ADCTC}}$ mit Gewicht 7 und ohne Vorgänger wird somit durch das Fragment ${\texttt{CTCA}}\choose{\texttt{CTCA}}$ mit Vorgänger ${\texttt{GT}}\choose{\texttt{GT}}$ ersetzt.


$f_0 = f_{\max} = Pr[8,9] = f_{9,8,4}$, $f_1 = P(f_0) = f_{4,2,2}$ und zuletzt $f_2 = P(f_1) = \text{NIL}$.
Das paarweise Alignment zwischen \texttt{ADGTCTCA} und \texttt{GTCADCTCA} sieht also wie folgt aus: \\
\vspace{-10pt}
\begin{center}
	\texttt{adGT---CTCA} \\
	\texttt{--GTcadCTCA} 
\end{center}
Hierbei wurden alignierte Stellen großgeschrieben und als Zuweisungsspalten genau übereinander gereiht. Der Score des Alignments beträgt 10, weil es zunächst ein kurzes Fragment mit zwei Übereinstimmungen gibt (Gewicht: $2\cdot 3+0\cdot(-1)-4 = 2$) und dann ein längeres mit vier Übereinstimmungen (Gewicht: $4\cdot3+0\cdot(-1)-4 = 8$). Dies sind die Ergebnisse aller paarweisen Alignments:
\vspace{8pt}

\addvbuffer[5pt]{\begin{tabular}{|r|c|c||r|c|c|}
	\hline
	Sequenzen & Alignments & Score & Sequenzen & Alignments & Score\\
	\hline
	1 & \texttt{adgTCTCA---} & \multirow{2}{*}{10} & 1 & \texttt{aDGTC---TCa} & \multirow{2}{*}{7}\\
	3 & \texttt{---TATCAdgg} & & 4 & \texttt{-DGTCadaTC-} & \\
	\hline
	2 & \texttt{-gTCADctca}  & \multirow{2}{*}{8} & 2 & \texttt{-GTCADCTCa} & \multirow{2}{*}{16}\\
	3 & \texttt{taTCADgg--}  & &4 & \texttt{dGTCADATC-} & \\
	\hline
	3 & \texttt{taTCADgg-}   & \multirow{2}{*}{8} & 1 & \texttt{adGT---CTCA}   & \multirow{2}{*}{10}  \\
	4 & \texttt{dgTCADatc}   &                    & 2 & \texttt{--GTcadCTCA} & \\
	\hline
\end{tabular}}

\section{Überlappgewichte}\label{sec:ueberlapp}

Beim multiplen Sequenzalignment werden normalerweise DNA- oder Proteinsequenzen miteinander verglichen, bei denen man davon ausgeht, dass sie einen gemeinsamen evolutionären Ursprung haben. Gibt es diesen, dann sind fast ausnahmslos auch gemeinsame Motive erhalten geblieben, die in vielen oder sogar allen Sequenzen vorkommen. Für ein biologisch korrektes Alignment ist es notwendig, diese zu finden und über möglichst viele Sequenzen hinweg einander zuzuweisen. Wurden diese verwandten Abschnitte bereits gefunden und miteinander aligniert, werden in der Regel auch die Zuweisungen zwischen diesen sogenannten Ankerpunkten besser \cite{mpps06}.

Es ist jedoch nicht immer leicht diese Motive zu finden, weil sie im Vergleich zu zufälligen Übereinstimmungen klein sein können. In dem Fall bekommen sie nur geringe Gewichte durch unsere Gewichtsfunktion und wenn wir am Ende von DIALIGN durch gieriges Auswählen der Fragmente das multiple Alignment bestimmen, kann es sein, dass sie nicht berücksichtigt werden, weil andere höher gewichtete Zuweisungen zu ihnen inkonsistent sind. Gierig bedeutet in diesem Fall, dass einmal gewählte Fragmente nicht mehr aus diesem entfernt werden können.

Um dieses Problem zu verhindern und Motive zu bevorzugen, die in möglichst vielen Sequenzen vorkommen, führen wir das Konzept der sogenannten \emph{Überlappgewichte} ein \cite{mdw96}. Betrachten wir dazu drei verschiedene Sequenzen $S_1$, $S_2$ und $S_3$ und zwei Fragmente $f^{1,2}$ und $f^{2,3}$ zwischen diesen. Es mag sein, dass die beiden Fragmente eine Überlappung in $S_2$ haben. In diesem Fall ist an dem Alignment ein drittes implizites Fragment $f^{1,3}$ zwischen $S_1$ und $S_3$ beteiligt, das auf ein gemeinsames Motiv zwischen allen drei Sequenzen hindeutet. Daher ist es angemessen die ursprünglichen Fragmente stärker zu gewichten, indem wir zu ihnen das Gewicht der Überlappung addieren.

\begin{equation}
	\tilde{w}\left(f^{1,2},f^{2,3}\right) \coloneqq w\left(f^{1,3}\right)
\end{equation}

Das Überlappgewicht eines Fragments mit sich selbst und zwischen zwei Fragmenten, die sich nicht überschneiden, definieren wir als 0.

Analog definieren wir das Überlappgewicht eines einzelnen Fragments als sein Gewicht addiert mit der Summe aller Überlappgewichte zwischen sich selbst und allen anderen Fragmenten:

\begin{equation}
	\hat{w}(f)\coloneqq w^*(f)+\sum_{e \in F}\tilde{w}(f,e)
\end{equation} 

Benutzt man Überlappgewichte, muss jedoch die Zusammensetzung der Sequenzen stärker beachtet werden. Liegt nämlich eine große Subfamilie von sehr ähnlichen Sequenzen vor, dann werden alle Fragmente zwischen einer Sequenz innerhalb und einer Sequenz außerhalb dieser Familie durch hohe Überlappgewichte gegenüber denen bevorzugt, die zwischen zwei Sequenzen berechnet wurden, die nicht aus der Sequenzfamilie stammen. \cite{vs93} stellen Methoden vor, die solchen Problemen vorbeugen. 
  
\subsection{Verbesserte Berechnung und Laufzeit}

Das Berechnen der Überlappgewichte geschieht bei DIALIGN durch einen naiven Vergleich aller Fragmente der paarweisen Alignments miteinander, bei dem sie auf Überschneidungen untersucht werden. Da es in den $\oh(n^2)$ Alignments zwischen $n$ Sequenzen jeweils bis zu $\oh(L)$ Fragmente gibt, kommt man so auf eine Gesamtlaufzeit von $\oh(n^4\cdot L^2)$ \cite{m99}.

Bei einer genaueren Betrachtung des Problems hat sich herausgestellt, dass für ein Fragment $f^{k,l}$ gar nicht alle Fragmente auf Überlappungen überprüft werden müssen, sondern nur die, an denen eine der beiden Sequenzen $S_k$ oder $S_l$ unseres Fragments beteiligt ist. Außerdem müssen wir nicht jedes Fragment eines anderen paarweisen Alignments betrachten, sondern können in sortierten Fragmentketten durch die Start- und Endpunkte sehr genau abschätzen, welche für Überlappungen in Frage kommen. Dazu benutzen wir den folgenden Satz:

\begin{satz}\label{satz:ueberlapp}
	Für eine Menge $S$ von $n$ Sequenzen und eine Menge $F$ von paarweisen Fragmenten zwischen diesen Sequenzen lassen sich in $\oh(n^3\cdot L)$ Zeit die Überlappgewichte berechnen.
\end{satz}

% save original \intextsep
\newlength{\oldintextsep}
\setlength{\oldintextsep}{\intextsep}

\setlength\intextsep{0pt}

\begin{wraptable}{l}{6cm}\label{tab:ueberlapp}
	\centering
	\begin{tabular}{|r|cccc|}
		\hline
		2 & $A_{2,1}$ & & & \\
		3 & $A_{3,1}$ & $A_{3,2}$ & & \\
		$\vdots$ & $\vdots$ & $\vdots$ & $\ddots$ & \\
		n & $A_{n,1}$ & $A_{n,2}$ & $\dots$ & $A_{n,n-1}$ \\
		\hline
		\diagbox[dir=NE]{i}{j} & 1 & 2 & $\dots$ & n-1 \\
		\hline
	\end{tabular}
	\caption{\unskip}
	Jeder Tabelleneintrag $A_{i,j}$ enthält Liste von Fragmenten
\end{wraptable}

\setlength{\intextsep}{\oldintextsep}

\begin{beweis}
	Zwischen den $n$ Sequenzen gibt es ${{n}\choose{2}} \in \oh(n^2)$ paarweise Alignments. Wir können o.B.d.A annehmen, dass diese in einer Tabelle $A$ vorliegen, wobei $A_{i,j}$ die Fragmente des paarweisen Alignments zwischen $S_i$ und $S_j$ in einer sortierten Liste enthält. Das liegt daran, dass der soeben gesehen Algorithmus \ref{alg:speichereffizient} die Fragmente mit seinem Backtrackingprozess sortiert ausgibt. 
	
	Betrachten wir ein Alignment zwischen den Sequenzen $S_i$ und $S_k$. Dann müssen wir für die Überlappgewichte nur die Einträge $A_{i,k}$ und $A_{l,j}$ mit $1 \leq k,l \leq n$ betrachten, denn es sind nur die Alignments relevant, bei denen eine der Sequenzen übereinstimmt. In einer vollständigen Tabelle sind das alle Listen, die in der selben Spalte oder Zeile stehen, also $\oh(n)$ viele.
	
	Seien $A_{i,k}$ und $A_{k,j}$ zwei Alignments, von denen wir die Überlappgewichte berechnen wollen. Dazu müssen wir die Überlappung zwischen allen Fragmenten in $S_k$ bestimmen. Dies können wir in linearer Zeit machen, indem wir parallel über die beiden sortierten Listen traversieren und anhand der Start- und Endpunkte in $S_k$ die impliziten Fragmente zwischen $S_i$ und $S_j$ bestimmen sowie die Gewichte der Fragmente aktualisieren. Dafür benötigen wir nur $\oh(L)$ Zeit, weil wir einmalig jedes Element der beiden Listen betrachten, es bis zu $\oh(L)$ Fragmente pro Alignment gibt und jedes von diesen in der Länge durch $l_{\max} \in \oh(1)$ beschränkt ist.
	Insgesamt haben wir also $\oh(n^2)$ paarweise Alignments für die mit jeweils $\oh(n)$ anderen Alignments Überlappgewichte berechnet werden müssen, was jeweils $\oh(L)$ Zeit kostet. Es folgt die Gesamtlaufzeit von $\oh(n^3\cdot L)$.
\end{beweis}

Genau genommen brauchen wir keine quadratische Tabelle, weil der Eintrag $A_{i,j}$ aus Symmetriegründen identisch zu $A_{j,i}$ ist. Auch die Diagonale können wir uns sparen, denn das Alignieren einer Sequenz mit sich selbst ist unnötig. Des Weiteren kann beim Algorithmus aus dem Beweis von Satz \ref{satz:ueberlapp} die Hälfte des Aufwands eingespart werden, denn die Überlappgewicht zwischen $A_{i,k}$ und $A_{k,j}$ müssen nicht doppelt berechnen werden, sondern können gleich zu den Gewichten in beiden Alignments addiert werden. Obgleich das nichts an der asymptotischen Laufzeit ändert, macht es in der Praxis einen Unterschied. 

\subsection{Beispiel Überlappgewichte}

Widmen wir uns der Berechnung von Überlappgewichten nach Satz \ref{satz:ueberlapp} in unserem Beispiel und betrachten dazu das Alignment zwischen den Sequenzen $S_1$ und $S_3$. Um das Gewicht zu aktualisieren, müssen wir alle Alignments auf Überlappungen überprüfen, in denen eine der beiden Sequenzen vorkommt. 

%\setlength\intextsep{2pt}
\begin{wraptable}{r}{6cm}\label{tab:ueberlapp_bsp}
	\centering
	\begin{tabular}{|r|ccc|}
		\hline
		2 & \cellcolor{red} $A_{2,1}$ & & \\
		3 & \cellcolor{yellow} $A_{3,1}$ & \cellcolor{red} $A_{3,2}$ & \\
		4 & \cellcolor{red} $A_{4,1}$ & $A_{4,2}$ & \cellcolor{red} $A_{4,3}$ \\
		\hline
		\diagbox[dir=NE]{i}{j} & 1 & 2 & 3 \\
		\hline
	\end{tabular}
	\caption{\unskip}
	Auf Überlappungen zu überprüfende Alignments
\end{wraptable}

%\setlength{\intextsep}{\oldintextsep}

Da unsere Tabelle \ref{tab:ueberlapp_bsp} nicht vollständig ist, reicht es nicht, die Einträge derselben Spalte und Zeile zu überprüfen, weil diese unter Umständen nicht vollständig ist. Stattdessen müssen wir alle Einträge in der ersten und dritten Spalte oder Zeile betrachten. Dann gehen wir alle Fragmente der Reihe nach durch und entscheiden anhand der Start- und Endpunkte in der gemeinsamen Sequenz, ob es Überschneidungen gibt. Falls ja, bestimmen wir diese und addieren das Gewicht zu dem unseres Fragments.

Rufen wir uns den bisherigen Stand der Scores der paarweisen Alignments in Erinnerung:

\addvbuffer[8pt]{\begin{tabular}{|r|c|c||r|c|c|}
	\hline
	Sequenzen & Alignments & Score & Sequenzen & Alignments & Score\\
	\hline
	1 & \texttt{adgTCTCA---} & \multirow{2}{*}{10} & 1 & \texttt{aDGTC---TCa} & \multirow{2}{*}{7}\\
	3 & \texttt{---TATCAdgg} & & 4 & \texttt{-DGTCadaTC-} & \\
	\hline
	2 & \texttt{-gTCADctca}  & \multirow{2}{*}{8} & 2 & \texttt{-GTCADCTCa} & \multirow{2}{*}{16}\\
	3 & \texttt{taTCADgg--}  & &4 & \texttt{dGTCADATC-} & \\
	\hline
	3 & \texttt{taTCADgg-}   & \multirow{2}{*}{8} & 1 & \texttt{adGT---CTCA}   & \multirow{2}{*}{10}  \\
	4 & \texttt{dgTCADatc}   &                    & 2 & \texttt{--GTcadCTCA} & \\
	\hline
\end{tabular}}

Wie wir sehen, enthält das von uns betrachtete Alignment nur das eine Fragment $f_{8,5,5}$ mit drei Übereinstimmungen und einer Abweichung. Als erstes überprüfen wir die Überlappung mit $A_{2,1}$. Beide haben den gemeinsamen Abschnitt \texttt{CTCA} in $S_1$, woraus sich das neue Fragment ${\texttt{CTCA}}\choose{\texttt{ATCA}}$ zwischen $S_2$ und $S_3$ ergibt. Dieses hat drei Übereinstimmungen, eine Abweichung und somit ein Gewicht von 8. In der Folge addieren wir diese Zahl zum Gewicht von $f_{8,5,5}^{1,3}$ und zu dem von $f_{8,9,4}^{1,2}$. Wenn wir diese Berechnungen auch mit und zwischen allen anderen Alignments durchführen, kommen wir zu den folgenden Überlappgewichten:

\addvbuffer[8pt]{\begin{tabular}{|r|c|c||r|c|c||r|c|c|}
	\hline
	Seq. & Frag. & Ü-Gew. & Seq. & Frag. & Ü-Gew. & Seq. & Frag. & Ü-Gew.\\
	\hline
	2 & \texttt{GTCADCTC} & \multirow{2}{*}{69} & 1 & \texttt{TCTCA} & \multirow{2}{*}{41} & 1 & \texttt{GT} &\multirow{2}{*}{20} \\
	4 & \texttt{GTCADATC} &                     & 3 & \texttt{TATCA} &                     & 2 & \texttt{GT} & \\
	3 & \texttt{TCAD} & \multirow{2}{*}{47} & 1 & \texttt{CTCA} & \multirow{2}{*}{34} & 1 & \texttt{TC} & \multirow{2}{*}{20} \\
	4 & \texttt{TCAD} &                     & 2 & \texttt{CTCA} &                          & 4 & \texttt{TC} & \\
	2 & \texttt{TCAD} & \multirow{2}{*}{44} & 1 & \texttt{DGTC} & \multirow{2}{*}{31} &    &   & \\
    3 & \texttt{TCAD} &                     & 4 & \texttt{DGTC} &                     &    &   & \\
    \hline
\end{tabular}}

Da wir im nächsten Schritt die Fragmente für unser multiples Alignment basierend auf ihren Gewichten gierig auswählen, wurden die Abschnitte bereits sortiert. Ein Algorithmus wird als gierig bezeichnet, wenn er eine Entscheidung lokal optimal trifft und danach nicht wieder ändert. In unserem Fall bedeutet das, dass die Fragmente mit höheren Gewichten früher gewählt werden und selbst dann nicht wieder aus unserem multiplen Alignment entfernt werden, wenn sie durch Inkonsistenzen verhindern, dass andere, zusammen möglicherweise bessere Fragmente gewählt werden können. Durch diese radikale Vorgehensweise haben gierige Algorithmen oft gute Laufzeiten, liefern aber nicht immer die bestmöglichen Ergebnisse.

\section{Konsistenz}

Die nach ihrem Gewicht sortierten Fragmente möchten wir der Reihe nach in unser multiples Alignment einfügen, vorausgesetzt, das gerade gewählte ist nicht inkonsistent zu den zuvor integrierten. Wenn wir uns an den Abschnitt über die theoretischen Grundlagen \ref{sec:theo} erinnern, dann hatten wir formal definiert, dass eine Relation $\mathcal{R}$ genau dann ein Alignment ist, wenn $\preceq_{\mathcal{R}}=(\preceq \cup\: \mathcal{R})_t$ die natürliche Ordnung auf jeder Sequenz erhält, also $x \preceq_{\mathcal{R}} y \implies x \preceq y$ für alle $x,y \in S_i \forall 1\leq i \leq n$ gilt.

Mengentheoretisch können wir uns unser Vorgehen so vorstellen, dass wir eine Menge von Fragmenten $f_1,\dots, f_k$ haben, die wir der Reihe nach in unser wachsendes multiples Alignment hinzufügen wollen, vorausgesetzt sie sind konsistent zueinander. Die hinzugefügten Fragmente bilden dabei für $i = 2, \dots, k$ eine aufsteigende Kette von Mengen $A_1 \subset \dots \subset A_k$:

\begin{equation}
\begin{split}
	\mathcal{A}_1 &= f_1 \\
	\mathcal{A}_i &= 
		\begin{cases}
			(\mathcal{A}_{i-1} \cup f_i), & \text{falls $f_i$ konsistent ist zu $A_{i-1}$} \\
			A_{i-1}, & \text{sonst} 
		\end{cases}
\end{split}
\end{equation} 

Das finale Alignment $\mathcal{A}$ ist dann genau das resultierende größte Alignment $\mathcal{A}_k$. Ziel ist es jetzt eine Möglichkeit zu finden, möglichst effizient zu bestimmen, ob ein Fragment konsistent zum bisherigen Alignment ist. Wir führen dazu zunächst folgende Definition ein:

\begin{definition}[Konsistenzgrenze\cite{am00}]
	Gegeben seien ein Alignment $\mathcal{A}$ auf einer Menge von Sequenzen $S$ mit Stellenraum $\mathcal{S}$. Dann existieren für eine Stelle $s \in \mathcal{S}$ und eine Sequenz $S_i \in S$ eine kleinste und größte Stelle in $S_i$, die mit $s$ alignierbar ist, ohne zu Inkonsistenzen zu führen.
	\begin{equation}
	\begin{split}
	\underline{b}_\mathcal{A}(s,i) &= \min(p: (s,[i,p])\: \text{ist konsistent zu} \mathcal{A}) \\
	\overline{b}_\mathcal{A}(s,i) &= \max(p: (s,[i,p])\: \text{ist konsistent zu} \mathcal{A})
	\end{split} 
	\end{equation}
	Diese beiden Stellen nennen wir die \emph{Konsistenzgrenzen} von $s$ in $S_i$. 
\end{definition}

In der ersten Version von DIALIGN wurden diese Konsistenzgrenzen für alle Stellen gespeichert und jedes Mal aktualisiert, wenn eine neue Sequenz zum multiplen Alignment hinzugefügt wurde \cite{mdw96}. Das verursachte Speicherplatzbedarf in der Größenordnung $\Theta(n^2\cdot L)$, denn für jede Stelle aus jeder Sequenz ($\Theta(n\cdot L)$ viele) mussten die Konsistenzgrenzen für jede der $n$ Sequenzen gespeichert werden. Noch schlechter ist die Laufzeit bei diesem naiven Ansatz, denn im schlimmsten Fall gibt es $\oh(n^2\cdot L)$ Fragmente, die der Reihe nach zum Alignment hinzugefügt werden, für die jeweils alle $\theta(n\cdot L)$ Konsistenzgrenzen überprüft und gegebenenfalls angepasst werden müssen. Es folgt eine Laufzeit von $\oh(n^4\cdot L^2)$, die auch die Gesamtlaufzeit des DIALIGN-Verfahrens dominiert hat \cite{m99}. 

Weil die Laufzeit im Vergleich zu anderen Alignmentverfahren, wie beispielsweise Clustal W, sehr schlecht war, entschied man sich den von \cite{a97} veröffentlichten und in der GABIOS-LIB (Greedy Alignment of BIOlogical Sequences LIBrary) implementierten besseren Ansatz auch in DIALIGN	einzubauen. Wie wir im Folgenden sehen werden, ist es möglich das Problem der Konsistenzgrenzen durch den Erhalt der transitiven Hülle eines Graphen abzubilden. Dadurch kann man die Fragmente deutlich effizienter der Reihe nach in unser multiples Alignment einfügen, wodurch sich die praktische Laufzeit in etwa um den Faktor zehn verbessern lässt \cite{am00}. 

\begin{definition}[Transitivitätsgrenzen\cite{am00}]
	Die sogenannten \emph{Transitivitätsgrenzen} erlauben es uns die Konsistenzgrenzen als graphtheoretisches Problem zu verstehen. Wir definieren zu unserer Stelle $s$ die \emph{Vorgängergrenze} $\operatorname{Pred}_{\mathcal{A}}(s,i)$ als die Stelle $y$ aus der Sequenz $S_i$, die von allen Stellen mit $y \preceq_{\mathcal{A}} s$ am weitesten rechts steht. Analog wird die \emph{Nachfolgergrenze} $\operatorname{Succ}_{\mathcal{A}}(s,i)$ als am weitesten links stehende Stelle mit $s \preceq_{\mathcal{A}} y$ festgelegt.
	\begin{equation}
	\begin{split}
		\operatorname{\operatorname{Pred}}_{\mathcal{A}}(s,i) &= \max(p: [i,p] \preceq_{\mathcal{A}} s) \\
		\operatorname{\operatorname{Succ}}_{\mathcal{A}}(s,i) &= \min(p: s \preceq_{\mathcal{A}} [i,p])
	\end{split}
	\end{equation}
\end{definition}

Zwischen Transitivitäts- und Konsistenzgrenzen herrscht ein direkter Zusammenhang. Ist eine Stelle $s \in \mathcal{S}$ bereits mit einer anderen Stelle aus der Sequenz $S_i \in S$ aligniert, dann gibt es zwischen allen vier Grenzen keinen Unterschied und es gilt:

\begin{equation}
	\operatorname{\operatorname{Pred}}_{\mathcal{A}}(s,i) = \operatorname{\operatorname{Succ}}_{\mathcal{A}}(s,i) = \underline{b}_\mathcal{A}(s,i) = \overline{b}_\mathcal{A}(s,i) = p
\end{equation}

Gibt es hingegen keine Stelle in $S_i$, die bereits $s$ zugewiesen wurde, dann unterscheiden sich $\operatorname{\operatorname{Pred}}_{\mathcal{A}}(s,i)$ und $\underline{b}_\mathcal{A}(s,i)$, sowie $\operatorname{Succ}_{\mathcal{A}}(s,i)$ und $\overline{b}_\mathcal{A}(s,i)$ jeweils nur um genau eine Position.

\begin{equation}
\begin{split}
	\operatorname{Pred}_{\mathcal{A}}(s,i) &= \underline{b}_\mathcal{A}(s,i) - 1\\
	\operatorname{Succ}_{\mathcal{A}}(s,i) &= \overline{b}_\mathcal{A}(s,i) + 1
\end{split}
\end{equation}

Man kann also sagen, dass Transitivitätsgrenzen und Konsistenzgrenzen äquivalent sind, denn wenn man das aktuelle Alignment kennt, kann man aus dem einen das jeweils andere bestimmen. Daraus folgt auch, dass man mit beiden darstellen kann, ob zwei Stellen miteinander alignierbar sind oder nicht. \improvement{Beispiel aus Paper ersetzen für Äq. Trans-und Konsgrenzen}

\scriptsize
\begin{wrapfigure}{r}{8cm}
\begin{framed}\raggedleft
	\begin{tikzcd}[/tikz/commutative diagrams/sep=scriptsize]
	& s_1 \arrow[r] & s_2 \arrow[r] & s_3 \arrow[r] & s_4 &  \\
	s'_1 \arrow[r] & s'_2 \arrow[r] & s_3' \arrow[r] & s_4' \arrow[r] & s_5' \arrow[r] & s_6' \\
	s_1'' \arrow[r] & s_2'' \arrow[r] & s_3'' \arrow[r] & s_4'' \arrow[r] & s_5'' & 
	\end{tikzcd}
	\caption{Graph dreier Sequenzen mit den durch sie induzierten Pfaden}\label{abb:SSDP}
\end{framed}
\end{wrapfigure}
\normalsize

In den nächsten beiden Abschnitten wird eine Technik vorgestellt, mit der man in konstanter Zeit entscheiden kann, ob zwei Stellen miteinander alignierbar sind, sowie einen inkrementellen Algorithmus, der es uns in angemessener Zeit erlaubt, ein Alignment zwischen zwei Stellen in unser multiples Alignment hinzuzufügen. Das wird erreicht, indem wir unseren Stellenraum $\mathcal{S}$ als gerichteten Graph auffassen, in dem die einzelnen Stellen Knoten entsprechen und jede Sequenz einen Pfad durch den Graphen darstellt. Jedes Mal, wenn eine Zuweisung zwischen zwei Stellen ausgewählt wird, fügen wir eine neue Kante zu unserem Graphen hinzu. Ziel ist es in jedem Schritt unseres Verfahrens die transitive Hülle des Graphen zu kennen, denn mit ihr lässt sich entscheiden, ob das Fragment, das wir gerade wählen wollen, konsistent zum bisherigen Alignment ist oder nicht. Als erstes wird der Algorithmus auf allgemeinen Graphen vorgestellt, bevor wir zeigen, wir wie ihn im Kontext des Multiple-Sequence-Alignment-Problems anwenden können.

\subsection{Berechnung der transitiven Hülle eines gerichteten Graphen}

Sei $G=(V,E)$ ein gerichteter Graph mit einer Menge Knoten $V$ und einer Menge an Kanten $E$ zwischen diesen Knoten. Unter einem Pfad $P$ auf $G$ verstehen wir ein $k$-Tupel von Knoten $(v_1, \dots, v_k)$, sodass $(v_i, v_{i+1}) \in E$ für alle $1 \leq i \leq k-1$, also eine Folge von Knoten, die alle direkt durch Kanten miteinander verbunden sind. Dabei nennen wir den Index eines Knotens innerhalb dieses Tupels seine Position ($\operatorname{pos}(x)$ für $x \in P$).

Die transitive Hülle eines Graphen $G = (V,E)$ ist der Graph $G^*=(V,E^*)$, in dem es eine Kante $(u,v) \in E^*$ gibt, falls es in $G$ einen Pfad von $u$ nach $v$ gibt. Für jedes $(u,v) \in E^*$ heißt $u$ \emph{Vorgänger} von $v$ und $v$ \emph{Nachfolger} von $u$. Diese Vorgänger und Nachfolger sind nicht mit den gleichnamigen Definitionen aus dem Abschnitt \ref{subsec:psa} über die paarweisen Alignments zu verwechseln. Zunächst definieren wir einige Variablen für den Kontext dieses Abschnitts: die Anzahl der Knoten $|V| = \nu$, die der Kanten $|E| = \mu$, die der Kanten in der transitiven Hülle $|E^*| = \mu^*$ und die Anzahl Kanten $\mu_0$, die sich vor dem Hinzufügen von neuen Verbindungen in unserem Graphen befinden. Zuletzt benötigen wir noch $\mu_p$ für die Anzahl der Kanten über die ein Pfad $P$ traversiert.

\begin{definition}[Spanning Set of Disjoint Paths (SSDP) \cite{a97}]
Sei im Folgenden eine $\mathcal{P} = \{P_1, \dots, P_k\}$ von Pfaden auf einem Graphen $G=(V,E)$ gegeben, für die gilt, dass jeder Knoten aus $V$ in genau einem der Pfade vorkommt. Eine solche Menge nennen wir SSDP (\emph{Spanning Set of Disjoint Paths}), also eine Menge von disjunkten Pfaden, die den ganzen Graphen aufspannen. 
\end{definition}

In dem Kontext des Multiple-Sequence-Alignment-Problems lässt sich ein solches SSDP leicht konstruieren, indem für jede Sequenz ein Pfad konstruiert wird, bei dem jedes Symbol mit dem direkten Nachfolger der gleichen Sequenz über eine Kante verbunden ist. Ein Beispiel für drei Sequenzen ist in Abbildung \ref{abb:SSDP} zu sehen.

\begin{satz}[{\cite{a97}}]
	\label{satz:ssdp}
	Es sei ein SSDP mit $k$ disjunkten Pfaden gegeben. Dann lässt sich die transitive Hülle $G^*$ unseres Graphen in $\oh(k^2\cdot(\mu - \mu_0) + \nu \cdot \min\{\nu, (\mu - \mu_p)\})$ Zeit und mit $\oh(k\cdot \nu)$ Speicherplatz erhalten, nachdem Kanten zu ihm hinzugefügt wurden.
\end{satz}

Bevor wir diesen Satz beweisen können, brauchen wir einige Vorüberlegungen. Für einen Knoten $x$ sei $P(x)$ das Tupel, das in jedem Eintrag $P(x)[i]$ für $1\leq i \leq k$ die Anzahl an Vorgängern von $x$ im Pfad $P_i$ angibt. In anderen Worten ist $P(x)[i]$ die maximale Position eines Vorgängers in $P_i$. Analog definieren wir $S(x)$, wobei  $S(x)[i]$ der minimale Nachfolger von $x$ in $S_i$ ist. In Abschnitt \ref{subsec:trans_hull} werden wir zeigen, dass $S(x)$ und $P(x)$ genau den Transitivitätsgrenzen aus dem Kontext von Alignments entsprechen und wir verwenden diese Begriffe synonym. Gibt es keine Vorgänger oder Nachfolger, setzen wir diese Werte auf 0 beziehungsweise auf $|P_i|+1|$ im Fall des Pfads $P_i$.

\setlength{\intextsep}{0pt}
\scriptsize
\begin{wrapfigure}{r}{7cm}
\begin{framed}\centering
	\begin{tikzcd}[/tikz/commutative diagrams/sep=scriptsize]
	{} \arrow[rrr] &  &  & y \arrow[r] & \dots \arrow[r] & u \arrow[r] & {} \\
	{} \arrow[rr] &  & x \arrow[rrrr] \arrow[ru, red] &  &  &  & {} \\
	{} \arrow[r] & v \arrow[ru] \arrow[rrrrr] &  &  &  &  & {} \\
	{} \arrow[r] & w \arrow[u] \arrow[rrrrr] &  &  &  &  & {}
	\end{tikzcd}
	\caption{Füge $(x,y)$ ein.}
	\label{abb:kante_eing}
\end{framed}
\end{wrapfigure}
\normalsize
\setlength{\intextsep}{\oldintextsep}

Für Elemente $x$ und $y$ auf zwei Pfaden $P_i$ und $P_j$ kann man sich leicht überlegen, dass aus $\operatorname{pos}(x) \leq P(y)[i]$ folgt, dass $(x,y)\in E^*$ gilt. Die gleiche Aussage folgt aus $\operatorname{pos}(y) \geq S(x)[j]$. Wie man sieht, ist es also möglich die transitive Hülle auf $\oh(k \cdot \nu)$ Speicherplatz zu sichern, wenn ein SSDP mit $k$ Pfaden vorliegt. Das kann signifikant weniger sein als die $\oh(\nu^2)$ Kanten, die im naiven Ansatz gespeichert werden müssen.

\improvement{Beispiel S(x) und P(x)}

Als nächstes führen wir eine Funktion \textrm{EdgeAddition} ein, die die Transitivitätsgrenzen nach dem Hinzufügen einer einzelnen Kante aktualisiert. Wollen wir unseren Graphen um mehr als eine Kante ergänzen, fügen wir sie der Reihe nach hinzu und rufen sukzessive die Funktion auf. Das ist beispielsweise der Fall, wenn wir ein längeres Fragment zu unserem Alignment hinzufügen. Im Folgenden seien die transitive Hülle und die Transitivitätsgrenzen unseres ursprünglichen Graphen gegeben. Sei außerdem $(x,y)$ die Kante, die wir ergänzen. Nun wählen wir einen beliebigen Knoten $u \in V$, dessen Transitivitätsgrenzen wir aktualisieren. $P(u)$ und $S(u)$ bezeichnen dabei die Grenzen vor und $P'(u)$ und $'S(u)$ die Grenzen nach dem Hinzufügen. Als erstes kann man sich überlegen, dass die Vorgängergrenzen ausschließlich wachsen können, während die Nachfolgergrenzen höchstens kleiner werden. Des Weiteren kann sich durch eine Kante von $x$ nach $y$ nur die Vorgängergrenzen von $u$ in einer Sequenz verändern, wenn $u$ ein Nachfolger von $y$ war und die Nachfolgergrenze, wenn $u$ ein Vorgänger von $x$ war. Im ersten Fall wählt wird das Maximum der beiden möglichen Werte ausgewählt und im letzteren das Minimum.  

Mit diesen zwei Formeln können wir für ein $u \in P_i$ und jeden Pfad $P_j$ die neuen Transitivitätsgrenzen von $u$ bestimmen:

\begin{equation}
	P'(u)[j] = \begin{cases}
			\max\{P(u)[j], P(x)[j]\}, & \text{falls $u$ Nachfolger von $y$ war} \\
			P(u)[j], & \text{sonst}
		\end{cases}
\end{equation} 

\begin{equation}
	S'(u)[j] = \begin{cases}
			\min\{S(u)[j], S(y)[j]\}, & \text{falls $u$ Vorgänger von $x$ war} \\
			S(u)[j], & \text{sonst}
		\end{cases}
\end{equation}

Falls bereits ein Pfad zwischen $x$ und $y$ existiert, wissen wir, dass sich die transitive Hülle nicht verändert und dass wir die Transitivitätsgrenzen dementsprechend nicht anpassen müssen. Die obigen Beobachtungen können wir jetzt direkt in den Algorithmus \ref{alg:edgeaddition} \textrm{EdgeAddition} münden lassen, indem wir über alle Paarkombinationen von Pfaden iterieren und dabei für jeden in Frage kommenden Knoten im jeweiligen Pfad die obigen Formeln anwenden. Wir wählen dabei die Knoten für die Nachfolgergrenze in absteigender und die für die Vorgängergrenze in aufsteigender Reihenfolge. Weil wir wissen, dass die Nachfolgergrenze immer nur sinken kann und wir die in Frage kommenden Knoten sortiert betrachten, folgt, dass der aktuelle Schleifendurchlauf abgebrochen werden kann, wenn die Nachfolgergrenze kleiner oder genauso groß ist wie die von $y$. In diesem Fall würde sie nicht mehr aktualisiert werden und wir können uns die Berechnung sparen. Für die Vorgängergrenzen gehen wir analog vor. Jetzt haben sind wir in der Lage Satz \ref{satz:ssdp} zu beweisen.

\begin{algorithm}
	\caption{Algorithmus EdgeAddition, der die transitive Hülle eines Graphen mit SSDP nach dem Hinzufügen einer Kante aktualisiert.}
	\label{alg:edgeaddition}
	\begin{algorithmic}[1]
		\Require Gerichteter Graph $G$ mit SSDP $P_1, \dots, P_k$
		\Procedure{EdgeAddition}{$x,y$}
			\If{$(x,y) \notin E^*$}\label{alg:pathIf}
				\NFor{Pfad $P_i$}
					\NFor{Pfad $P_j$}
						\NFor{$u$ in $P_i$ startend von $P(x)[i]$ in absteigender Reihenfolge}
							\If{$S(u)[j] > S(y)[j]$} \label{alg:succ_if}
								\State{$S(u)[j]	\gets S(y)[j]$}\Comment{\small{aktualisiere Nachfolgergrenze}}\label{algl:succ}
							\Else
								\State{breche den aktuellen Schleifendurchlauf für $u$ ab}						
							\EndIf
				\NFor{Pfad $P_i$}
					\NFor{Pfad $P_j$}
						\NFor{$u$ in $P_i$ startend von $S(y)[i]$ in aufsteigender Reihenfolge}
							\If{$P(u)[j] < P(x)[j]$} \label{alg:pred_if}
								\State{$P(u)[j]	\gets P(x)[j]$}\Comment{\small{aktualisiere Vorgängergrenze}}\label{algl:pred}
							\Else
								\State{breche den aktuellen Schleifendurchlauf für $u$ ab}						
							\EndIf
			\EndIf
		\EndProcedure
	\end{algorithmic}
\end{algorithm}
%\caption{Algorithmus zum Aktualisieren der transitiven Hülle, nachdem eine Kante $(x,y)$ zum Graphen hinzugefügt wurde}

\begin{beweis}
	Im schlimmsten Fall werden die ineinander verschachtelten Schleifen je $\oh(k^2 \cdot (\mu - \mu_0))$-mal durchlaufen. Das ergibt sich aus der Kombination aller $\oh(k^2)$ Paare von Pfaden und, dass nur für die ursprünglichen Kanten $\mu_0$ im Graphen und die sie verbindenden Knoten die if-Bedingungen in Zeile \ref{alg:succ_if} und \ref{alg:pred_if} nicht erfüllt sein könnten.
	
	Bei genauerer Betrachtung wie oft es wirklich zu einer Aktualisierung der Transitivitätsgrenzen kommen kann, stellen wir fest, dass diese je nach Graph möglicherweise viel geringer ist als oben abgeschätzt. Um Redundanz zu vermeiden, betrachten wir hier nur die Vorgängergrenzen. Für Nachfolgergrenzen gilt aus Symmetriegründen genau das selbe. Die einzige Situation, in der ein Knoten $v \in V$ die Vorgängergrenzen eines anderen Knotens $u$ verändern kann, ist, wenn $v$ ein Vorgänger von $x$, aber kein Vorgänger von $u$ ist, bevor die Kante $(x,y)$ hinzugefügt wird (vgl. beispielsweise Abbildung \ref{abb:kante_eing}). Gleichzeitig muss $u$ ein Nachfolger von $y$ sein, da die Pfade $\mathcal{P}$ disjunkt sind. Also folgt, dass die Vorgängergrenzen von $u$ höchstens $\nu$-mal angepasst werden und es insgesamt nicht mehr als $\nu^2$ Anpassungen gibt. 

	Sei $(w,v)$ eine Kante unseres Graphen, die auf keinem unserer Pfade aus dem SSDP liegt. Diese Kante kann die Vorgängergrenze von $u$ in der Methode \textrm{EdgeAddition} nur dann verändern, wenn $v$ ein Vorgänger von $x$ ist, aber kein Vorgänger von $u$, bevor die Kante $(x,y)$ hinzugefügt wird. Nach dieser Aktualisierung kann die Kante $(w,v)$ die Transitivitätsgrenzen von $u$ nie wieder anpassen. Das bedeutet, dass dies für einen Knoten $u$ höchstens so oft passiert, wie es Kanten gibt, die in keinem Pfad des SSDP liegen. Das sind genau $\oh(\mu - \mu_p)$ und es folgt, dass insgesamt höchstens $\nu \cdot (\mu - \mu_p)$ solcher Aktualisierungen vorgenommen werden.
	
	Da sowohl die Anzahl dieser Knoten, als auch der Kanten im Graph die Anzahl der Aktualisierungen beschränken, kann es nicht zu mehr Aktualisierungen als dem Minimum dieser beiden Werte kommen, also $\oh(\nu \cdot \min\{\nu, \mu - \mu_p\})$. Fasst man alles zusammen, so folgt die behauptete Laufzeit von $\oh(k^2 \cdot (\mu - \mu_0) + \nu \cdot \min\{\nu, \mu - \mu_p\})$.
\end{beweis}

\subsection{Konsistenzgrenzen durch Berechnung der transitiven Hülle}\label{subsec:trans_hull}

Jetzt möchten wir den allgemeinen graphtheoretischen Ansatz auf unser multiples Alignment anwenden. Zunächst übertragen wir unsere Sequenzen $S = \{S_1, \dots, S_n\}$ auf einen Graphen $G=(V,E)$ mit SSDP. Hierbei ist jede Stelle aus $\mathcal{S}$ ein Knoten. Zwischen zwei Knoten $u$ und $v$ gibt es genau dann eine Kante $(u,v) \in E$, wenn die dazugehörigen Stellen aus der selben Sequenz kommen und direkt aufeinanderfolgen. Dadurch ergibt sich automatisch unser SSDP mit $n$ Pfaden, denn jede Sequenz liefert genau einen solchen und da jeder Knoten mit genau einer Sequenz assoziiert ist, spannen diese Pfade auch den ganzen Graphen. Den Pfad einer Sequenz $S_i$ bezeichnen wir als $P_i$. Jedes Mal, wenn wir in unserem Alignment von $S$ zwei Stellen $(i,p)$ und $(j,q)$ miteinander alignieren, fügen wir je eine Kante in beide Richtungen zwischen den dazugehörigen Knoten im Graphen ein.
	
\begin{definition}[Alignmentgraph\cite{a97}]
	Den soeben definierten Graphen bezeichnen wir als \emph{Alignmentgraphen}.
\end{definition}

Gibt es zwischen $u$ und $v$ Pfade in beiden Richtungen ($(u,v)$ und $(v,u) \in E^*$), dann symbolisieren wir dies durch $u \rightleftharpoons^{*} v$. Wir sagen dann, dass $u$ und $v$ miteinander \emph{koinzidieren}. 

Wie bereits angedeutet ist es bei einem Alignment möglich Lücken so in die Sequenzen einzufügen, dass genau die einander zugewiesenen Symbole übereinander stehen. Diese Tupel von Stellen nennen wir \emph{Zuweisungsspalten} und zu ihnen zählen wir nur die miteinander alignierten Symbole. Andere, nicht mit den gerade betrachteten Stellen alignierte Symbole, gehören nicht zur Zuweisungsspalte, selbst wenn sie in der selben Spalte der Sequenzen stehen, nachdem man Lücken eingefügt hat.\improvement{Beispiel} Eine Menge von miteinander koinzidierenden Knoten nennen wir einen \emph{Anker}, wenn es keine weiteren Knoten gibt, die mit Knoten aus dieser Menge koinzidieren.

\begin{definition}[Regularität\cite{a97}]
	Wir nennen einen Alignmentgraphen mit seinem SSDP $(G,P)$ auf einer Menge von Sequenzen $S$ genau dann \emph{regulär}, wenn die zugrundeliegende Relation ein Alignment ist. 
\end{definition}

\begin{lemma}[{\cite{a97}}]
	Sei $G$ ein Alignmentgraph und $P$ das ihm zugewiesene SSDP. $(G,P)$ ist genau dann regulär, wenn jeder dazugehörige Anker höchstens einen Knoten aus jedem Pfad von $P$ hat. In diesem Fall entspricht ein Anker genau einer Zuweisungsspalte.
\end{lemma}

\begin{beweis}
	\bewhin Angenommen, jeder Anker unseres Alignmentgraphen $G$ enthält höchstens einen Knoten aus jedem Pfad in $P$. Betrachten wir jetzt die Halbordnung $\preceq^{*}$, bei der für zwei Anker $a$ und $b$ $\:a \preceq^{*} b$ genau dann gilt, wenn zwischen zwei Knoten $u \in a$ und $v \in b$ ein Pfad in $G$ existiert. Da keiner der Anker von $G$ zwei oder mehr verschiedene Knoten vom selben Pfad aus $P$ enthält und da auf ihnen unsere Halbordnung $\preceq^{*}$ existiert, können wir anhand dieser die Anker immer in Zuweisungsspalten übereinander schreiben und erhalten somit ein Alignment. $\preceq^{*}$ entspricht dabei genau der topologischen Sortierung auf $G$. Da auf $(G,P)$ ein Alignment existiert, ist es regulär.
	
	\bewrueck Sei $G$ regulär. Dann ist die zugehörige Relation zwischen Knoten per Definition ein Alignment und für dieses können wir die Zuweisungen in Zuweisungsspalten untereinander schreiben. Somit sind alle Anker Zuweisungsspalten und keiner enthält zwei oder mehr Knoten aus derselben Sequenz.
\end{beweis}

Für den Rest des Abschnitts nehmen wir an, dass unser Alignmentgraph $G$ mit SSDP regulär ist. Ziel ist es jetzt zu überprüfen, ob er auch regulär bleibt, nachdem eine Zuweisung zwischen zwei Stellen $s$ und $t$ und die korrespondierenden Kanten in $G$ hinzugefügt wurde. Falls ja, dann nennen wir $s$ und $t$ \emph{alignierbar}, einen Begriff, den wir zuvor bereits informell genutzt haben.

\begin{lemma}[{\cite{a97}}]
	Zwei Stellen $s$ und $t$ mit den korrespondierenden Knoten $u$ und $v$ sind genau dann alignierbar, wenn eine der folgenden zwei Bedingungen eintritt:
	
	(1) Es existiert kein Pfad zwischen $u$ und $v$, das heißt $(u,v),(v,u) \notin E^{*}$,
	
	(2) $u$ und $v$ koinzidieren miteinander, also $u \rightleftharpoons^{*} v$.
\end{lemma}

\begin{beweis}
	Sei $G'$ der Graph nach dem Hinzufügen der Kanten $(u,v)$ und $(v,u)$. Wir müssen zeigen, dass $(G',P)$ genau dann regulär ist, wenn eine der beiden obigen Bedingungen eintritt.
	
	\bewhin (1) Angenommen, es existiert kein Pfad zwischen $u$ und $v$ und seien $a_1$ und $a_2$ die dazugehörigen Anker der beiden Knoten. Es sei $a = a_1 \cup a_2$ der neue Anker von $G'$ nach dem Hinzufügen von $(u,v)$. Dann kann $a$ nicht mehrere Knoten vom selben Pfad aus $P$ enthalten, weil es sonst bereits einen Pfad von $u$ nach $v$ oder von $v$ nach $u$ gegeben hätte und die Vorbedingung verletzt gewesen wäre. Das liegt daran, dass es zwischen diesen Knoten vom selben Pfad eine Kante gegeben haben müsste, über die dann auch eine einseitige Verbindung zwischen $u$ und $v$ bestünde. Weil alle anderen Anker von $G$ nicht verändert werden, folgt, dass $G'$ regulär ist.
	
	(2) Es gelte $u \rightleftharpoons^{*} v$ für $G$. Dann sind die Anker von $G'$ die selben wie von $G$, denn $u$ und $v$ haben bereits zuvor koinzidiert. Also ist auch $G'$ regulär, da $G$ es war.
	
	\bewrueck Die Rückrichtung des Beweises führen wir per Kontrapositionsbeweis. Es sei also nur eine einseitige Verbindung zwischen $u$ und $v$ gegeben. O.B.d.A. nehmen wir an, dass $(u,v) \in E^{*}$ und $(v,u) \notin E^{*}$. Da $G$ ein Alignmentgraph ist, gibt es zwangsläufig zwei Knoten $x$ und $y$, die auf dem selben Pfad $P_i$ aus $\mathcal{P}$ liegen und über die der Pfad von $u$ nach $v$ läuft. Gäbe es keinen solchen Knoten, dann wäre die Vorbedingung nicht erfüllt, weil nur Kanten auf den Pfaden $\mathcal{P}$ keine antiparallele Kante haben. Nach dem Hinzufügen der Kante $(u,v)$ mit dem resultierenden Alignmentgraphen $G'$ gäbe es dann einen Pfad von $y$ nach $x$, denn $(y,v), (v,u), (u,x) \in E^{*}$. Daraus folgt dann $x \rightleftharpoons^{*} y$, also eine Koinzidenz zwischen $x$ und $y$ vom selben Pfad $P_i$, wodurch die Regularität von $G'$ verletzt ist.
\end{beweis}

Sei ein Symbol $s$ aus der Sequenz $S_i$ mit korrespondierendem Knoten $v$ aus dem Alignmentgraphen gegeben. Dann sind genau die Symbole einer zweiten Sequenz $S_j$ mit $s$ alignierbar, die zwischen $P(v)[j] + 1$ und $S(v)[j] - 1$ liegen. Das liegt an einer Beobachtung, die wir bereits zu Beginn dieses Unterabschnitts gemacht haben: \enquote{Für Elemente $x$ und $y$ auf zwei Pfaden $P_i$ und $P_j$ kann man sich leicht überlegen, dass aus $\operatorname{pos}(x) \leq P(y)[i]$ folgt, dass $(x,y)\in E^*$ gilt. Die gleiche Aussage folgt aus $\operatorname{pos}(y) \geq S(x)[j]$.} Haben wir jetzt einen Knoten $u$ auf $P_j$ mit $P(v)[j] +1 \leq u \leq S(v)[j] - 1$, dann gilt $u \rightleftharpoons^{*} v$ und die beiden korrespondierenden Symbole sind nach dem letzten Lemma miteinander alignierbar. Diese Überprüfung ist in $\oh(1)$ Zeit möglich. Wie bereits angedeutet, entsprechen die Transitivitätsgrenzen aus dem Kontext der Graphen genau denen auf unseren Sequenzen, denn der größte Vorgänger $P(u)[i]$ von Knoten $u\in V$ auf dem Pfad $P_i$  ist, wie wir gezeigt haben, gleichzeitig auch der am weitesten rechts stehende Knoten $v$, für den in unserem Alignment $v \preceq_{\mathcal{A}} u$ gilt. Es folgt $P(u)[i] = \operatorname{Pred}_{\mathcal{A}}(u,i)$ und für die Nachfolgergrenzen gilt Analoges.

\begin{korollar}
	Für eine Menge an Sequenzen $S = \{S_1, \dots, S_n\}$ und zugehörigen Alignmentgraphen mit SSDP $(G,P)$ kann die transitive Hülle von $G$ in $\oh(n^3\cdot L + n^2\cdot L^2)$ Zeit und mit $\oh(n^2\cdot L)$ Speicherplatz erhalten werden, wobei $L$ die maximale Länge aller Sequenzen ist.
\end{korollar}

\begin{beweis}
	Da $(G,P)$ regulär ist, enthält jeder Anker höchstens einen Pfad aus $P$. Die Anzahl der Kanten pro Anker ist also beschränkt durch das Doppelte der Anzahl an möglichen Paaren zwischen den Sequenzen, denn für zwei alignierte Symbole werden zwischen den dazugehörigen Knoten auch zwei Kanten hinzugefügt. Von diesen $n\cdot (n-1)$ Kanten können aber nur $2\cdot (n-1)$-viele für Aktualisierungen im Algorithmus \textrm{EdgeAddition} sorgen. Das liegt daran, dass jeder Knoten nur mit $(n-1)$ neuen Knoten verbunden werden kann. Alle weiteren Kanten ändern die transitive Hülle des Alignmentgraphen nicht und werden direkt in Zeile \ref{alg:pathIf} von Algorithmus \ref{alg:edgeaddition} abgefangen.
	
	Die maximale Anzahl an möglichen Kanten wird erreicht, wenn $\oh(L)$ Anker vorliegen, die jeweils Symbole aus möglichst vielen Sequenzen enthalten. Es ist gibt zwar Alignments mit deutlich mehr Ankern (bis zu $\oh(n\cdot L)$), aber das ginge mit einer Reduzierung der zu überprüfenden Kanten einher. Im schlimmsten Fall kommt es also zu $\oh(n\cdot L)$ rechenintensiven Aufrufen von \textrm{EdgeAddition}. Erinnern wir uns an die Laufzeit von \textrm{EdgeAddition} auf unserem Graphen: $\oh(n^2 \cdot (\mu - \mu_0) + \nu \cdot \min\{\nu, \mu - \mu_p\})$, mit $\mu - \mu_0$ der Anzahl an hinzugefügten Verbindungen, $\nu$ der Anzahl an Stellen aller Sequenzen und $\mu - \mu_p$ der Anzahl an Kanten zwischen allen Knoten, die nicht zur gerade betrachteten Sequenz gehören. $\mu - \mu_p$ liegt im schlimmsten Fall über $\nu$, sodass dieses als Minimum im entsprechenden Term ausgewählt wird. Es gelten $\mu - \mu_0 \in \oh(n\cdot L)$ und $\nu \in \oh(n\cdot L)$. Die Laufzeit von \textrm{EdgeAddition} aller Kanten im rechenintensiven Fall liegt also in $\oh(n^3\cdot L + n^2\cdot L^2)$. Die anderen Kanten, die nicht in Zeile \ref{alg:edgeaddition}\ref{alg:pathIf} abgefangen werden, sind nur $\oh(n^2\cdot L)$-viele und da ihre Bearbeitung nur konstante Zeit kostet, beträgt die Laufzeit auch insgesamt $\oh(n^3\cdot L + n^2\cdot L^2)$ Zeit.
	
	Während des Algorithmus müssen wir stets unseren Alignmentgraphen vorhalten. Dieser enthält für jede Stelle einen Knoten, also $\oh(n\cdot L)$-viele, und jeweils $\oh(n\cdot L)$ Kanten für den Pfad über jede Sequenz. Im Worst-Case kommen dazu jeweils bis zu $\oh(n^2)$ Verbindungen zwischen den Symbolen dieser Zuweisungsspalte für die $\oh(L)$ Anker. Der benötigte Speicherplatz beträgt somit $\oh(n^2\cdot L)$.  
\end{beweis}

Die Schlussfolgerung des letzten Satzes ist, dass die Berechnung der Transitivitäts- und somit Konsistenzgrenzen für ein ganzes multiples Alignment in $\oh(n^3\cdot L + n^2\cdot L^2)$ Zeit und mit $\oh(n^2\cdot L)$ Speicherplatz möglich ist. 

\subsection{Zusätzliche Einsparungen an Speicherplatz}

Durch ein paar geschickte Beobachtungen ist es Abdedda\"im und Morgenstern gelungen, die Laufzeit und den Speicherplatz für die DIALIGN-Implementierung mit GABIOS-LIB weiter zu verbessern\cite{am00}. Diese werden im Folgenden kurz vorgestellt. Wenn zwei Stellen aus $\mathcal{S}$ miteinander aligniert sind, dann folgt daraus automatisch, dass ihre Transitivitätsgrenzen identisch sind. Das nutzen wir aus, indem wir nicht die Grenzen für jede Stelle speichern und aktualisieren, sondern stattdessen für ganze Äquivalenzklassen $[x]_{\mathcal{A}}$ unseres Alignments.

Die zweite Verbesserung zielt auf verwaiste Stellen ab, das heißt solche, die mit keiner anderen aligniert sind. Sei $x = (i,p)$ ein solcher Waise aus der Sequenz $S_i$ an der Stelle $p$. Dann stimmen die Nachfolgergrenzen von $x$ genau mit denen der am weitesten links stehenden Stelle $y = (i,p')$ mit $p < p'$ überein, sodass $y$ kein Waise ist.
Jetzt genügt es, ein Feld mit Werten \textrm{nextClass}$[x] = p'$ für alle Waisen unserer Sequenzen zu speichern. Dadurch ist es uns möglich, die Transitivitätsgrenzen $\operatorname{Succ}_{\mathcal{A}}(x,j)$ dieser Stellen in konstanter Zeit zu aktualisieren, wenn eine neue Zuweisung zwischen unseren Sequenzen und somit eine neue Kante in unserem Alignmentgraphen hinzugefügt wird. 

Möglicherweise lässt sich dieses Array auch durch eine Baum- oder andere Datenstruktur ersetzen, die es uns ermöglicht Einträge zu löschen, nachdem die entsprechenden Stellen keine Waisen mehr sind. Das verhindert, dass beim Alignieren von sehr ähnlichen Sequenzen viel Speicher durch Arrays belegt ist, deren Einträge nie wieder benötigt werden. Dieser Ansatz könnte insbesondere deshalb gut funktionieren, weil Stellen innerhalb eines Intervalls zwischen zwei Nichtwaisen die gleichen Vorgänger und Nachfolger haben. Eine Möglichkeit wäre es, einen AVL- oder B-Baum pro Sequenz über der Ordnung der Startpunkte aller Intervalle zu konstruieren. Jedes Knotenelement speichert dann zusätzlich seinen Endpunkt, sowie Vorgänger und Nachfolger. Wird ein neues Fragment ins Alignment eingefügt, wird das Intervall höchstens in zwei neue aufgeteilt, was die Löschung eines und das Hinzufügen zwei neuer Knoten zur Folge hätte. Asymptotisch wäre die Laufzeit vermutlich schlechter, aber durch den mitunter deutlich verringerten Speicherplatz in der Praxis letztendlich besser. Das weiterzuführen ginge aber zu weit und soll hier nicht betrachtet werden.

\subsection{Einbindung in DIALIGN}

Auch wenn dieses Thema in \cite{am00} nicht behandelt wird, möchte ich kurz darauf eingehen was für den obigen Ansatz zur Überprüfung von Konsistenz im konkreten nötig ist. 

DIALIGN ist ein segmentbasiertes Verfahren für multiples Sequenzalignment. Unser Algorithmus \ref{algo:edge_addition} \textrm{EdgeAddition} ist lediglich in der Lage eine einzelne Kante, die eine symbolweise Zuweisung darstellt, zu unserem Alignmentgraphen hinzuzufügen. Um sicherzustellen, dass ein ganzes Fragment, zu den bisher gewählten Zuweisungen konsistent ist, betrachten wir dieses auf der Ebene einfacher Paare von Stellen. Zunächst überprüfen wir für alle Stellenpaare nacheinander, ob diese alignierbar sind. Falls ja, können wir sie der Reihe nach zum Alignment mit \textrm{EdgeAddition} hinzufügen und falls nicht, würde das Fragment für Inkonsistenzen sorgen und wir fügen nichts hinzu. Die Überprüfung kann einmalig für alle Paare am Anfang durchgeführt werden, weil jedes Paar definitiv zu einem eigenen Anker gehört und die Alignierbarkeit nicht durch andere Paare desselben Fragments eingeschränkt wird.

Es mag sein, dass man für die \enquote{inneren} Stellen der Fragmente effizientere Wege  als \textrm{EdgeAddition} finden kann, um diese zum Alignment hinzuzufügen. In diesem Fall wäre der Algorithmus nur für die beiden Randpaare unseres Fragments nötig.

\subsection{Evaluation von DIALIGN mit der GABIOS-LIB}

Nachdem die GABIOS-LIB in DIALIGN 2.1 integriert wurde, haben Abdedda\"im und Morgenstern die neue Version auf verschiedenen simulierten und echten Datensätzen getestet und mit der vorherigen Version verglichen \cite{am00}. Die Datensätze umfassten dabei bis zu 200 Sequenzen mit Durchschnittslängen von 100, 63,3 und 119,3 je nach Satz. 

Es hat sich herausgestellt, dass die Laufzeit der alten Version sich proportional zu $n^4$ verhielt, während die von DIALIGN 2.1 sogar besser als $n^3$ war. Wie nicht anders zu erwarten, wurde der Unterschied bei steigender Anzahl der Sequenzen $n$ tendenziell größer. Die Laufzeit verbesserte sich im besten Fall um den Faktor 120 und im Durchschnitt etwa um den Faktor 10. Insbesondere die höhere Geschwindigkeit bei großen Alignments mit mehr Sequenzen ist erfreulich, da diese ohnehin komplexer zu berechnen sind.

Ein weiterer Vorteil ist der verringerte Speicherverbrauch im Verhältnis zur alten Version 2.0. Zwar beträgt der Speicherverbrauch der neuen Implementierung im schlimmsten Fall nach wie vor $\oh(n^2\cdot L)$, was zuvor der echte benötigte Speicher war. In der Praxis sank er aber um einen konstanten Faktor abhängig von der Ähnlichkeit der alignierten Sequenzen (ausgenommen randomisierte Sequenzen). Die Anzahl $n$ hatte hierbei keinen signifikanten Einfluss auf den Grad der Verbesserung. Dieser lag bei den nichtrandomisierten Datensätzen etwa zwischen fünf und zehn.

\subsection{Beispiel zu Konsistenzgrenzen}

Für die Konsistenzgrenzen brauchen wir in jedem Schritt unseren Alignmentgraphen, alle Äquivalenzklassen unseres Alignments, deren Vorgänger- und Nachfolgergrenzen und die Felder \textrm{nextClass} und \textrm{prevClass} für alle  Waisen. Der Übersichtlichkeit halber wurden nicht die ganzen Felder angegeben, sondern nur die Werte ungleich \enquote{NIL}. Zur Erinnerung hier nochmal der aktuelle Zwischenstand mit unseren Fragmenten sortiert nach Überlappgewichten.

\begin{tabular}{|r|c|c||r|c|c||r|c|c|}
	\hline
	Seq. & Frag. & Ü-Gew. & Seq. & Frag. & Ü-Gew. & Seq. & Frag. & Ü-Gew.\\
	\hline
	2 & \texttt{GTCADCTC} & \multirow{2}{*}{69} & 1 & \texttt{TCTCA} & \multirow{2}{*}{41} & 1 & \texttt{GT} &\multirow{2}{*}{20} \\
	4 & \texttt{GTCADATC} &                     & 3 & \texttt{TATCA} &                     & 2 & \texttt{GT} & \\
	3 & \texttt{TCAD} & \multirow{2}{*}{47} & 1 & \texttt{CTCA} & \multirow{2}{*}{34} & 1 & \texttt{TC} & \multirow{2}{*}{20} \\
	4 & \texttt{TCAD} &                     & 2 & \texttt{CTCA} &                          & 4 & \texttt{TC} & \\
	2 & \texttt{TCAD} & \multirow{2}{*}{44} & 1 & \texttt{DGTC} & \multirow{2}{*}{31} &    &   & \\
	3 & \texttt{TCAD} &                     & 4 & \texttt{DGTC} &                     &    &   & \\
	\hline
\end{tabular}

Diese werden wir jetzt der Reihe nach in unseren Alignmentgraphen einfügen, wenn die Konsistenz dadurch erhalten bleibt.

\subsubsection{Ursprungszustand}

Vor dem ersten Schritt enthält der Alignmentgraph genau unsere Stellen $\mathcal{S}$ mit den Pfaden $\mathcal{P}$, die der natürlichen Ordnung auf den jeweiligen Sequenzen entsprechen. Weil es noch keine Nichtwaisen gibt, können wir die Felder \textrm{nextClass} und \textrm{prevClass} zunächst ignorieren, da es keine Stellen gibt, auf die diese verweisen können.

\begin{center}
\begin{tikzpicture}[
	mycircle/.style={
		circle,
		draw=black,
		fill=gray,
		fill opacity = 0.3,
		text opacity=1,
		inner sep=0pt,
		minimum size=15pt,
		font=\tiny},
	myarrow/.style={-Stealth},
	node distance=0.3cm and 1.1cm
	]
	% erste Sequenz
	\node[mycircle] (c11) {A};
	\node[mycircle,right=of c11] (c12) {D};
	\node[mycircle,right=of c12] (c13) {G};
	\node[mycircle,right=of c13] (c14) {T};
	\node[mycircle,right=of c14] (c15) {C};
	\node[mycircle,right=of c15] (c16) {T};
	\node[mycircle,right=of c16] (c17) {C};
	\node[mycircle,right=of c17] (c18) {A};

	% zweite Sequenz
	\node[mycircle,below=of c11] (c21) {G};
	\node[mycircle,right=of c21] (c22) {T};
	\node[mycircle,right=of c22] (c23) {C};
	\node[mycircle,right=of c23] (c24) {A};
	\node[mycircle,right=of c24] (c25) {D};
	\node[mycircle,right=of c25] (c26) {C};
	\node[mycircle,right=of c26] (c27) {T};
	\node[mycircle,right=of c27] (c28) {C};
	\node[mycircle,right=of c28] (c29) {A};

	% dritte Sequenz
	\node[mycircle,below=of c21] (c31) {T};
	\node[mycircle,right=of c31] (c32) {A};
	\node[mycircle,right=of c32] (c33) {T};
	\node[mycircle,right=of c33] (c34) {C};
	\node[mycircle,right=of c34] (c35) {A};
	\node[mycircle,right=of c35] (c36) {D};
	\node[mycircle,right=of c36] (c37) {G};
	\node[mycircle,right=of c37] (c38) {G};

	% vierte Sequenz
	\node[mycircle,below=of c31] (c41) {D};
	\node[mycircle,right=of c41] (c42) {G};
	\node[mycircle,right=of c42] (c43) {T};
	\node[mycircle,right=of c43] (c44) {C};
	\node[mycircle,right=of c44] (c45) {A};
	\node[mycircle,right=of c45] (c46) {D};
	\node[mycircle,right=of c46] (c47) {A};
	\node[mycircle,right=of c47] (c48) {T};
	\node[mycircle,right=of c48] (c49) {C};
	
	\foreach \i/\j/\txt/\p in {% start node/end node/text/position
		%erste Sequenz
		c11/c12//above,
		c12/c13//above,
		c13/c14//above,
		c14/c15//above,
		c15/c16//above,
		c16/c17//above,
		c17/c18//above,
		%zweite Sequenz
		c21/c22//above,
		c22/c23//above,
		c23/c24//above,
		c24/c25//above,
		c25/c26//above,
		c26/c27//above,
		c27/c28//above,
		c28/c29//above,
		%dritte Sequenz
		c31/c32//above,
		c32/c33//above,
		c33/c34//above,
		c34/c35//above,
		c35/c36//above,
		c36/c37//above,
		c37/c38//above,
		%vierte Sequenz
		c41/c42//above,
		c42/c43//above,
		c43/c44//above,
		c44/c45//above,
		c45/c46//above,
		c46/c47//above,
		c47/c48//above,
		c48/c49//above}
	\draw [myarrow] (\i) -- node[sloped,font=\tiny,\p] {\txt} (\j);
\end{tikzpicture}
\end{center}

\subsubsection{Erstes Fragment}

Zu Beginn haben wir das Fragment ${\texttt{GTCADCTC}}\choose{\texttt{GTCADATC}}$ zwischen den Sequenzen $S_2$ und $S_4$. Da unser Alignment noch leer ist, bleibt die Konsistenz auf jeden Fall gewahrt. Wir fügen daher die Kanten in unseren Alignmentgraphen ein und berechnen die Vorgänger- und Nachfolgergrenzen für alle Äquivalenzklassen und Waisen.

\begin{center}
	\begin{tikzpicture}[
	mycircle/.style={
		circle,
		draw=black,
		fill=gray,
		fill opacity = 0.3,
		text opacity=1,
		inner sep=0pt,
		minimum size=15pt,
		font=\tiny},
	myarrow/.style={-Stealth},
	node distance=0.4cm and 1.1cm
	]
	% erste Sequenz
	\node[mycircle] (c11) {A};
	\node[mycircle,right=of c11] (c12) {D};
	\node[mycircle,right=of c12] (c13) {G};
	\node[mycircle,right=of c13] (c14) {T};
	\node[mycircle,right=of c14] (c15) {C};
	\node[mycircle,right=of c15] (c16) {T};
	\node[mycircle,right=of c16] (c17) {C};
	\node[mycircle,right=of c17] (c18) {A};
	
	% zweite Sequenz
	\node[mycircle,below=of c11] (c21) {G};
	\node[mycircle,right=of c21] (c22) {T};
	\node[mycircle,right=of c22] (c23) {C};
	\node[mycircle,right=of c23] (c24) {A};
	\node[mycircle,right=of c24] (c25) {D};
	\node[mycircle,right=of c25] (c26) {C};
	\node[mycircle,right=of c26] (c27) {T};
	\node[mycircle,right=of c27] (c28) {C};
	\node[mycircle,right=of c28] (c29) {A};
	
	% dritte Sequenz
	\node[mycircle,below=of c21] (c31) {T};
	\node[mycircle,right=of c31] (c32) {A};
	\node[mycircle,right=of c32] (c33) {T};
	\node[mycircle,right=of c33] (c34) {C};
	\node[mycircle,right=of c34] (c35) {A};
	\node[mycircle,right=of c35] (c36) {D};
	\node[mycircle,right=of c36] (c37) {G};
	\node[mycircle,right=of c37] (c38) {G};
	
	% vierte Sequenz
	\node[mycircle,below=of c31] (c41) {D};
	\node[mycircle,right=of c41] (c42) {G};
	\node[mycircle,right=of c42] (c43) {T};
	\node[mycircle,right=of c43] (c44) {C};
	\node[mycircle,right=of c44] (c45) {A};
	\node[mycircle,right=of c45] (c46) {D};
	\node[mycircle,right=of c46] (c47) {A};
	\node[mycircle,right=of c47] (c48) {T};
	\node[mycircle,right=of c48] (c49) {C};
	
	\foreach \i/\j/\txt/\p in {% start node/end node/text/position
		%erste Sequenz
		c11/c12//above,
		c12/c13//above,
		c13/c14//above,
		c14/c15//above,
		c15/c16//above,
		c16/c17//above,
		c17/c18//above,
		%zweite Sequenz
		c21/c22//above,
		c22/c23//above,
		c23/c24//above,
		c24/c25//above,
		c25/c26//above,
		c26/c27//above,
		c27/c28//above,
		c28/c29//above,
		%dritte Sequenz
		c31/c32//above,
		c32/c33//above,
		c33/c34//above,
		c34/c35//above,
		c35/c36//above,
		c36/c37//above,
		c37/c38//above,
		%vierte Sequenz
		c41/c42//above,
		c42/c43//above,
		c43/c44//above,
		c44/c45//above,
		c45/c46//above,
		c46/c47//above,
		c47/c48//above,
		c48/c49//above}
	\draw [myarrow] (\i) -- node[sloped,font=\tiny,\p] {\txt} (\j);
	
	% erstes Fragment
	\foreach \i/\j/\txt/\p in {% start node/end node/text/position
		c21/c42//above,
		c22/c43//above,
		c23/c44//above,
		c24/c45//above,
		c25/c46//above,	
		c26/c47//above,
		c27/c48//above,
		c28/c49//above}
	\draw [Stealth-Stealth, draw=black,double=white] (\i) -- node[sloped,font=\tiny,\p] {\txt} (\j);
	\end{tikzpicture}
\end{center}

Um zu verdeutlichen, dass durch doppelte Kanten verbundene Knoten im Sinne unseres Alignments äquivalent sind, wurden diese Verbindungen mit Äquivalenzpfeilen dargestellt.

\small
\begin{tabular}{|r||c|c|c|c|}
	\hline
	Bezeichner 	& $[(2,1)]_{\mathcal{A}}$ & $[(2,2)]_{\mathcal{A}}$ & $[(2,3)]_{\mathcal{A}}$ & $[(2,4)]_{\mathcal{A}}$\\
	Äq.klasse  & $\{(2,1),(4,2)\}$	      & $\{(2,2),(4,3)\}$       & $\{(2,3),(4,4)\}$       & $\{(2,4),(4,5)\}$        \\
	\hline
	            & $[(2,5)]_{\mathcal{A}}$ & $[(2,6)]_{\mathcal{A}}$ & $[(2,7)]_{\mathcal{A}}$ & $[(2,8)]_{\mathcal{A}}$\\
	            & $\{(2,5),(4,6)\}$       & $\{(2,6),(4,7)\}$       & $\{(2,7),(4,8)\}$       & $\{(2,8),(4,9)\}$  \\
	\hline
\end{tabular}
\normalsize

Bei den Waisen werden nur die Stellen beeinflusst, die in den Sequenzen liegen, die bereits ein Fragment enthalten, aber nicht selbst Teil davon sind.

\vspace{5pt}

\small
\begin{tabular}{|r|cccc|cccc||r|c|r|c|}
	\hline
	 & \multicolumn{4}{c|}{$\operatorname{Pred}((i,p),j)$} & \multicolumn{4}{c||}{$\operatorname{Succ}((i,p),j)$} & \multicolumn{2}{c|}{\textrm{prevClass}} & \multicolumn{2}{c}{\textrm{nextClass}} \\ \hline
	\diagbox[dir=NW]{$(i,p)$}{$j$} & 1 & 2 & 3 & 4 & 1 & 2 & 3 & 4 & $(i,p)$ & $P((i,p))$ & $(i,p)$ & $S((i,p))$ \\ \hline
	$[(2,1)]_{\mathcal{A}}$ & 0 & 1 & 0 & 2 & 9 & 1 & 9 & 2 & $(2,9)$ & 8 & $(4,1)$ & 1 \\
	$[(2,2)]_{\mathcal{A}}$ & 0 & 2 & 0 & 3 & 9 & 2 & 9 & 3 & & & & \\
	$[(2,3)]_{\mathcal{A}}$ & 0 & 3 & 0 & 4 & 9 & 3 & 9 & 4 & & & & \\
	$[(2,4)]_{\mathcal{A}}$ & 0 & 4 & 0 & 5 & 9 & 4 & 9 & 5 & & & & \\
	$[(2,5)]_{\mathcal{A}}$ & 0 & 5 & 0 & 6 & 9 & 5 & 9 & 6 & & & & \\
	$[(2,6)]_{\mathcal{A}}$ & 0 & 6 & 0 & 7 & 9 & 6 & 9 & 7 & & & & \\
	$[(2,7)]_{\mathcal{A}}$ & 0 & 7 & 0 & 8 & 9 & 7 & 9 & 8 & & & & \\
	$[(2,8)]_{\mathcal{A}}$ & 0 & 8 & 0 & 9 & 9 & 8 & 9 & 9 & & & & \\
	\hline
\end{tabular}
\normalsize
\vspace{5pt}

Wie nicht anders zu erwarten, wurden die Vorgänger und Nachfolger für alle Sequenzen, die nicht mit einem Fragment verbunden sind, auf 0 beziehungsweise die Länge der Sequenz plus eins gesetzt. Bei allen Ankern ist der Eintrag für die jeweilige Sequenz genau die Position der an dieser Äquivalenzklasse beteiligten Stelle.

\subsubsection{Zweites Fragment}

Als nächstes fügen wir das Fragment ${\texttt{TCAD}}\choose{\texttt{TCAD}}$ aus der dritten und vierten Sequenz ein. Weil die dritte Sequenz noch nicht Teil des multiplen Alignments ist, kann es auch hier zu keinen Inkonsistenzen kommen.


\begin{center}
\begin{tikzpicture}[
	mycircle/.style={
		circle,
		draw=black,
		fill=gray,
		fill opacity = 0.3,
		text opacity=1,
		inner sep=0pt,
		minimum size=15pt,
		font=\tiny},
	myarrow/.style={-Stealth},
	node distance=0.6cm and 1.1cm
	]
	% erste Sequenz
	\node[mycircle] (c11) {A};
	\node[mycircle,right=of c11] (c12) {D};
	\node[mycircle,right=of c12] (c13) {G};
	\node[mycircle,right=of c13] (c14) {T};
	\node[mycircle,right=of c14] (c15) {C};
	\node[mycircle,right=of c15] (c16) {T};
	\node[mycircle,right=of c16] (c17) {C};
	\node[mycircle,right=of c17] (c18) {A};
	
	% zweite Sequenz
	\node[mycircle,below=of c11] (c21) {G};
	\node[mycircle,right=of c21] (c22) {T};
	\node[mycircle,right=of c22] (c23) {C};
	\node[mycircle,right=of c23] (c24) {A};
	\node[mycircle,right=of c24] (c25) {D};
	\node[mycircle,right=of c25] (c26) {C};
	\node[mycircle,right=of c26] (c27) {T};
	\node[mycircle,right=of c27] (c28) {C};
	\node[mycircle,right=of c28] (c29) {A};
	
	% dritte Sequenz
	\node[mycircle,below=of c21] (c31) {T};
	\node[mycircle,right=of c31] (c32) {A};
	\node[mycircle,right=of c32] (c33) {T};
	\node[mycircle,right=of c33] (c34) {C};
	\node[mycircle,right=of c34] (c35) {A};
	\node[mycircle,right=of c35] (c36) {D};
	\node[mycircle,right=of c36] (c37) {G};
	\node[mycircle,right=of c37] (c38) {G};
	
	% vierte Sequenz
	\node[mycircle,below=of c31] (c41) {D};
	\node[mycircle,right=of c41] (c42) {G};
	\node[mycircle,right=of c42] (c43) {T};
	\node[mycircle,right=of c43] (c44) {C};
	\node[mycircle,right=of c44] (c45) {A};
	\node[mycircle,right=of c45] (c46) {D};
	\node[mycircle,right=of c46] (c47) {A};
	\node[mycircle,right=of c47] (c48) {T};
	\node[mycircle,right=of c48] (c49) {C};
	
	\foreach \i/\j/\txt/\p in {% start node/end node/text/position
		%erste Sequenz
		c11/c12//above,
		c12/c13//above,
		c13/c14//above,
		c14/c15//above,
		c15/c16//above,
		c16/c17//above,
		c17/c18//above,
		%zweite Sequenz
		c21/c22//above,
		c22/c23//above,
		c23/c24//above,
		c24/c25//above,
		c25/c26//above,
		c26/c27//above,
		c27/c28//above,
		c28/c29//above,
		%dritte Sequenz
		c31/c32//above,
		c32/c33//above,
		c33/c34//above,
		c34/c35//above,
		c35/c36//above,
		c36/c37//above,
		c37/c38//above,
		%vierte Sequenz
		c41/c42//above,
		c42/c43//above,
		c43/c44//above,
		c44/c45//above,
		c45/c46//above,
		c46/c47//above,
		c47/c48//above,
		c48/c49//above}
	\draw [myarrow] (\i) -- node[sloped,font=\tiny,\p] {\txt} (\j);
	
	% erstes Fragment
	\foreach \i/\j/\txt/\p in {% start node/end node/text/position
		c21/c42//above,
		c22/c43//above,
		c23/c44//above,
		c24/c45//above,
		c25/c46//above,	
		c26/c47//above,
		c27/c48//above,
		c28/c49//above}
	\draw [Stealth-Stealth, draw=black,double=white] (\i) -- node[sloped,font=\tiny,\p] {\txt} (\j);
	
	% zweites Fragment
	\foreach \i/\j/\txt/\p in {% start node/end node/text/position
		c33/c43//above,	
		c34/c44//above,
		c35/c45//above,
		c36/c46//above}
	\draw [Stealth-Stealth, draw=black,double=white] (\i) -- node[sloped,font=\tiny,\p] {\txt} (\j);
\end{tikzpicture}
\end{center}
.
\small
\begin{tabular}{|r||c|c|c|c|}
	\hline
	Bezeichner 	& $[(2,1)]_{\mathcal{A}}$ & $[(2,2)]_{\mathcal{A}}$ & $[(2,3)]_{\mathcal{A}}$ & $[(2,4)]_{\mathcal{A}}$\\
	Äq.klasse  & $\{(2,1),(4,2)\}$	      & $\{(2,2),(3,3),(4,3)\}$       & $\{(2,3),(3,4),(4,4)\}$       & $\{(2,4),(3,5),(4,5)\}$        \\
	\hline
	& $[(2,5)]_{\mathcal{A}}$ & $[(2,6)]_{\mathcal{A}}$ & $[(2,7)]_{\mathcal{A}}$ & $[(2,8)]_{\mathcal{A}}$\\
	& $\{(2,5),(3,6),(4,6)\}$       & $\{(2,6),(4,7)\}$       & $\{(2,7),(4,8)\}$       & $\{(2,8),(4,9)\}$ \\
	\hline
\end{tabular}
\normalsize
\vspace{5pt}

Zu aktualisieren sind die Transitivitätsgrenzen für die dritte Sequenz und die \textrm{Prev-} und \textrm{NextClass}-Einträge der Stellen von $S_3$, die vor oder hinter unserem Fragment liegen. Da diese jeweils am Start oder Ende positioniert sind, ist nur einer der beiden Einträge relevant.

\vspace{5pt}
\small
\begin{tabular}{|r|cccc|cccc||r|c|r|c|}
	\hline
	& \multicolumn{4}{c|}{$\operatorname{Pred}((i,p),j)$} & \multicolumn{4}{c||}{$\operatorname{Succ}((i,p),j)$} & \multicolumn{2}{c|}{\textrm{prevClass}} & \multicolumn{2}{c}{\textrm{nextClass}} \\ \hline
	\diagbox[dir=NW]{$(i,p)$}{$j$} & 1 & 2 & 3 & 4 & 1 & 2 & 3 & 4 & $(i,p)$ & $P((i,p))$ & $(i,p)$ & $S((i,p))$ \\ \hline
	$[(2,1)]_{\mathcal{A}}$ & 0 & 1 & 0 & 2 & 9 & 1 & 3 & 2 & $(2,9)$ & 8 & $(4,1)$ & 1 \\
	$[(2,2)]_{\mathcal{A}}$ & 0 & 2 & 3 & 3 & 9 & 2 & 3 & 3 & $(3,7)$ & 6 & $(3,1)$ & 3 \\
	$[(2,3)]_{\mathcal{A}}$ & 0 & 3 & 4 & 4 & 9 & 3 & 4 & 4 & $(3,8)$ & 6 & $(3,2)$ & 3 \\
	$[(2,4)]_{\mathcal{A}}$ & 0 & 4 & 5 & 5 & 9 & 4 & 5 & 5 & & & & \\
	$[(2,5)]_{\mathcal{A}}$ & 0 & 5 & 6 & 6 & 9 & 5 & 6 & 6 & & & & \\
	$[(2,6)]_{\mathcal{A}}$ & 0 & 6 & 6 & 7 & 9 & 6 & 9 & 7 & & & & \\
	$[(2,7)]_{\mathcal{A}}$ & 0 & 7 & 6 & 8 & 9 & 7 & 9 & 8 & & & & \\
	$[(2,8)]_{\mathcal{A}}$ & 0 & 8 & 6 & 9 & 9 & 8 & 9 & 9 & & & & \\
	\hline
\end{tabular}
\normalsize

\subsubsection{Drittes Fragment}

In diesem Schritt fügen wir das Fragment ${\texttt{TCAD}}\choose{\texttt{TCAD}}$ aus $S_2$ und $S_3$ ein. Hier fügen wir nur zusätzliche Kanten in bereits existierende Anker ein. Das hat auch zur Folge, dass sich die Vorgänger- und Nachfolgergrenzen nicht verändern können, weil bereits in beide Richtungen Kanten existierten (s. Algorithmus \ref{alg:edgeaddition}).

\begin{center}
	\begin{tikzpicture}[
	mycircle/.style={
		circle,
		draw=black,
		fill=gray,
		fill opacity = 0.3,
		text opacity=1,
		inner sep=0pt,
		minimum size=15pt,
		font=\tiny},
	myarrow/.style={-Stealth},
	node distance=0.6cm and 1.1cm
	]
	% erste Sequenz
	\node[mycircle] (c11) {A};
	\node[mycircle,right=of c11] (c12) {D};
	\node[mycircle,right=of c12] (c13) {G};
	\node[mycircle,right=of c13] (c14) {T};
	\node[mycircle,right=of c14] (c15) {C};
	\node[mycircle,right=of c15] (c16) {T};
	\node[mycircle,right=of c16] (c17) {C};
	\node[mycircle,right=of c17] (c18) {A};
	
	% zweite Sequenz
	\node[mycircle,below=of c11] (c21) {G};
	\node[mycircle,right=of c21] (c22) {T};
	\node[mycircle,right=of c22] (c23) {C};
	\node[mycircle,right=of c23] (c24) {A};
	\node[mycircle,right=of c24] (c25) {D};
	\node[mycircle,right=of c25] (c26) {C};
	\node[mycircle,right=of c26] (c27) {T};
	\node[mycircle,right=of c27] (c28) {C};
	\node[mycircle,right=of c28] (c29) {A};
	
	% dritte Sequenz
	\node[mycircle,below=of c21] (c31) {T};
	\node[mycircle,right=of c31] (c32) {A};
	\node[mycircle,right=of c32] (c33) {T};
	\node[mycircle,right=of c33] (c34) {C};
	\node[mycircle,right=of c34] (c35) {A};
	\node[mycircle,right=of c35] (c36) {D};
	\node[mycircle,right=of c36] (c37) {G};
	\node[mycircle,right=of c37] (c38) {G};
	
	% vierte Sequenz
	\node[mycircle,below=of c31] (c41) {D};
	\node[mycircle,right=of c41] (c42) {G};
	\node[mycircle,right=of c42] (c43) {T};
	\node[mycircle,right=of c43] (c44) {C};
	\node[mycircle,right=of c44] (c45) {A};
	\node[mycircle,right=of c45] (c46) {D};
	\node[mycircle,right=of c46] (c47) {A};
	\node[mycircle,right=of c47] (c48) {T};
	\node[mycircle,right=of c48] (c49) {C};
	
	\foreach \i/\j/\txt/\p in {% start node/end node/text/position
		%erste Sequenz
		c11/c12//above,
		c12/c13//above,
		c13/c14//above,
		c14/c15//above,
		c15/c16//above,
		c16/c17//above,
		c17/c18//above,
		%zweite Sequenz
		c21/c22//above,
		c22/c23//above,
		c23/c24//above,
		c24/c25//above,
		c25/c26//above,
		c26/c27//above,
		c27/c28//above,
		c28/c29//above,
		%dritte Sequenz
		c31/c32//above,
		c32/c33//above,
		c33/c34//above,
		c34/c35//above,
		c35/c36//above,
		c36/c37//above,
		c37/c38//above,
		%vierte Sequenz
		c41/c42//above,
		c42/c43//above,
		c43/c44//above,
		c44/c45//above,
		c45/c46//above,
		c46/c47//above,
		c47/c48//above,
		c48/c49//above}
	\draw [myarrow] (\i) -- node[sloped,font=\tiny,\p] {\txt} (\j);
	
	% erstes Fragment
	\foreach \i/\j/\txt/\p in {% start node/end node/text/position
		c21/c42//above,
		c22/c43//above,
		c23/c44//above,
		c24/c45//above,
		c25/c46//above,	
		c26/c47//above,
		c27/c48//above,
		c28/c49//above}
	\draw [Stealth-Stealth, draw=black,double=white] (\i) -- node[sloped,font=\tiny,\p] {\txt} (\j);
	
	% zweites Fragment
	\foreach \i/\j/\txt/\p in {% start node/end node/text/position
		c33/c43//above,	
		c34/c44//above,
		c35/c45//above,
		c36/c46//above}
	\draw [Stealth-Stealth, draw=black,double=white] (\i) -- node[sloped,font=\tiny,\p] {\txt} (\j);
	
	% drittes Fragment
	\foreach \i/\j/\txt/\p in {% start node/end node/text/position
		c22/c33//above,	
		c23/c34//above,
		c24/c35//above,
		c25/c36//above}
	\draw [Stealth-Stealth, draw=black,double=white] (\i) -- node[sloped,font=\tiny,\p] {\txt} (\j);
	\end{tikzpicture}
\end{center}

\subsubsection{Viertes Fragment}

Nun fügen wir das Fragment ${\texttt{TCTCA}}\choose{\texttt{TATCA}}$ aus der ersten und dritten Sequenz ein. Auch hier kann es wieder zu keinen Inkonsistenzen kommen, weil $S_1$ noch nicht Teil des Alignments war.


\begin{center}
	\begin{tikzpicture}[
	mycircle/.style={
		circle,
		draw=black,
		fill=gray,
		fill opacity = 0.3,
		text opacity=1,
		inner sep=0pt,
		minimum size=15pt,
		font=\tiny},
	myarrow/.style={-Stealth},
	node distance=0.6cm and 1.1cm
	]
	% erste Sequenz
	\node[mycircle] (c11) {A};
	\node[mycircle,right=of c11] (c12) {D};
	\node[mycircle,right=of c12] (c13) {G};
	\node[mycircle,right=of c13] (c14) {T};
	\node[mycircle,right=of c14] (c15) {C};
	\node[mycircle,right=of c15] (c16) {T};
	\node[mycircle,right=of c16] (c17) {C};
	\node[mycircle,right=of c17] (c18) {A};
	
	% zweite Sequenz
	\node[mycircle,below=of c11] (c21) {G};
	\node[mycircle,right=of c21] (c22) {T};
	\node[mycircle,right=of c22] (c23) {C};
	\node[mycircle,right=of c23] (c24) {A};
	\node[mycircle,right=of c24] (c25) {D};
	\node[mycircle,right=of c25] (c26) {C};
	\node[mycircle,right=of c26] (c27) {T};
	\node[mycircle,right=of c27] (c28) {C};
	\node[mycircle,right=of c28] (c29) {A};
	
	% dritte Sequenz
	\node[mycircle,below=of c21] (c31) {T};
	\node[mycircle,right=of c31] (c32) {A};
	\node[mycircle,right=of c32] (c33) {T};
	\node[mycircle,right=of c33] (c34) {C};
	\node[mycircle,right=of c34] (c35) {A};
	\node[mycircle,right=of c35] (c36) {D};
	\node[mycircle,right=of c36] (c37) {G};
	\node[mycircle,right=of c37] (c38) {G};
	
	% vierte Sequenz
	\node[mycircle,below=of c31] (c41) {D};
	\node[mycircle,right=of c41] (c42) {G};
	\node[mycircle,right=of c42] (c43) {T};
	\node[mycircle,right=of c43] (c44) {C};
	\node[mycircle,right=of c44] (c45) {A};
	\node[mycircle,right=of c45] (c46) {D};
	\node[mycircle,right=of c46] (c47) {A};
	\node[mycircle,right=of c47] (c48) {T};
	\node[mycircle,right=of c48] (c49) {C};
	
	\foreach \i/\j/\txt/\p in {% start node/end node/text/position
		%erste Sequenz
		c11/c12//above,
		c12/c13//above,
		c13/c14//above,
		c14/c15//above,
		c15/c16//above,
		c16/c17//above,
		c17/c18//above,
		%zweite Sequenz
		c21/c22//above,
		c22/c23//above,
		c23/c24//above,
		c24/c25//above,
		c25/c26//above,
		c26/c27//above,
		c27/c28//above,
		c28/c29//above,
		%dritte Sequenz
		c31/c32//above,
		c32/c33//above,
		c33/c34//above,
		c34/c35//above,
		c35/c36//above,
		c36/c37//above,
		c37/c38//above,
		%vierte Sequenz
		c41/c42//above,
		c42/c43//above,
		c43/c44//above,
		c44/c45//above,
		c45/c46//above,
		c46/c47//above,
		c47/c48//above,
		c48/c49//above}
	\draw [myarrow] (\i) -- node[sloped,font=\tiny,\p] {\txt} (\j);
	
	% viertes Fragment
	\foreach \i/\j/\txt/\p in {% start node/end node/text/position
		c14/c31//above,	
		c15/c32//above,
		c16/c33//above,
		c17/c34//above,
		c18/c35//above}
	\draw [Stealth-Stealth, draw=black,double=white] (\i) -- node[sloped,font=\tiny,\p] {\txt} (\j);	

	% erstes Fragment
	\foreach \i/\j/\txt/\p in {% start node/end node/text/position
		c21/c42//above,
		c22/c43//above,
		c23/c44//above,
		c24/c45//above,
		c25/c46//above,	
		c26/c47//above,
		c27/c48//above,
		c28/c49//above}
	\draw [Stealth-Stealth, draw=black,double=white] (\i) -- node[sloped,font=\tiny,\p] {\txt} (\j);
	
	% zweites Fragment
	\foreach \i/\j/\txt/\p in {% start node/end node/text/position
		c33/c43//above,	
		c34/c44//above,
		c35/c45//above,
		c36/c46//above}
	\draw [Stealth-Stealth, draw=black,double=white] (\i) -- node[sloped,font=\tiny,\p] {\txt} (\j);
	
	% drittes Fragment
	\foreach \i/\j/\txt/\p in {% start node/end node/text/position
		c22/c33//above,	
		c23/c34//above,
		c24/c35//above,
		c25/c36//above}
	\draw [Stealth-Stealth, draw=black,double=white] (\i) -- node[sloped,font=\tiny,\p] {\txt} (\j);
	\end{tikzpicture}
\end{center}
.
\small
\begin{tabular}{|r||c|c|c|}
	\hline
	Bezeichner 	& $[(2,1)]_{\mathcal{A}}$ & $[(2,2)]_{\mathcal{A}}$ & $[(2,3)]_{\mathcal{A}}$ \\
	Äq.klasse  & $\{(2,1),(4,2)\}$	      & $\{(2,2),(3,3),(4,3),(1,6)\}$       & $\{(2,3),(3,4),(4,4),(1,7)\}$ \\
	\hline
	& $[(2,4)]_{\mathcal{A}}$ & $[(2,5)]_{\mathcal{A}}$ & $[(2,6)]_{\mathcal{A}}$ \\
	& $\{(2,4),(3,5),(4,5),(1,8)\}$ & $\{(2,5),(3,6),(4,6)\}$       & $\{(2,6),(4,7)\}$ \\
	\hline
	& $[(2,7)]_{\mathcal{A}}$ & $[(2,8)]_{\mathcal{A}}$ & $[(1,4)]_{\mathcal{A}}$ \\
	& $\{(2,7),(4,8)\}$       & $\{(2,8),(4,9)\}$       & $\{(1,4),(3,1)\}$        \\
	\hline
	& $[(1,4)]_{\mathcal{A}}$ & & \\
	& $\{(1,4),(3,1)\}$ & & \\
	\hline
\end{tabular}

\vspace{5pt}

\begin{tabular}{|r|cccc|cccc||r|c|r|c|}
	\hline
	& \multicolumn{4}{c|}{$\operatorname{Pred}((i,p),j)$} & \multicolumn{4}{c||}{$\operatorname{Succ}((i,p),j)$} & \multicolumn{2}{c|}{\textrm{prevClass}} & \multicolumn{2}{c}{\textrm{nextClass}} \\ \hline
	\diagbox[dir=NW]{$(i,p)$}{$j$} & 1 & 2 & 3 & 4 & 1 & 2 & 3 & 4 & $(i,p)$ & $P((i,p))$ & $(i,p)$ & $S((i,p))$ \\ \hline
	$[(2,1)]_{\mathcal{A}}$ & 0 & 1 & 0 & 2 & 6 & 1 & 3 & 2 & $(2,9)$ & 8 & $(4,1)$ & 1 \\
	$[(2,2)]_{\mathcal{A}}$ & 6 & 2 & 3 & 3 & 6 & 2 & 3 & 3 & $(3,7)$ & 6 & $(3,1)$ & 3 \\
	$[(2,3)]_{\mathcal{A}}$ & 7 & 3 & 4 & 4 & 7 & 3 & 4 & 4 & $(3,8)$ & 6 & $(3,2)$ & 3 \\
	$[(2,4)]_{\mathcal{A}}$ & 8 & 4 & 5 & 5 & 8 & 4 & 5 & 5 & & & $(1,1)$ & 4 \\
	$[(2,5)]_{\mathcal{A}}$ & 0 & 5 & 6 & 6 & 9 & 5 & 6 & 6 & & & $(1,2)$ & 4 \\
	$[(2,6)]_{\mathcal{A}}$ & 0 & 6 & 6 & 7 & 9 & 6 & 9 & 7 & & & $(1,3)$ & 4 \\
	$[(2,7)]_{\mathcal{A}}$ & 0 & 7 & 6 & 8 & 9 & 7 & 9 & 8 & & & & \\
	$[(2,8)]_{\mathcal{A}}$ & 0 & 8 & 6 & 9 & 9 & 8 & 9 & 9 & & & & \\
	$[(1,4)]_{\mathcal{A}}$ & 4 & 0 & 1 & 0 & 4 & 2 & 1 & 3 & & & & \\
	$[(1,5)]_{\mathcal{A}}$ & 5 & 0 & 2 & 0 & 5 & 2 & 2 & 4 & & & & \\
	\hline
\end{tabular}
\normalsize

\subsubsection{Weitere Fragmente}

Die restlichen Fragmente unserer paarweisen Alignments sind leider nicht konsistent zu unserem bisherigen multiplen Alignment. Betrachtet man ${\texttt{GT}}\choose{\texttt{GT}}$ zwischen $S_1$ und $S_2$, das als drittnächstes an der Reihe ist, stellt man fest, dass die jeweiligen Stellen nicht alignierbar sind. Für $(1,2) =$ (\texttt{G}) ist das Alignieren vorerst möglich, denn $\textrm{NextClass}((1,3)) = 4$ und $\operatorname{Succ}((1,4),2) - 1 = 1$. Für $(1,3) =$ (\texttt{T}) gilt das nicht mehr, denn $\operatorname{Succ}((1,4),2) - 1 = 1 < 2$. Für die anderen drei übrigen Fragmente gilt Analoges.

\section{Abschluss des Verfahrens}

Nach diesem ersten Durchlauf unseres Ansatzes sind wir jedoch noch nicht fertig. Es kann beispielsweise sein, dass wir ein wichtiges Motiv haben, dass in mehreren Sequenzen vorkommt und somit Teil unseres multiplen Alignments sein sollte. Bei zwei Sequenzen war es jedoch nicht im paarweisen Alignment enthalten, weil stattdessen ein zufälliges, aber größeres Fragment ausgewählt wurde. Wenn wir Glück haben, findet dieses aber nicht den Weg in unser multiples Alignment, weil es im Vergleich zu anderen Fragmenten, mit denen es inkonsistent war, ein geringeres Gewicht hat. Deshalb führen wir zwischen allen Teilsequenzen, die durch unsere Ankerpunkte vorgegeben sind, unser DIALIGN-Verfahren erneut durch und wiederholen dies, bis es keine neuen Fragmente mit positivem Gewicht mehr gibt \cite{mdw96}. In der Praxis stellt man fest, dass es üblicherweise zu höchstens drei Iterationen kommt \cite{m99}. Wir können daher annehmen, dass die Anzahl an Durchläufen unseres Verfahrens konstant ist und für die Laufzeit nicht weiter in Betracht gezogen werden muss.

Denken wir an unser Beispiel zurück, dann stellen wir fest, dass das Fragment $f_{3,2,2} = $$ {\texttt{DG}}\choose{\texttt{DG}}$ aus der ersten und vierten Sequenz das positive Gewicht 2 hat. Es kann also unter Aktualisierung unseres Alignmentgraphen in unser multiples Alignment aufgenommen werden. Weitere geeignete Fragmente der Teilsequenzen gibt es nicht. Bei der nächsten Iteration stellt man demnach fest, dass kein neues Fragment ein positives Gewicht hat und wir können das Alignieren abbrechen.

Als abschließenden Schritt müssen wir die Ausgabe des Alignments vorbereiten. Dabei werden alignierte Symbole als Groß- und Waisen als Kleinbuchstaben dargestellt. Zudem sollen die Zuweisungsspalten genau übereinander stehen, wofür unter Umständen das Einfügen  von Leerzeichen in die Ausgabesequenzen nötig ist. Hierfür sortieren wir alle Fragmente für jede Sequenz nach Startpunkten und traversieren diese, sowie die Sequenzen selbst, der Reihe nach durch. Bei Bedarf werden Lücken eingefügt. Da die Länge jeder Sequenz in $\oh(1)$ ist, ist dies in $\oh(n^2\cdot L)$ möglich \cite{m99}.

Das finale Alignment unserer vier Beispielsequenzen mit DIALIGN 2.2 und einer $+3/-1$"=Substitutionsmatrix sieht dann so aus:
\ttfamily
\begin{enumerate}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item aDGTCTCA-----
	\item --G--TCADCTCa
	\item ---TATCADgg--
	\item -DG--TCADATC-
\end{enumerate}
\normalfont 

\subsection{Gesamtkomplexität}

Weil wir jetzt das komplette DIALIGN-Verfahren kennen, können wir abschließend die Laufzeit aller Teilschritte zusammenfassen und die Gesamtkomplexität bestimmen.

\begin{korollar}
	Mit DIALIGN	lässt sich ein multiples Sequenzalignment in $\oh(n^3\cdot L + n^2\cdot L^2)$ Zeit und mit $\oh(N_{\max} + n^2\cdot L)$ Speicherplatz berechnen.
\end{korollar}

\begin{beweis}
	Wir gehen davon aus, dass die Anzahl an Iterationen wie oben beschrieben in $\oh(1)$ liegt. Es folgt, dass die Laufzeit einer Iteration asymptotisch auch der Gesamtlaufzeit entspricht. 
	
	Mit unserem speichereffizienten Algorithmus lässt sich jedes paarweise Alignment in $\oh(L^2)$ Zeit und mit $\oh(N_{\max}) \in \oh(L^2)$ Speicherplatz berechnen \cite{m02}. Da es $\oh(n^2)$ paarweise Alignments gibt, folgt hierfür die Laufzeit in $\oh(n^2\cdot L^2)$. Die Werte für unsere Fragmente speichern wir sortiert in einer $\oh(n^2)$ großen Tabelle, wobei jeder Eintrag auf die Liste von Fragmenten eines paarweisen Alignments verweist. Da jedes von diesen bis zu $\oh(L)$ Segmente enthält, folgt der Speicherverbrauch von $\oh(n^2\cdot L)$ zu diesem Zeitpunkt.
	
	Mit Hilfe der Tabelle von sortierten Fragmenten und dem parallelen Traversieren über diese können wir in-place und in $\oh(n^3\cdot L)$ Zeit unsere Überlappgewichte berechnen. Diese Verbesserung von mir ist wichtig, weil sonst der naive Ansatz mit Laufzeit $\oh(n^4\cdot L^2)$ die Gesamtkomplexität dominiert hätte\cite{m99}. Bevor wir die Fragmente gierig in unser multiples Alignment einfügen können, müssen wir sie alle auf Basis ihrer Überlappgewichte sortieren. Mit einem effizienten Algorithmus wie beispielsweise Heapsort ist dies in $\oh(n^2\cdot L\cdot \log(n^2\cdot L))$ Rechenschritten möglich. 
	
	Im vorletzten Schritt von DIALIGN konstruieren wir unseren Alignmentgraphen und benutzen ihn, um die Transitivitäts- und somit die Konsistenzgrenzen zu berechnen. Er enthält $\oh(n\cdot L)$ Knoten mit bis zu $\oh(n^2\cdot L)$ Kanten und, wie in Satz \ref{satz:ssdp} bewiesen, kostet das Aktualisieren der Transitivitätsgrenzen $\oh(n^3\cdot L + n^2\cdot L^2)$ Rechenschritte. Das Vorbereiten der Ausgabe ist wie gerade erwähnt in $\oh(n^2\cdot L)$ Zeit möglich.
	
	Somit dominieren die Konsistenzgrenzen die Laufzeit und je nach $N_{\max}$ in unseren paarweisen Alignments auch den Speicherverbrauch. Es folgt die behauptete Laufzeit von $\oh(n^3\cdot L + n^2\cdot L^2)$ Rechenschritten und der benötigte Speicherplatz von $\oh(N_{\max} + n^2\cdot L)$. 
\end{beweis}

\section{Evaluierung, Zusammenfassung und Schwächen des Ansatzes}

\subsection{Evaluierung}

DIALIGN	wurde im Laufe der Zeit und nach jeder neuen Verbesserung ausführlichen Tests und Vergleichen zu anderen Programmen für multiple Sequenzalignments unterzogen. Diese möchte ich im Folgenden kurz zusammenfassen.

DIALIGN 1.0 wurde zunächst an einem Satz von elf DNA-Sequenzen getestet, die jeweils Helix-Loop-Helix-Bindungstellen für Proteine haben \cite{mdw96}. Diese Bindungsstellen mit einer Länge von etwa 30 DNA-Basen wurden experimentell gefunden und außerhalb dieser Regionen existieren keine erkennbaren Ähnlichkeiten zwischen den Sequenzen. Während DIALIGN in der Lage war alle elf Sequenzen korrekt miteinander zu alignieren, waren das Optimum der anderen Verfahren zwei korrekte Zuordnungen. Die verglichenen Programme waren dabei DFALIGN, PILEUP, CLUSTAL und GENALIGN. Auch bei den Vergleichen mit elf Programmen zum alignieren von Proteinsequenzen schnitt DIALIGN neben CLUSTAL V und DFALIGN unter den besten dreien ab.

Es ist sinnvoll bei zu alignierenden Sequenzen zwischen lokal und global verwandten zu unterscheiden. Lokal verwandte haben nur Ähnlichkeiten in begrenzten Abschnitten, während der Rest höchstens zufällige Übereinstimmungen enthält. Hier ist es optimal lediglich die ähnlichen Segmente ins Alignment aufzunehmen und die nicht verwandten zu ignorieren. Global verwandte Sequenzen haben hingegen Ähnlichkeiten, die sich über die volle Länge der Sequenzen ziehen und wo es nur vereinzelt zu Deletionen, Insertionen oder Punktmutationen kommt.

Beim Testen von DIALIGN 2.0 an verschiedenen Testsequenzen hat man festgestellt, dass DIALIGN 1 und 2.0 auf global verwandten Sequenzen vergleichbar zu globalen Alignern wie CLUSTAL W und DCA zu sein scheinen \cite{mahd98}. Bei lokal verwandten Sequenzen war DIALIGN 2.0 allen anderen getesteten Programmen hingegen weit überlegen. Ein weiterer Vorteil ist, dass DIALIGN 2.0 anders als der Vorgänger und viele der anderen Programme unabhängig von benutzerdefinierten Eingaben war.

Da große Alignments sehr rechenintensiv sein können, ist es außerdem wichtig die Laufzeit der Verfahren im Auge zu behalten. Progressive Alignierer wie beispielsweise CLUSTAL W starten damit nach dem Berechnen paarweiser Alignments zunächst die beiden ähnlichsten Sequenzen zu verwenden und dann der Reihe nach die jeweils ähnlichste Sequenz ins multiple Alignment einzufügen, bis alle Sequenzen Teil der Zuordnung sind.  Die erste Version von DIALIGN hatte eine Laufzeit, die etwa um den Faktor 100 langsamer war, als vergleichbare globale Alignierer. Durch die Verwendung des graphtheoretischen Ansatzes für die Konsistenzgrenzen von Abdedda\"im konnte dieser Unterschied in etwa um den Faktor zehn gesenkt werden \cite{am00}. Es ist denkbar, dass die speichereffiziente Berechnung der paarweisen Alignments die Lücke weiter geschlossen hat, indem aufgrund des geringeren Speicherverbrauchs weniger Seitenfehler und damit teure I/O-Operationen auftreten.


\subsection{Zusammenfassung}

Wir haben in diesem Kapitel den DIALIGN-Ansatz für multiple Sequenzalignments kennengelernt. DIALIGN erstellt multiple Alignments, indem zuerst mit einem speichereffizienten Algorithmus über dynamische Programmierung paarweise Alignments berechnet werden. Mit Hilfe vom parallelen Traversieren über sortierte Listen können wir dann effektiv die Überschneidungen der Fragmente finden und diese damit neu gewichten. Nachdem wir unsere Fragmente nach ihren Gewichten sortiert haben, fügen wir sie der Reihe nach in unser multiples Alignment und unseren Alignmentgraphen ein, vorausgesetzt die Konsistenz wird durch sie nicht verletzt. Die so entstandenen Anker wählen wir dann als Grenzen für Teilsequenzen und führen zwischen diesen iterativ das selbe Verfahren solange durch, bis es keine Fragmente mit positiven Gewichten mehr gibt. Zum Schluss konstruieren wir die Ausgabe, indem wir nichtalignierte Symbole klein und alignierte groß schreiben, sowie Lücken in unsere Sequenzen einfügen, sodass alle Stellen eines Ankers genau in einer Spalte stehen. 

DIALIGN aligniert nur die Segmente der Sequenzen miteinander, die auch wirklich ähnlich zueinander sind, während globale Alignierer selbst dann versuchen die ganzen Sequenzen einander zuzuordnen, wenn es nur lokale Übereinstimmungen gibt. Das bietet einen großen Vorteil bei lokal verwandten Sequenzfamilien. Viele dezidierte Algorithmen für lokale Alignments, wie beispielsweise der auf Needleman-Wunsch basierende Smith-Waterman-Algorithmus, sind nur in der Lage eine einzige Region mit Übereinstimmungen zu finden. DIALIGN hingegen kann auch mehrere weit voneinander entfernte lokale Übereinstimmungen finden oder gleich globale Alignments mit angemessener Genauigkeit berechnen \cite{mdw96}. In diesem Sinne ist es ein sehr flexibler Algorithmus, der für eine Vielzahl an Anwendungen angemessen ist. 

Erinnern wir uns zurück an die gängigsten Mutationen, die auf den von uns untersuchten Sequenzen vorkommen: Deletionen und Insertionen von ganzen Abschnitten oder Punktmutationen, bei denen einzelne Basen oder Aminosäuren durch andere ersetzt werden. Man stellt fest, dass jede dieser Situationen sich in DIALIGN wiederfindet. Punktmutationen zeigen sich durch Abweichungen einzelner Stellen in längeren Fragmenten und mit gelöschten oder eingefügten Segmenten gehen wir um, indem ein einzelnes längeres Fragment in zwei oder mehr kürzere aufgeteilt wird \cite{mfdw98}. Es ist außerdem anzunehmen, dass der segmentbasierte Ansatz von DIALIGN insofern für die Benutzer angenehmer ist, als dass nicht auf Biegen und Brechen versucht wird die kompletten Sequenzen in ein Alignment einzufügen, selbst wenn es keine Ähnlichkeit gibt. Man stellt fest, dass es für einen Alignierer fast genauso wichtig ist, nichtverwandte Abschnitte auch nicht zuzuordnen, wie es wichtig ist, dies für verwandte zu tun. Denn sonst muss der Forscher, der das Alignment später benutzt, erst mühsam von Hand feststellen, welche Abschnitte eigentlich die gesuchten Motive sind \cite{m99}.

\subsection{Schwächen von DIALIGN}

Es gibt im Allgemeinen zwei Gründe, warum automatisierte Alignmentverfahren wie beispielsweise DIALIGN biologisch unzureichende Ergebnisse liefern können: Entweder die Gütefunktion, also in unserem Fall der Score unseres Alignments, bildet die Wirklichkeit unzureichend ab und weist bedeutungslosen Abschnitten größere Werte zu, als anderen wichtigen Motiven. Oder aber die Gütefunktion ist grundsätzlich richtig, aber dafür werden beim zusammensetzen des multiplen Alignments die falschen Fragmente ausgewählt. In diesem Fall liegt das Problem bei unserer Heuristik, die gierig die Fragmente nach Gewicht und Konsistenz auswählt. 

Um festzustellen wie sich DIALIGN weiter verbessern lässt, muss man zuerst die Güte unserer Ergebnisse quantifizieren und dann überprüfen, ob die obigen Situationen auftreten. Bei der Quantifizierung gibt es zunächst zwei verschiedene Möglichkeiten, wie man feststellen kann, ob und wie gut ein Alignment wirklich ist. Als erstes brauchen wir dafür fertige Alignments zum Vergleich von denen wir wissen, dass sie korrekt sind. Solche finden sich beispielsweise in Testdatenbanken wie BAliBASE, die eine Vielzahl von Zuordnungen auf unterschiedlichen Klassen von Sequenzen bieten. Das erste Gütekriterium ist der \emph{Sum-of-Pairs}-Score, der in Prozent angibt wie viele paarweise korrekte Übereinstimmungen es im Vergleich zur Referenz gab. Die zweite Möglichkeit ist der \emph{Column}-Score, der überprüft wie viele ganze Spalten korrekt aligniert wurden \cite{mpps06}. Grundsätzlich ist letzterer das bessere Maß, weil wir Ähnlichkeiten über die komplette Menge an Sequenzen hinweg finden wollen. Es kann jedoch passieren, dass in beinahe jeder Spalte eine einzige fehlerhafte Zuordnung auftritt, was in einem sehr niedrigen Column-Score resultieren würde, obwohl das Alignment eigentlich nicht so schlecht ist.

\cite{mpps06} haben DIALIGN auf einer Vielzahl von Sequenzen untersucht, um festzustellen welche Probleme beim Alignieren auftreten. Die schlechte Nachricht: beide der oben genannten treten auf, abhängig von den zu alignierenden Sequenzen. Das erste Testalignment war eine Menge von Genen des Pufferfischs \emph{Takifugu rubripes}. Diese enthalten sogenannte Hoxgene, die die Ausbildung von Vorder- (Kopf) und Hinterteilen (Schwanz) bei der Klasse der Bilateria regulieren. Zu den Bilateria gehören alle Tiere, die einen bilateralsymmetrisch aufgebauten Körper haben, also beispielsweise alle Säugetiere, Würmer, Fische, Fische oder Amphibien. Die Hoxgene sind evolutionär gesehen sehr alt und ihre Geschichte wurde durch viele Tandemduplikate dominiert. Tandemduplikate sind gleiche oder sehr ähnliche Abschnitte, die an mehreren Stellen innerhalb der Sequenzen vorkommen. Im schlimmsten Fall kommt es dann dazu, dass die falschen Hoxgene miteinander aligniert werden. Weil diese sehr ähnlich sind, ist es wahrscheinlich, dass sie einander zugewiesen werden und die Alignments hohe Gewichte haben. Biologisch sind diese Zuweisungen aber von geringem Wert, weil es eben nicht die richtigen Paare von Hoxgenen in unserem Alignment waren. Genau diese Erfahrung hat man auch bei \emph{Takifugu rubripes} gemacht. Das DIALIGN-Ergebnis hatte zwar einen um 13\% höheren Score, als das korrekte Ergebnis, der Column-Score lag dagegen bei 0\% und selbst die Residuenpaare waren nur zu 33\% richtig. Ergebnisse wie dieses sind ein klares Ergebnis dafür, dass die Gütefunktion von DIALIGN in manchen Fällen versagt. Bei diesem extremen Beispiel ist es aufgrund der geringeren Korrelation zwischen der mathematischen und der biologischen Ähnlichkeit der Hoxgene schwer eine entsprechende Gütefunktion zu finden. Mögliche Ansätze können Machine Learning oder semiautomatisierte Verfahren sein, wo ein Mensch mit Expertenwissen bestimmte Abschnitte von Hand zuweist (Verankerung \footnote{Im englischen Original auch \enquote{anchor}. Um Verwirrung mit unseren Ankern vorzubeugen hier umbenannt.}) und lediglich die Abschnitte dazwischen maschinell aligniert \cite{mpps06}. Man hat jedoch auch weitere Sequenzfamilien in BAliBASE gefunden, bei denen der Score bei schlechteren Alignments stieg. In diesem Fall kann man über bessere Gütefunktionen nachdenken, weil bessere Heuristiken das Problem nicht lösen. Schließlich basieren sie auf den Ergebnissen der anscheinend unzureichenden Gütefunktionen.

Bei anderen Sequenzen hat man hingegen festgestellt, dass die korrekten Alignments Scores haben können, die bis zu 15\% über den Ergebnissen von DIALIGN liegen. In diesem Fall ist das Problem vermutlich die Heuristik, die gierig die Fragmente mit den höchsten Gewichten wählt. Wenn man Pech hat läuft man so in ein lokales Maximum, indem man Fragmente wählt, die hohe Gewichte, aber geringen biologischen Wert haben und über Inkonsistenzen verhindern, dass andere bedeutungsvollere Zuweisungen gewählt werden. Auch mathematisch kann der gierige Ansatz suboptimale Ergebnisse liefern, indem ein einziges großes Fragment das Hinzufügen mehrerer kleiner verhindert, die summiert ein größeres Gesamtgewicht hätten. Weil das nicht optimale, große Fragment nie wieder aus unserem multiplen Alignment entfernt werden kann, sind wir auch nicht in der Lage die anderen Segmente auszuwählen \cite{m99}. 

Um diesem Problem vorzubeugen lernen wir im nächsten Kapitel eine neue, verbesserte Heuristik für DIALIGN kennen. Das Verfahren von \cite{cpm10} basiert auf Flussnetzen und weiteren graphtheoretischen Ansätzen, die eine flexiblere Auswahl der Anker unseres multiplen Alignments ermöglichen.