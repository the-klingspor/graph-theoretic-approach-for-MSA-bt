\chapter{DIALIGN}
\label{ch:DIALIGN}
In diesem Kapitel stelle ich zunächst das DIALIGN-Verfahren für multiples Sequenzalignment nach \cite{mdw96} vor. Dabei werde ich alle Anpassungen und Verbesserungen des Verfahrens vorstellen, die bis zur Version 2.2 umgesetzt wurden. Anders als der im letzten Kapitel vorgestellte Algorithmus von Needleman-Wunsch aligniert DIALIGN keine einzelnen Symbole, sondern gleich ganze Segmente der Eingabesequenzen. Das hat die Vorteile, dass man zum einen auf die Kosten zum Einfügen von Lücken verzichten kann und dadurch weitgehend von benutzerdefinierten Eingaben unabhängig wird, und weiterhin ist man so in der Lage sowohl global, als auch lokal verwandte Sequenzen einander auszurichten: Wenn man feststellt, dass in einem Bereich keine Segmente vorliegen, die einander ähnlich sind, dann verzichtet man darauf diese sich gegenseitig zuzuweisen und sie werden nicht Teil des \emph{Alignments}. 

DIALIGN	kann genau wie Needleman-Wunsch im Sinne der jeweiligen Zielfunktion mathematisch optimale paarweise \emph{Alignments} berechnen. Anders als bei letzterem, kann man aber auch mit Hilfe einer Heuristik effizient multiple Alignments berechnen, die aus drei oder mehr Sequenzen bestehen. Das grobe Vorgehen sieht dabei wie folgt aus:

\begin{algorithm}
	\caption{DIALIGN}
	\label{alg:dialign}
	\begin{algorithmic}[1]
		\Require Menge $S$ von Sequenzen mit $|S| = n$
		\Procedure{DIALIGN}{$S$}
		\State Weise allen möglichen Fragmenten $f$ ein Gewicht $w^*(f)$ zu
		\State \begin{varwidth}[t]{\linewidth}
			Berechne mit dynamischer Programmierung alle möglichen ${n}\choose{2}$ paarweisen\par
			\hskip\algorithmicindent Alignments aus $S$
			\end{varwidth}
		\State Sortiere alle Fragmente der paarweisen Alignments nach ihrem Gewicht als $f_{1, \dots, n}$
		\State $A \gets \emptyset$ \Comment{Initialisiere Ausgabe für Alignment}
		\For{i=1, \dots , n} 
			\If{$f_i$ ist zu allen bisher gewählten Fragmenten \emph{konsistent}}
				\State $A \cup \{f_i\}$\Comment{Füge $f_i$ zum \emph{Alignment} hinzu}
			\EndIf
		\EndFor
		\State \textbf{return} $A$
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

Unter \emph{Konsistenz} können wir uns zunächst informell vorstellen, dass es bei einer Zuweisung weder zu Überkreuzungen kommt, noch dazu, dass ein Symbol einer Sequenz gleichzeitig mehreren einer anderen zugewiesen wird.\unsure{Möchte ich das lieber hier haben oder zwischen Definition und Beispielen zu Konsistenz}

\section{Theoretische Grundlagen}

Um multiple Sequenzalignments genauer zu verstehen und die dazu nötigen Algorithmen analysieren zu können, brauchen wir einige Definitionen. Diese sind \citet{mdw96}, \citet{am00} und \citet{cpm10} entnommen. Dazu betrachten wir im Folgenden eine $n$-stellige Menge von Sequenzen $S$ über einem endlichen Alphabet. Dabei gibt $L_i$ die Länge der $i$-ten Sequenz an.

\begin{definition}[Stelle und Stellenraum]
	Eine \emph{Stelle} ist ein Tupel $(i,p)$, bei dem $i$ die Sequenz und $p$ die Position eines Zeichens innerhalb dieser Sequenz angibt. Als \emph{Stellenraum} bezeichnen wir die Menge aller Stellen über unseren Sequenzen $S$: $\mathcal{S} \coloneqq \{(i,p)|1 \leq i \leq n, 1 \leq p \leq L_i \}$ \\
	Der Einfachheit identifizieren wir die \emph{Stellen} der $i$-ten Sequenz als $\mathcal{S}_i$. Auf dem \emph{Stellenraum} existiert eine Halbordnung `$\preceq$', wobei $(i,p) \preceq (i',p')$ genau dann gilt, falls $i=i'$ und $p\leq p'$.
\end{definition}

Nachdem wir bis jetzt nur umgangssprachlich mit \emph{Alignments} und \emph{Konsistenz} zu tun hatten, möchte ich diese Begriffe nun formalisieren.

\begin{definition}[Alignment und Konsistenz]
	Ein \emph{Alignment} $\mathcal{A}$ ist eine Äquivalenzrelation auf der Menge $\mathcal{S}$, die ein bestimmtes \emph{Konsistenzkriterium} erfüllt. Sei zunächst $\mathcal{R}$ eine beliebige binäre Relation auf $\mathcal{S}$. Wir können diese mit `$\preceq$' zu der Präordnung (auch Quasiordnung genannt) $\preceq_{\mathcal{R}=(\preceq \cup \mathcal{R})_t}$ erweitern, also einer zweistelligen Relation, die reflexiv und transitiv, aber nicht antisymmetrisch ist. Hierbei bezeichnet $\mathcal{X}_t$ die transitive Hülle einer Relation $\mathcal{X}$. 
	
	Wir bezeichnen $\mathcal{R}$ als \emph{konsistent}, wenn $\preceq_{\mathcal{R}}=(\preceq \cup\: \mathcal{R})_t$ die natürliche Ordnung auf jeder Sequenz erhält, also $x \preceq_{\mathcal{R}} y \implies x \preceq y$ für alle $x,y \in S_i \forall 1\leq i \leq n$ gilt. Außerdem nennen wir eine Menge von Relationen $\{\mathcal{R}_1, \dots, \mathcal{R}_n\}$ \emph{konsistent}, wenn ihre Vereinigung $\cup_i \mathcal{R}_i$ \emph{konsistent} ist, sowie ein Paar $(x,y) \in \mathcal{S}^2$ \emph{konsistent} mit einer Relation $\mathcal{R}$, falls $\mathcal{R} \cup \{(x,y)\}$ \emph{konsistent} ist.
	
	Für ein Alignment $\mathcal{A}$ und $(x,y)$ gilt $x\mathcal{A}y$ genau dann, wenn die \emph{Stellen} $x$ und $y$ durch $\mathcal{A}$ aligniert werden oder identisch sind.
\end{definition}

Im Folgenden wollen wir zwei Beispiele betrachten, um das Konzept der \emph{Konsistenz} und \emph{Alignments} besser zu veranschaulichen. Informell können wir uns ein \emph{Alignment} als eine Relation vorstellen, bei der es weder zu einer Überkreuzung von Zuweisungen kommt, noch zu Fällen, bei denen ein Symbol (transitiv) gleichzeitig mehreren Symbolen aus einer einzigen anderen Sequenz zugewiesen ist.

\begin{beispiel}
	\begin{center}
	\begin{tikzcd}
		a_1 \arrow[rrdd, no head] & a_2 & a_3 & a_4 & a_5 \\
		b_1 \arrow[d, no head] & b_2 & b_3 & b_4 \arrow[lu, no head] & b_5 \\
		c_1 & c_2 & c_3 & c_4 \arrow[u, no head] & c_5
	\end{tikzcd}
	\end{center}
	Für alle \emph{Stellen}, die aus der selben kommen Sequenz stammen, gilt $x \preceq_{\mathcal{R} y \implies x \preceq y}$, wie beispielsweise für $a_1$ und $a_5$: $a_1 \mathcal{A} c_3, c_3 \preceq c_4, c_4 \mathcal{A} b_4, b_4 \mathcal{A} a_3$ und $a_3 \preceq a_5$. Es folgt $a_1 \preceq_{\mathcal{R}} a_5$. Also ist die Relation auf $\mathcal{S}$ \emph{konsistent} und somit ein \emph{Alignment}.
	
	\begin{center}
	\begin{tikzcd}
		a_1 \arrow[rdd, no head] & a_2 & a_3 & a_4 \arrow[rdd, no head] & a_5 \\
		b_1 & b_2 & b_3 \arrow[ru, no head] & b_4 & b_5 \\
		c_1 \arrow[ruu, no head] & c_2 & c_3 & c_4 & c_5 \arrow[u, no head]
	\end{tikzcd}
	\end{center}
	Hier handelt es sich um kein \emph{Alignment}, denn die \emph{Konsistenz} ist gleich an mehreren Stellen verletzt. Erstens gilt $a_2 \preceq_{\mathcal{R}} a_1$, denn $a_2 \mathcal{A} c_1, c_1 \preceq c_2$ und $c_2 \mathcal{A} c_1$. Da aber $c_1 \preceq c_2$ gilt, erhält die Relation die natürliche Ordnung auf der erstens Sequenz nicht. Der Grund liegt hier an der Überkreuzung von mehreren Zuweisungen. Des Weiteren gilt $b_5 \preceq_{\mathcal{R}} b_3$, weil $b_5 \mathcal{A} c_5, c_5 \mathcal{A} a_4$ und $a_4 \mathcal{A} b_3$, aber $b_5 \npreceq b_3$. Hier ist das Problem eine transitive Mehrfachzuweisung von mehreren Symbolen der einen Sequenz auf das gleiche einer anderen (sowohl $b_3$ als auch $b_5$ stehen in Relation zu beispielsweise $a_4$). 
\end{beispiel}

Es lässt sich zeigen, dass eine Relation $\mathcal{A}$ genau dann ein \emph{Alignment} ist, wenn es möglich ist zwischen den alignierten Symbolen Lücken einzufügen, sodass gerade die einander zugewiesenen untereinander stehen. Deshalb bezeichnet man die Äquivalenzklassen $[x]_{\mathcal{A}} = \{y \in \mathcal{S} \colon x\mathcal{A}y \}$ von $\mathcal{A}$ auch als \emph{Spalten}. Man kann sich leicht überlegen, dass das bei Überkreuzungen und transitiven Mehrfachzuweisungen nicht möglich ist. Bei unserem ersten Beispiel von oben würde das so aussehen:

\begin{beispiel}
	\begin{center}
	\begin{tikzcd}
		- & - & A_1 \arrow[dd, no head] & a_2 & A_3 \arrow[d, no head] & a_4 & a_5 \\
		b_1 & B_2 \arrow[d, no head] & - & b_3 & B_4 \arrow[d, no head] & b_5 & - \\
		c_1 & C_2 & C_3 & - & C_4 & c_5 & -
	\end{tikzcd}
	\end{center}
Alle Symbole, die Teil einer Zuweisungsspalte sind, also einer Äquivalenzklasse mit mehr als einer \emph{Stelle}, wurden als Großbuchstabe dargestellt, während die unalignierten kleingeschrieben wurden.
\end{beispiel}

Da DIALIGN ein segmentbasiertes Alignmentverfahren ist, brauchen wir noch eine Bezeichnung für eine paarweise, lückenlose Zuweisung von direkt aufeinanderfolgenden Elementen zweier Sequenzen.

\begin{definition}[Fragment]
	Gegeben seien zwei Sequenzen $S_1$ und $S_2$ und ein \emph{Alignment} $\mathcal{A}$ auf diesen Sequenzen. Dann definieren wir das \emph{Fragment} mit Länge $l$, das an den Stellen $i$ in $S_1$ und $j$ in $S_2$ endet mit $1 \leq i \leq l(S_1), 1 \leq j \leq l(S_2)$ und $i - l \geq 0 \leq j - l$, als $f_{i,j,l}$, wenn $S_1[i-k] \, \mathcal{A} \, S_2[j-k] \, \forall \, 0 \leq k \leq l - 1$ gilt. Manchmal werden \emph{Fragmente} auch als \emph{diagonals} bezeichnet, weil sie in der Matrix des Needleman-Wunsch-Verfahrens als Diagonale von mehreren aufeinanderfolgenden einander zugeordneten Symbolen stehen würden.
\end{definition}

Wir können unter einem \emph{Alignment} auch eine Kette von zueinander \emph{konsistenten Fragmenten} verstehen.

\section{Gewichtsfunktionen und Substitutionsmatrizen}
\subsection{Gewichtsfunktionen in DIALIGN 1}

Um zwei \emph{Fragmente} miteinander vergleichen zu können, müssen wir die Ähnlichkeit zwischen ihnen quantifizieren. Je ähnlicher sich zwei \emph{Fragmente} sind, desto eher können wir davon ausgehen, dass sie einen gemeinsamen evolutionären Ursprung haben und als desto wichtiger schätzen wir sie für unser \emph{Alignment} ein. In der ersten Variante von DIALIGN hat man eine starre stochastische Gewichtsfunktion benutzt, indem man davon ausging, dass alle Symbole gleichverteilt mit Wahrscheinlichkeit $p = 0,25$ für DNA und $p = 0,05$ für Proteine auftreten \citep{mdw96}. Gegeben sei ein \emph{Fragment} $f$ der Länge $l$, mit $m$ in beiden Sequenzen übereinstimmenden Symbolen. Dann lautet die Wahrscheinlichkeit, dass ein solches \emph{Fragment} der Länge $l$ $m$ oder mehr Übereinstimmungen hat wie folgt:

\begin{equation}
	P(l,m) = \sum_{i=m}^{l} {l \choose i} \cdot p^i \cdot (1-p)^{l-i}
\end{equation}

Wie in anderen Disziplinen, wie der Informationstheorie oder statistischen Mechanik benutzen wir als Gewichtsfunktion nun den negativen Logarithmus von $P(l,m)$. Dadurch bekommen wir ein umso höheres Gewicht, je niedriger die Wahrscheinlichkeit ist, dass das vorliegende \emph{Fragment} zufällig entstanden ist. Ziel wird es im Folgenden sein die Summe der Gewichte aller \emph{Fragmente} eines \emph{Alignments} zu maximieren. Diese bezeichnen wir als \emph{Score} des \emph{Alignments}.

\begin{equation}
	w(f) \coloneqq -\ln(P(l,m))	
\end{equation}

\subsection{Substitutionsmatrizen}

Es hat sich jedoch herausgestellt, dass diese Gewichtsfunktion nicht immer zielführend ist. Nicht alle Aminosäuren sind gleich ähnlich und die Übergangswahrscheinlichkeiten zwischen ihnen können dramatisch verschieden sein. So ist beispielsweise eine Veränderung von Arginin zu Lysin recht wahrscheinlich, während jene von Tryptophan zu Glycin nur sehr selten vorkommt \citep{p13}. 

Deswegen verwenden wir genau wie bei Needleman-Wunsch Substitutionsmatrizen, wie beispielsweise BLOSUM62, um die Ähnlichkeit zwischen zwei \emph{Fragmenten} zu berechnen. Sei dazu $f_{i,j,l}$ ein \emph{Fragment} aus den zwei Sequenzen $S_1$ und $S_2$ und $M$ eine Substitutionsmatrix. Dann berechnet folgende Formel das Gewicht von $f_{i,j,l}$:

\begin{equation}
	w(f_{i,j,l}) \coloneqq \sum_{k=1}^{l} M[i\!-\!l\!+\!k,j\!-\!l\!+\!k]
\end{equation}

Dieses Vorgehen hat einige Vorteile gegenüber der alten Gewichtsberechnung. Zum einen kann man das Gewicht eines \emph{Fragments} $f_{i,j,l}$ sehr einfach berechnen, wenn man das Gewicht des \emph{Fragments} $f_{i-1,j-1,l-1}$ bereits kennt, indem man einen einzigen Ähnlichkeitswert zur Summe hinzu addiert. Zum anderen kann man die Berechnung vieler Gewichte frühzeitig abbrechen und zwar, wenn eine Teilsumme der Ähnlichkeitswerte negativ ist. Dann weiß man, dass ein \emph{Alignment} mit höherem \emph{Score} berechnen werden kann, wenn man diesen Teil des Fragments weglässt. Diese beiden Eigenschaften werden wir uns im nächsten Abschnitt über die effiziente Berechnung der paarweisen \emph{Alignments} zunutze machen.

Nun wollen wir Substitutionsmatrizen und die Theorie dahinter genauer betrachten. Das werden wir anhand der von \cite{hh92} entwickelten BLOcks Substitution Matrix (BLOSUM) tun, da andere verbreitete Substitutionsmatrizen ähnlich entstanden sind. Die Matrizen wurden empirisch bestimmt, indem man sich Blöcke von Proteinmotiven anguckte, bei denen ein korrektes \emph{Alignment} bekannt war. Als \emph{Block} bezeichnen wir einen längeren, zusammenhängenden alignierten Bereich ohne gelöschte oder eingefügte Segmente. Für die Berechnung eines Eintrags der Matrix $M_{i,j}$ brauchen wir die Wahrscheinlichkeit, mit der die beiden Aminosäuren auftreten $q_i$ und $q_j$, sowie die Wahrscheinlichkeit, dass gerade diese beide Aminosäuren miteinander aligniert werden $p_{i,j}$.

\begin{equation}
	M_{i,j} \coloneqq \frac{1}{\lambda} \log\bigg( \frac{p_{i,j}}{q_i\cdot q_j} \bigg)
\end{equation}

Der Korrekturterm $\lambda$ wird benutzt, um die Werte auf ganze Zahlen zu runden, die weniger anfällig für Rundungsfehler und andere Ungenauigkeiten in der Computerarithmetik sind. Diese Vorgehensweise wird, da man den Logarithmus einer Wahrscheinlichkeit berechnet, als \emph{log-odd}-Verfahren bezeichnet. Der Eintrag $M_{i,j}$ gibt ein Maß für die Wahrscheinlichkeit an, dass das betrachtete Paar in einem \emph{Alignment} aus genau diesen beiden Aminosäuren auftritt und die Wahrscheinlichkeit für eine längere Folge aufeinanderfolgender Paare wird mit der Summe der Einträge berechnet. Das funktioniert aufgrund der Rechenregeln des Logarithmus: $\log(p_1 \cdot p_2) = \log(p_1) + \log(p_2)$. Möchte man die ursprünglichen Wahrscheinlichkeiten berechnen, muss man lediglich die Summe der Ähnlichkeitswerte exponentieren. 

\cite{hh92} haben mehrere Substitutionsmatrizen entwickelt. Die Zahl hinter jeder BLOSUM gibt die Ähnlichkeit der zur Berechnung der Matrix verwendeten Proteinsequenzen an. Für die BLOSUM62 wurden beispielsweise nur Blöcke benutzt, bei denen es eine Ähnlichkeit von höchstens 62\% gab. Im Allgemeinen wird dazu geraten BLOSUMs mit geringen Suffixen wie beispielsweise BLOSUM45 zum alignieren von entfernt verwandten, mit großen wie BLOSUM80 für eng verwandte und BLOSUM62 für durchschnittlich eng verwandte Sequenzen zu benutzen.

BLOSUM62\improvement{BLOSUM62 IM ANHANG???}

Bei DNA wird meistens nur eine simple Unterscheidung zwischen Treffern und Nichttreffern gemacht. Als Substitutionsmatrix entspräche dies der Einheitsmatrix. Dies hat aber die Nachteile, dass alle \emph{Fragmente} positive Gewichte haben und damit potentiell für unser \emph{Alignment} in Betracht kommen. Besser sind positive Werte für ähnliche und negative für sehr unähnliche Abschnitte, weil sich so der Rechenaufwand verringern lässt. Außerdem kann man mit Matrizen, die dem Einsatzgebiet angepasst sind, oft bessere Ergebnisse erzielen. Nach \cite{p13} sind die Ähnlichkeiten zwischen zu vergleichenden DNA-Sequenzen deutlich größer, als bei Proteinen. Sie betragen zwischen homologen menschlichen DNA-Abschnitten etwa 99,9\% und bei proteinkodierenden Regionen zwischen Mensch und Maus immer noch 80\%, während Ähnlichkeiten von unter 50\%, anders als bei Proteinen, quasi nicht mehr zu entdecken sind. Dementsprechend können +1/-3 für Treffer und Nichttreffer bei 99\%, +2/-3 bei 90\% und +5/-4 bei 70\% Übereinstimmung benutzt werden.

Ich muss jedoch zugeben, dass die Wahl der richtigen Substitutionsmatrix ein bisschen dem Henne-Ei-Problem ähnelt: um die Ähnlichkeit von zwei Sequenzen zu bestimmen, müssen wir sie mit der passenden Matrix alignieren. Für die Wahl dieser Matrix sollten wir jedoch wissen, wie ähnlich sich die beiden Sequenzen sind.

Wann genau sich die Berechnung der Gewichte in DIALIGN verändert hat, steht leider in keiner Veröffentlichung, auch wenn sie bereits in \cite{mdw96} als kommende Ergänzung in Betracht gezogen wurde. Spätestens in DIALIGN TX, der neuesten Version des Programms wie wir sie auf der Website der Göttinger Bioinformatik finden \citep{DIALIGNTX}, wird diese Technik jedoch angewendet. Dort dient eine modifizierte BLOSUM 62, die nur nichtnegative Werte enthält, als Matrix für Proteinsequenzen, während bei DNA lediglich die Einheitsmatrix benutzt wird.

\subsection{Gewichtsfunktionen in DIALIGN 2} 

In der ursprünglichen Version von DIALIGN gab es noch einen benutzerdefinierten Parameter $T$, der das minimale Gewicht eines in Betracht zu nehmenden \emph{Fragments} angab. Dieser wurde eingeführt, damit nicht kleine, zufällige Übereinstimmungen ihren Weg in das \emph{Alignment} finden. Denn für ein gutes \emph{Alignment} ist es genauso wichtig, dass nicht miteinander verwandte Abschnitte einander auch nicht zugewiesen werden, wie es wichtig ist, dass dies bei verwandten getan wird. Bei Tests mit DIALIGN 1 hat man jedoch festgestellt, dass ein Großteil der ausgewählten \emph{Fragmente} nur knapp über der Gewichtsgrenze $T$ lagen und wenn man diese senkte, sank das Gewicht der \emph{Fragmente} auch \citep{mahd98}. 

Das liegt daran, dass die Gewichtsfunktion $w$ einem langen \emph{Fragment} $f$ quasi das gleiche Gewicht zuordnet, wie die Summe der Gewichte der Teilfragmente $f_1, \dots, f_n$, wenn man $f$ in diese teilt. Das sorgt dafür, dass man oft bessere \emph{Scores} erhält, wenn man größere Fragmente aufteilt und dazwischen einzelne Regionen mit geringen Übereinstimmungen weglässt, statt große \emph{Fragmente} auszuwählen. Neben der Abhängigkeit vom willkürlichen Parameter $T$ und der Tendenz kleine, unbedeutende Übereinstimmungen auszuwählen, hat dies auch den Nachteil, dass die rechenintensive Aktualisierung der Konsistenzgrenzen öfter durchgeführt werden muss. 

Deshalb ist man in DIALIGN 2 dazu übergegangen statt der Wahrscheinlichkeit $P(l,m)$, dass in einem \emph{Fragment} der Länge $l$ mindestens $m$ Übereinstimmungen auftreten, zu berechnen, wie wahrscheinlich es ist, dass in den beiden Gesamtsequenzen $S_1$ und $S_2$ mit Längen $l_1$ respektive $l_2$ überhaupt eine Sequenz mit Länge $l$ und $m$ Übereinstimmungen auftritt. 

\begin{equation}
	P^*(l,m) \approx l_1\cdot l_2\cdot P(l,m)
\end{equation}

Als neue Gewichtsfunktion $w^*$ ergibt sich dann mit $K \coloneqq \log(l_1) + \log(l_2)$:

\begin{equation}
	w^*(f) \coloneqq w(f) - K
\end{equation}

Wenn man $f$ nun in $f_1, \dots f_n$ aufteilt, wird der Korrekturterm $K$ nicht nur einmal, sondern n-mal abgezogen. Das sorgt dafür, dass tendentiell längere \emph{Fragmente} ausgewählt werden \citep{m99}. Ein weiterer Vorteil ist, dass der Erwartungswert des Gewichts eines zufälligen \emph{Fragments} nicht mehr 1, sondern 0 ist. Dadurch haben alle Abschnitte mit unterdurchschnittlicher Ähnlichkeit automatisch negative Gewichte und wir haben eine einfache und schnelle Möglichkeit zu entscheiden, ob ein \emph{Fragment} weiter für unser \emph{Alignment} in Betracht gezogen werden muss.

Wie sich der Effekt von $w^*$ auswirkt, wenn man eine Substitutionsmatrix benutzt, die einem zufälligen \emph{Fragment} im Schnitt ein negatives Gewicht zuordnet, werden wir später nach der Programmierung empirisch feststellen. Möglicherweise ist es dann besser auf ihn zu verzichten. Mit einer (+2/-3)-Matrix haben wir beispielsweise einen Erwartungswert von $E(w(f_{i,j,l})) = \big( \frac{3}{4}\cdot(-3) + \frac{1}{4}\cdot2 \big) \cdot l = -\frac{7}{4}\cdot l$ für ein zufälliges DNA-\emph{Fragment} der Länge $l$. Ein anderer Ansatz verbindet die Substitutionsmatrix mit dem Korrekturterm $K$, indem wir wie DIALIGN TX eine Substitutionsmatrix benutzen, die aber keine negativen Werte enthält. Dafür ziehen wir aber weiterhin $K$ vom Gewicht ab.
 
\section{Paarweise Alignments mit dynamischer Programmierung}

Nachdem wir uns jetzt genauer mit den Gewichten von Fragmenten beschäftigt haben, können wir uns der Berechnung der paarweisen \emph{Alignments} mit Hilfe von dynamischer Programmierung widmen. Dabei beziehe ich mich, außer wenn anders gekennzeichnet, auf die speichereffiziente Umsetzung aus DIALIGN 2.2, die in \cite{m02} vorgestellt wurde. 

Wie bei dynamischer Programmierung üblich, stellen wir zunächst eine Rekursionsgleichung auf. Sei dazu $Sc[i,j]$ der maximal mögliche \emph{Score} aller \emph{Fragmente} bis zu den Elementen $S_1[i]$ und $S_2[j]$ zweier Sequenzen $S_1$ und $S_2$. An dieser Stelle tritt sehr ähnlich zu Needleman-Wunsch eine von drei Situationen auf: Die ersten beiden Möglichkeiten sind, dass wir die \emph{Stelle} $(1,i)$ oder die \emph{Stelle} $(2,j)$ nicht zu unserem \emph{Alignment} hinzufügen. Oder aber wir wählen ein \emph{Fragment} $f_{i,j,l}$ aus, das in $(i,j)$ endet. In diesem Fall wählen wir genau das aus, welches den \emph{Score} aller in $(i,j)$ endenden \emph{Alignments} maximiert. Welcher der drei Fälle der richtige ist, um den höchstmöglichen \emph{Score} bis $(i,j)$ zu berechen, erfahren wir, indem wir das Maximum über sie berechnen.

\begin{equation}\label{eq:dp_score2}
	Sc[i,j] = \max
	\begin{cases}
		Sc[i-1,j], \\
		Sc[i,j-1], \\
		\max_{l\geq 1}\{Sc[i\!-\!l,j\!-\!l] + w^*(f_{i,j,l})\}
	\end{cases}
\end{equation}

\begin{satz}
	Mit der obigen Rekursionsgleichung lässt sich ein optimales paarweises \emph{Alignment} zweier Sequenzen mit Längen $L_1$ und $L_2$ in $\oh(L^3)$ Zeit und $\oh(L^2)$ Speicherplatz berechnen für $L = \max(L_1, L_2)$. Außerdem gilt für die Menge der möglichen Fragmente $F: |F| \in \oh(L^3)$.
\end{satz}
	
\begin{beweis}
	Insgesamt müssen wir $L_1 \cdot L_2 \in \oh(L^2)$-viele Tabelleneinträge berechnen, die wir im Allgemeinen auch gleichzeitig im Speicher vorhalten. Für jeden zu berechnenden Eintrag $Sc[i,j]$ brauchen wir Zugriffe auf $(\min(i,j) + 2)$-viele Einträge in der Matrix und müssen $\min(i,j)$ Gewichte neu berechnen. Dabei dominiert die Berechnung der Gewichte, wobei jedes Gewicht nur genau einmal berechnet werden muss (für den Score des Tabelleneintrags, in dem das \emph{Fragment} endet). Im schlimmsten Fall gilt $L_1 = L_2$. Dann gibt es \emph{Fragmente} der Länge 1 mit jeweils $L$ möglichen Endpunkten in $S_1$ und $S_2$, der Länge zwei mit jeweils $L-1$ möglichen Endpunkten und so weiter. Die Anzahl aller \emph{Fragmente} $|F| = \sum_{k=0}^{L-1}(L-k)^2 = \frac{1}{6} \cdot L(2L^2+3L+1) \in \oh(L^3)$ und die naiv berechnete Anzahl der Zugriffe ist $\sum_{k=0}^{L-1}(L-k)^2\cdot k = \frac{1}{12} \cdot (L-1)L^2(L+1) \in \oh(L^4)$. Glücklicherweise kann man das Gewicht jedes Fragments $f_{i,j,l}$ in $\oh(1)$ Zeit aus $f_{i,j,l-1}$ berechnen, denn $w^*(f_{i,j,l}) = w^*(f_{i,j,l-1}) + M[i\!-\!l\!+\!1, j\!-\!l\!+\!1]$, wodurch sich die Laufzeit auf $\oh(L^3)$ verkleinern lässt.
\end{beweis}

Um nicht nur den \emph{Score} eines perfekten paarweisen \emph{Alignments} berechenen zu können, sondern auch dieses \emph{Alignment} selbst, müssen wir zunächst noch einige Definitionen einführen. Zunächst definieren wir für ein \emph{Fragment} $f \in F$ das \emph{Präfixgewicht} $W(f)$, das die maximale Summe der Gewichte einer Kette von \emph{Fragmenten} bezeichnet, die mit $f$ endet.

\begin{equation}
	W(f) \coloneqq \max \left\{ \sum_{k=0}^{M} w^*(f_k) : f_1 \ll \dots \ll f_M=f \right\}
\end{equation}

\begin{definition}[Vorgänger]
	Sei $f_1 \ll \dots \ll f_M$ eine Kette von \emph{Fragmente}, die das Maximum der vorherigen Gleichung erreicht. Dann bezeichnen wir $P(f) = f_{M-1}$ als den \emph{Vorgänger} von $f$. Außerdem sei $Pr[i,j]$ das letzte \emph{Fragment} einer optimalen Kette, die spätestens in $(i,j)$ endet. 
\end{definition}

Jetzt können wir für ein \emph{Fragment} $f \in F$, das in $(i,j)$ startet, das \emph{Gesamtgewicht} und den \emph{Vorgänger} genau definieren. Das \emph{Präfixgewicht} ist genau das Gewicht von $f$ addiert mit dem \emph{Score} der \emph{Fragmente}, die vor $f$ stehen. $P(f)$ und $Pr[i,j]$ sind zwar strenggenommen nicht wohldefiniert und es könnte mehrere \emph{Fragmente} mit diesen Eigenschaften geben. Wie auch schon in \cite{mdw96} wählen wir dann das in den Sequenzen am weitesten rechts stehende aus.

\begin{equation}\label{eq:praefixgewicht}
	W(f) = Sc[i\!-\!1,j\!-\!1]+w^*(f)
\end{equation}

Der \emph{Vorgänger} von $f$ ist das letzte Element einer Kette von \emph{Fragmente}, die vor $f$ enden.

\begin{equation}\label{eq:vorgaenger}
	P(f) = Pr[i\!-\!1,j\!-\!1]
\end{equation}

Damit können wir jetzt \eqref{eq:dp_score2} mit unseren neuen Definitionen umformulieren, denn der dritte Fall der obigen Gleichung ist genau das maximale \emph{Präfixgewicht} eines \emph{Fragments}, das in $(i,j)$ endet.

\begin{equation}\label{eq:praefixgewicht2}
	Sc[i,j] = \max
		\begin{cases}
		Sc[i\!-\!1,j], \\
		Sc[i,j\!-\!1], \\
		\max{W(f): f\: \text{endet in}\: (i,j)}
	\end{cases}	
\end{equation}

Analog zu den Fällen von $W(f)$ können wir jetzt auch $Pr[i,j]$ setzen. Das letzte \emph{Fragment} einer optimalen Kette bis $(i,j)$ ist das selbe wie bei $(i-1,j)$ beziehungsweise $(i,j-1)$, wenn diese in keinem dieser beiden Stellenpaare endet. Endet sie hingegen in $(i,j)$, dann ist das gesuchte \emph{Fragment} das, welches das \emph{Präfixgewicht} aller in $(i,j)$ endenden \emph{Fragmente} maximiert.

\begin{equation}\label{eq:vorgaenger2}
	Pr[i,j] =
		\begin{cases}
			Sc[i-1,j], & \text{if}\: Sc[i,j] = Sc[i\!-\!1,j]\\
			Sc[i,j-1], & \text{if}\: Sc[i,j] = Sc[i,j\!-\!1]\\
			\hat{f},   & \text{if}\: Sc[i,j] = \max{\{W(f) : f\: \text{endet in}\: (i,j)\}}
		\end{cases}	
\end{equation}

Hier gilt $\hat{f} = argmax\{W(f) : f\: \text{endet in}\: (i,j) \}$. Jetzt stehen uns alle Informationen zur Verfügung, um neben dem \emph{Score} einer optimalen Kette von \emph{Fragmenten} auch diese selbst zu berechnen. Zunächst sei $f_{\max} = argmax_{f\in F}(W(f))$ das letzte Element dieser Kette. Man erhält es, indem man sich das letzte Element einer optimalen Kette anguckt, die bis ganz ans Ende von $S_1$ und $S_2$ reichen kann: $f_{\max} = Pr[L_1,L_2]$. Mit einem Backtrackingalgorithmus sind wir nun in der Lage das optimale paarweise \emph{Alignment} zu berechnen, indem wir mit $f_{\max}$ starten und immer den direkten \emph{Vorgänger} des aktuellen \emph{Fragments} auswählen.

\begin{equation}\label{eq:backtracking}
	f_0 = f_{\max}\: \text{und}\: f_{k+1} = P(f_k)
\end{equation} 

\subsection{Speichereffiziente Berechnung der paarweisen \emph{Alignments}}

In diesem Abschnitt beschäftigen wir uns mit einer sehr speichereffizienten und schnellen Implementierung des soeben gesehenen Ansatzes. Zunächst beschränken wir die maximale Länge eines \emph{Fragments} $l_{\max}$ auf eine kleine, feste Zahl, beispielsweise 40. Je nach gewünschter Genauigkeit und benötigter Geschwindigkeit kann man diesen Wert vergrößern oder verkleinern. Auch wenn diese Einschränkung den maximal zu erreichenden \emph{Score} senkt und wir daher keine perfekten \emph{Alignments} mehr berechnen, hat $l_{\max}$ in der Praxis kaum einen Einfluss auf die Güte der Ergebnisse. Das liegt daran, dass wir im Fall von geringen Ähnlichkeiten zwischen Sequenzen nur selten \emph{Fragmente} mit Längen haben, die $l_\{max\}$ überschreiten und im Fall von sehr ähnlichen Sequenzen können wir lange \emph{Fragmente} auch in mehrere kleinere in der Größenordnung unserer Begrenzung aufteilen. Wir werden zeigen, dass mit dieser Einschränkung ein paarweises \emph{Alignment} in $\oh(L^2)$ Zeit und $\oh(L+N_{\max})$ Speicherplatz berechnet werden kann, wobei $N_{\max}$ die Anzahl an gleichzeitig gespeicherten \emph{Fragmenten} ist \citep{m02}, die durch $|F|$ begrenzt wird.

Wir gehen unsere \emph{Score}matrix Spalte für Spalte von links nach rechts durch. An jeder Position $(i,j)$ berechnen wir mit \ref{eq:praefixgewicht} und \ref{eq:vorgaenger} $W(f)$ und $P(f)$ für alle \emph{Fragmente }$f \in \{f_{i+k,j+k,k} : 1 \leq k \leq l_{\max}\}$, die an der Stelle $(i,j)$ beginnen. Dabei speichern wir Pointer auf $W(f)$ und $P(f)$ in den Listen $F_{j+k}$, die mit der Spalte $j+k$ assoziiert werden in denen die jeweiligen \emph{Fragmente enden}. Alles was wir dafür an Informationen benötigen sind $Sc[i\!-\!1,j\!-\!1]$ und $Pr[i\!-\!1,j\!-\!1]$. Deshalb müssen wir nicht permanent die ganze Matrix vorhalten, sondern benötigen nur die zuletzt berechnete und die aktuelle Spalte für $Sc$ und $Pr$, also vier eindimensionale Arrays der Länge $L_1$.

Bevor wir zur $(j+1)$-ten Spalte übergehen, berechnen wir alle Einträge von 1 bis $i$ für die $j$-te Spalte. Dazu greifen wir auf die Werte der vorhergehenden Spalte $(j-1)$ und auf die zuvor gespeicherten Listen aller \emph{Fragmente} $F_j$ zu , die in der $j$-ten Spalte enden, wobei wir die Formeln \ref{eq:praefixgewicht2} und \ref{eq:vorgaenger2} benutzen. Man kann sich überlegen, dass für jeden Eintrag $(i,j)$ höchstens $l_{\max} \in \oh(1)$ \emph{Fragmente} gespeichert wurden. Sobald wir mit der Berechnung der $j-ten$ Spalte fertig sind, können wir die Werte von $Pr[i,j-1]$ und $Sc[i,j-1]$ für $1 \leq i \leq L_1$ löschen.

Diesen Vorgang wiederholen wir, bis wir schlussendlich auch alle Werte der letzten, also $L_2$-ten, Spalte berechnet haben. Dann kennen wir mit $Sc[L_1,L_2]$ den \emph{Score} des paarweisen \emph{Alignments} und können mithilfe der Backtrackingprozedur \ref{eq:backtracking} die \emph{Fragmente} aus denen es besteht bestimmen. Dazu brauchen wir die Mengen $F_j$, deren Einträge aber glücklicherweise nicht alle dauerhaft gespeichert werden müssen. Sobald $Sc[i,j]$ und $Pr[i,j]$ für eine Position $i,j)$ berechnet wurden, können wir alle \emph{Fragmente}, die dort enden, löschen, abgesehen von $Pr[i,j]$, für das immer noch in Frage kommt, dass es Teil der optimalen Kette von \emph{Fragmenten} ist. Sollte $Pr[i,j]$ nicht in $(i,j)$ enden, können wir sogar alle Einträge aus $F_j$ löschen, die in Zeile $i$ enden.

\begin{algorithm}
	\caption{Speichereffizientes paarweises DIALIGN}
	\label{alg:speichereffizient}
	\begin{algorithmic}[1]
		
		\Require Zwei Sequenzen $S_1$ und $S_2$ mit den Längen $L_1$ und $L_2$
		\Procedure{pairwiseAlignment}{$S_1$, $S_2$, $l_max$}
		\For{$i \gets 0$}{$L_1$}
			\State $Sc[i,0] \gets 0$
		\EndFor
		\For{$j \gets 1$ \textbf{to} $L_2$}
			\For{$i \gets 1$ \textbf{to} $L_1$}
				\For{$l \gets 1$ \textbf{to} $l_{\max}$}\label{algl:fragmentgewichte}
					\State $W(f_{i+l,j+l,l}) \gets w^*(f_{i+l,j+l,l}) + Sc[i\!-\!1,j\!-\!1]$
					\State $P(f_{i+l,j+l,l}) \gets Pr[i\!-\!1,j\!-\!1]$
					\State $F_{j+l} \gets F_{j+l} \cup {f_{i+l.j+l,l}}$\Comment{{\small Speichere \emph{Fragment} für Spalte in der es endet}}\label{algl:fragmentliste}
				\EndFor
				\State
					$Sc[i,j] = \max
					\begin{cases}
						Sc[i\!-\!1,j], \\
						Sc[i,j\!-\!1], \\
						\max{W(f): f\: \text{endet in}\: (i,j)}
					\end{cases}$\label{algl:praefix}
				\State Setze $Pr[i,j]$ analog zu $Sc[i,j]$
				\State lösche $Sc[i,j\!-\!1]$ und $Pr[i,j\!-\!1]$\Comment{{\small Lösche alte Spalteneinträge}}
				\ForAll{$f_{i,j,k} \in F_j$ mit $f \neq Pr[i,j]$}
					\State lösche $F_{i,j,k}$\Comment{{\small Lösche die, die in keiner opt. Kette in $(i,j)$ enden}}
				\EndFor
			\EndFor
		\EndFor
		\State $f_0 \gets Pr[L_1,L_2]$
		\While{$f_k \neq \textbf{NIL}\:$}\Comment{{\small Backtracking, um \emph{Alignment} zu bestimmen}}
			\State $f_{k+1} \gets P(f_{k})$
			\State $k \gets k+1$
		\EndWhile 
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

Da wir wissen, dass nur \emph{Fragmente} mit positiven Gewichten Teil unseres \emph{Alignments} sein können, sind wir in der Lage die Mengen $F_j$ von gespeicherten \emph{Fragmenten} weiter einzuschränken. Wenn die Teilsumme von Ähnlichkeitswerten bis zu einem bestimmten Punkt negativ, können wir den Durchlauf von \algref{alg:speichereffizient}{algl:fragmentgewichte} sofort abbrechen, weil wir wissen, dass wir ein besseres \emph{Alignment} finden, wenn wir den Teil mit der negativen Summe von Gewichten ignorieren. Außerdem gibt es zwei Situationen bei denen wir die Berechnung der Gewichte für Fragmente zwar nicht abbrechen, aber wissen, dass das aktuell betrachtete Element nicht gespeichert werden muss:

\begin{itemize}
	\item Bei negativem Gewicht. Es kann beispielsweise sein, dass $w(f)$ zwar positiv ist, aber $w^* = w(f)-K < 0$ gilt. Dann kann dieses \emph{Fragment} den Score zwar nicht erhöhen, aber vielleicht ist es Teil eines größeren, das Teil des finalen \emph{Alignments} sein kann.
	\item Wenn das Gewicht kleiner ist, als das größte bisher gefundene eines \emph{Fragments}, das in $(i,j)$ startet. In diesem Fall wissen wir, dass ersteres auf jeden Fall ein besseres \emph{Alignment} liefern würde.
	\item Bei DNA: Wenn das Residuenpaar direkt hinter dem Ende des aktuellen \emph{Fragments} einen positiven Ähnlichkeitswert hat. Das bedeutet, dass dieses auf jeden Fall bessere Ergebnisse liefert und wir das aktuelle nicht speichern müssen. Im Programm können wir dies so umsetzen, dass wir das Fragment $f_{i+l,j+l,l}$ erst dann zu $F_{j+l}$ hinzufügen, wenn wir im nächsten Durchlauf der Schleife \algref{alg:speichereffizient}{algl:fragmentgewichte} keins mit einem größeren Gewicht finden. Auf diese Art und Weise suchen wir quasi nach lokalen Maxima der Fragmentgewichte und speichern nur diese. Bei Proteinsequenzen funktioniert dieses Vorgehen nicht, weil es sein könnte, dass es für eins der beiden Symbole weiter hinten in der jeweils anderen Sequenz einen besseren Partner gibt. In diesem Fall brauchen wir aber das andere 
\end{itemize}

Guckt man sich \algref{alg:speichereffizient}{algl:praefix} genauer an, stellt man fest, dass man gar nicht alle \emph{Fragmente} kennen muss, die in $(i,j)$ enden. Es reicht das zu kennen, welches das \emph{Präfixgewicht} $W(f)$ aller dort endenden Ketten maximiert. Anstatt alle dieser \emph{Fragmente} in $F_j$ zu speichern reicht es zu überprüfen, ob der dritte Fall von \algref{alg:speichereffizient}{algl:praefix} eintritt und erst dann in \algref{alg:speichereffizient}{algl:fragmentliste} zu sichern. Das bedeutet, dass wir keine ganze Liste von \emph{Fragmenten} für jede Stelle unserer Tabelle speichern müssen, sondern nur ein einziges.

Widmen wir uns nun $N_{\max}$, der Anzahl an \emph{Fragmenten}, die maximal gleichzeitig gespeichert werden. Die Anzahl an gesicherten \emph{Fragmenten}, die wir noch nicht für $Sc[i,j]$ betrachtet haben, beträgt $l_{\max} \cdot L_1 \in \oh(L)$, weil wir für jede der nächsten $l_{\max}$ Spalten und dort jede der $L_1$-vielen Zeilen das \emph{Fragment} speichern, das $W(f)$ für alle dort endenden maximiert. Zusätzlich wird die Reihe von \emph{Vorgängern} für jeden aktuellen Spalteneintrag gesichert, indem wir in $Pr[i,j]$ einen Pointer auf das letzte \emph{Fragment} einer optimalen Kette für die Teilsequenzen bis zu den Stellen $i$ und $j$ in den beiden Sequenzen speichern. Dieses wiederum speichert einen Pointer auf seinen eigenen \emph{Vorgänger} und so weiter. Im schlimmsten Fall befinden wir uns in der letzten Spalte der Tabelle und die in den Einträgen endenden optimalen Ketten sind alle unabhängig voneinander. Dann kann es sein, dass diese jeweils aus $\oh(L_2)$ nah aufeinanderfolgenden \emph{Fragmenten} der Länge $\oh(1)$ bestehen. In diesem Fall ist $N_{\max} \in \oh(L^2)$, genau wir der insgesamt benötigte Speicherplatz. In der Praxis kann man aber erwarten, dass $N_{\max}$ deutlich kleiner ist. 

\cite{m02} hat sein Verfahren mit verschiedenen Sequenzen getestet. Dabei hat er festgestellt, dass $N_{\max}$ für unabhängige zufällig erstelle Sequenzen im Vergleich zur Größe $L$ zu vernachlässigen ist. Und selbst wenn sehr ähnliche Sequenzen miteinander aligniert wurden, befand sich $N_{\max}$ in der Größenordnung von $L \cdot l_{\max}$. So gesehen bietet dieser Ansatz einen großen Vorteil gegenüber der naiven Umsetzung der Rekursionsformel für paarweise \emph{Alignments}.

\subsection{Laufzeit}

\begin{satz}
	Ein paarweises optimales \emph{Alignment} zwischen zwei Sequenzen $S_1$ und $S_2$ mit Längen $L_1$ und $L_2$, gegeben eine maximale Fragmentlänge $l_{\max}$, lässt sich in $\oh(L^2)$ Zeit berechnen für $L = \max\{L_1, L_2\}$.
\end{satz}

\begin{beweis}
	Das Allokieren des Speicherplatzes für die vier Tabellenspalten (je zwei für $Sc[i,j]$ und $Pr[i,j]$) und das initialisieren der ersten Spalten benötigt $\oh(L)$ Zeit. Das Berechnen \emph{Vorgänger} und \emph{Präfixgewichte}, sowie das Speichern in $F_{j'}$, der in $(i,j)$ startenden \emph{Fragmente} benötigt jeweils $\oh(1)$ Zeit, da ihre Länge durch $l_{\max}$ beschränkt ist. $Sc[i,j]$ und $Pr[i,j]$ lassen sich auch in konstanter Zeit berechnen, da wir nur das Maximum von drei Werten bestimmen müssen. Sollte nicht das \emph{Fragment} gewählt werden, welches das \emph{Präfixgewicht} aller in $(i,j)$ endenden \emph{Fragmente} maximiert, löschen wir diesen einzelnen Eintrag in $\oh(1)$ Zeit. Dies wird für jeden möglichen der $L_1 \cdot L_2 \in \oh(L^2)$ Tabelleneinträge berechnet, was auch die Laufzeit der geschachtelten \emph{for}-Schleifen ist.
	Der Backtrackingprozess zur Berechnung des optimalen \emph{Alignments} ist in $\oh(L)$ Zeit möglich, da wir lediglich der Pointerkette von \emph{Vorgänger} zu \emph{Vorgänger} folgen müssen, bis wir am Anfang der Sequenzen angelangt sind.
	Es folgt die behauptete Laufzeit von $\oh(L^2)$.
\end{beweis}

Da wir \emph{Alignments} zwischen allen ${n}\choose{2}$ $\in \oh(n^2)$-vielen Paaren mit jeweils $\oh(L^2)$ Laufzeit berechnen müssen, kommen wir für die paarweisen \emph{Alignments} insgesamt auf eine Laufzeit von $\oh(n^2\cdot L^2)$

\subsection{Beispiel zur Berechnung paarweiser \emph{Alignments}} 
Um das Verfahren, das diese Bachelorarbeit behandelt, genauer zu verstehen, widmen wir uns jetzt einem Beispiel mit vier DNA-Sequenzen. Zu diesen werden wir im Lauf der Kapitel immer wieder zurückkehren und an ihnen die verschiedenen Schritte unseres Algorithmus der Reihe nach durchführen.
\ttfamily
\begin{enumerate}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
	\item ADGTCTCA
	\item GTCADCTCA
	\item TATCADGG
	\item DGTCADATC
\end{enumerate}
\normalfont
Als erstes berechnen wir nach dem oben beschriebenen Algorithmus ein paarweises \emph{Alignment} zwischen den ersten beiden Sequenzen.

\scriptsize
\begin{tabular}{r|cc|cc|l}
	& \multicolumn{2}{c|}{\multirow{2}{*}{$Sc[i,j]$}} & \multicolumn{2}{c|}{\multirow{2}{*}{$Pr[i,j]$}} & \multicolumn{1}{c}{\texttt{ADGTCTCA}}\\
	& \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{1}{c}{\texttt{\textcolor{red}{G}TCADCTCA}} \\
	\hline \hline
	\diagbox{i}{j} & 0 & 1 & 0 & 1 & Hier beginnende \emph{Fragmente} und Kommentare\\
	\hline
	0 & 0 & 0 & NIL & NIL & \\
	1 & " & " &  "  &  "  & \\
	2 & " & " &  "  &  "  & $F_2[4]=\{f_{4,2,2},W(f)=2,P(f)=\text{NIL}\}$\\
	3 & " & " &  "  &  "  & $F_3[5]=\{f_{5,3,3},W(f)=5,P(f)=\text{NIL}\}$\\
	4 & " & " &  "  &  "  & \\
	5 & " & " &  "  &  "  & \\
	6 & " & " &  "  &  "  & \\
	7 & " & " &  "  &  "  & \\
	8 & " & " &  "  &  "  & 
\end{tabular}

\begin{tabular}{r|cc|cc|l}
	& \multicolumn{2}{c|}{\multirow{2}{*}{$Sc[i,j]$}} & \multicolumn{2}{c|}{\multirow{2}{*}{$Pr[i,j]$}} & \multicolumn{1}{c}{\texttt{ADGTCTCA}}\\
	& \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{1}{c}{\texttt{G\textcolor{red}{T}CADCTCA}} \\
	\hline \hline
	\diagbox{i}{j} & 1 & 2 & 1 & 2 & Hier beginnende \emph{Fragmente} und Kommentare\\
	\hline
	0 & 0 & 0 & NIL & NIL & \\
	1 & " & " &  "  &  "  & \\
	2 & " & " &  "  &  "  & \\
	3 & " & " &  "  &  "  & \\
	4 & " & \textcolor{red}{2} &  "  & \textcolor{red}{$f_{4,2,2}$} & $F_3[5]$ wird nicht aktualisiert, da akt. \emph{Fragment} größeres \emph{Präfixgewicht} hat\\
	5 & " & " &  "  &  "  & \\
	6 & " & " &  "  &  "  & $F_4[8]=\{f_{4,8,3},W(f=5,P(f)=\text{NIL})\}$\\
	7 & " & " &  "  &  "  & \\
	8 & " & " &  "  &  "  & 
\end{tabular}

\begin{tabular}{r|cc|cc|l}
& \multicolumn{2}{c|}{\multirow{2}{*}{$Sc[i,j]$}} & \multicolumn{2}{c|}{\multirow{2}{*}{$Pr[i,j]$}} & \multicolumn{1}{c}{\texttt{ADGTCTCA}}\\
& \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{1}{c}{\texttt{GT\textcolor{red}{C}ADCTCA}} \\
\hline \hline
\diagbox{i}{j} & 2 & 3 & 2 & 3 & Hier beginnende \emph{Fragmente} und Kommentare \\
\hline
0 & 0 & 0 & NIL & NIL & \\
1 & " & " &  "  &  "  & \\
2 & " & " &  "  &  "  & \\
3 & " & " &  "  &  "  & \\
4 & 2 & 2 &  $f_{4,2,2}$  &  $f_{4,2,2}$  & \\
5 & " & \textcolor{red}{5} &  "  &  \textcolor{red}{$f_{5,3,3}$}  & \\
6 & " & " &  "  &  "  & \\
7 & " & " &  "  &  "  & $F_4[8]$ wird nicht aktualisiert\\
8 & " & " &  "  &  "  & 
\end{tabular}

\begin{tabular}{r|cc|cc|l}
	& \multicolumn{2}{c|}{\multirow{2}{*}{$Sc[i,j]$}} & \multicolumn{2}{c|}{\multirow{2}{*}{$Pr[i,j]$}} & \multicolumn{1}{c}{\texttt{ADGTCTCA}}\\
	& \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{1}{c}{\texttt{GTC\textcolor{red}{A}DCTCA}} \\
	\hline \hline
	\diagbox{i}{j} & 3 & 4 & 3 & 4 & Hier beginnende \emph{Fragmente} und Kommentare \\
	\hline
	\multirow{3}{*}{0} & \multirow{3}{*}{0} & \multirow{3}{*}{0} & \multirow{3}{*}{NIL} & \multirow{3}{*}{NIL} & $F_5[2]=\{f_{2,5,2},W(f)=2,P(f)=\text{NIL}\}$,\\ 
	  &   &   &     &     & $F_7[4]=\{f_{4,7,4},W(f)=4,P(f)=\text{NIL}\}$,\\
	  &   &   &     &     & $F_8[5]=\{f_{5,8,5},W(f)=7,P(f)=\text{NIL}\}$ \\
	1 & " & " &  "  &  "  & \\
	2 & " & " &  "  &  "  & \\
	3 & " & " &  "  &  "  & \\
	4 & 2 & 2 &  $f_{4,2,2}$  &  $f_{4,2,2}$  & \\
	5 & 5 & 5 &  $f_{5,3,3}$  &  $f_{5,3,3}$  & \\
	6 & " & " &  "  &  "  & \\
	7 & " & " &  "  &  "  & \\
	8 & " & " &  "  &  "  & $f_{5,3,3}$ statt $f_{8,4,3}$, wähle vorderes \emph{Fragment} bei Gleichstand; lösche $f_{8,4,3}$ aus $F_4[8]$
\end{tabular}

\begin{tabular}{r|cc|cc|l}
	& \multicolumn{2}{c|}{\multirow{2}{*}{$Sc[i,j]$}} & \multicolumn{2}{c|}{\multirow{2}{*}{$Pr[i,j]$}} & \multicolumn{1}{c}{\texttt{ADGTCTCA}}\\
	& \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{1}{c}{\texttt{GTCA\textcolor{red}{D}CTCA}} \\
	\hline \hline
	\diagbox{i}{j} & 4 & 5 & 4 & 5 & Hier beginnende \emph{Fragmente} und Kommentare \\
	\hline
	0 & 0 & 0 & NIL & NIL & \\
	1 & " & " &  "  &  "  & $F_7[4]$ und $F_8[5]$ werden nicht aktualisiert\\
	2 & " & \textcolor{red}{2} &  "  & \textcolor{red}{$f_{2,5,2}$} & \\
	3 & " & " &  "  &  "  & \\
	4 & 2 & " &  $f_{4,2,2}$  &  $f_{4,2,2}$  & \\
	5 & 5 & 5 &  $f_{5,3,3}$  &  $f_{5,3,3}$  & bevorzuge $(i,j-1)$ gegenüber $(i-1,j)$\\
	6 & " & " &  "  &  "  & \\
	7 & " & " &  "  &  "  & \\
	8 & " & " &  "  &  "  & 
\end{tabular}

\begin{tabular}{r|cc|cc|l}
	& \multicolumn{2}{c|}{\multirow{2}{*}{$Sc[i,j]$}} & \multicolumn{2}{c|}{\multirow{2}{*}{$Pr[i,j]$}} & \multicolumn{1}{c}{\texttt{ADGTCTCA}}\\
	& \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{1}{c}{\texttt{GTCAD\textcolor{red}{C}TCA}} \\
	\hline \hline
	\diagbox{i}{j} & 5 & 6 & 5 & 6 & Hier beginnende \emph{Fragmente} und Kommentare \\
	\hline
	0 & 0 & 0 & NIL & NIL & \\
	1 & " & " &  "  &  "  & \\
	2 & 2 & 2 &  $f_{2,5,2}$  &  $f_{2,5,2}$  & \\
	3 & " & " &  "  &  "  & \\
	4 & " & " &  $f_{4,2,2}$  &  $f_{4,2,2}$  & \\
	\multirow{3}{*}{5} & \multirow{3}{*}{5} & \multirow{3}{*}{5} &  \multirow{3}{*}{$f_{5,3,3}$}  & \multirow{3}{*}{$f_{5,3,3}$}  & $F_7[6]=\{f_{6,7,2},W(f)=4,P(f)=f_{4,2,2}\}$, \\
	  &   &   &     &     & $F_8[7]=\{f_{7,8,3},W(f)=7,P(f)=f_{4,2,2}\}$ \\
	  &   &   &     &     & $F_9[8]=\{f_{9,8,4},W(f)=10,P(f)=f_{4,2,2}\}$ \\
	6 & " & " &  "  &  "  & \\
	7 & " & " &  "  &  "  & \\
	8 & " & " &  "  &  "  & 
\end{tabular}

\begin{tabular}{r|cc|cc|l}
	& \multicolumn{2}{c|}{\multirow{2}{*}{$Sc[i,j]$}} & \multicolumn{2}{c|}{\multirow{2}{*}{$Pr[i,j]$}} & \multicolumn{1}{c}{\texttt{ADGTCTCA}}\\
	& \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{1}{c}{\texttt{GTCADC\textcolor{red}{T}CA}} \\
	\hline \hline
	\diagbox{i}{j} & 6 & 7 & 6 & 7 & Hier beginnende \emph{Fragmente} und Kommentare \\
	\hline
	0 & 0 & 0 & NIL & NIL & \\
	1 & " & " &  "  &  "  & \\
	2 & 2 & 2 &  $f_{2,5,2}$  &  $f_{2,5,2}$  & \\
	3 & " & " &  "  &  "  & \\
	4 & 2 & \textcolor{red}{4} &  $f_{4,2,2}$  &  \textcolor{red}{$f_{4,7,4}$} & \\
	5 & 5 & 5 &  $f_{5,3,3}$  &  $f_{5,3,3}$  & $F_8[7]$ und $F_9[8]$ nicht aktualisiert; \emph{Score} erreicht, aber nicht übertroffen\\
	6 & " & " &  "  &  "  & \\
	7 & " & " &  "  &  "  & \\
	8 & " & " &  "  &  "  & 
\end{tabular}

\begin{tabular}{r|cc|cc|l}
	& \multicolumn{2}{c|}{\multirow{2}{*}{$Sc[i,j]$}} & \multicolumn{2}{c|}{\multirow{2}{*}{$Pr[i,j]$}} & \multicolumn{1}{c}{\texttt{ADGTCTCA}}\\
	& \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{1}{c}{\texttt{GTCADCT\textcolor{red}{C}A}} \\
	\hline \hline
	\diagbox{i}{j} & 7 & 8 & 7 & 8 & Hier beginnende \emph{Fragmente} und Kommentare \\
	\hline
	0 & 0 & 0 & NIL & NIL & \\
	1 & " & " &  "  &  "  & \\
	2 & 2 & 2 &  $f_{2,5,2}$  &  $f_{2,5,2}$  & \\
	3 & " & " &  "  &  "  & \\
	4 & 4 & 4 &  $f_{4,7,4}$  &  $f_{4,7,4}$  & \\
	5 & 5 & \textcolor{red}{7} &  $f_{5,3,3}$  &  \textcolor{red}{$f_{5,8,5}$}  & $F_8[7]$ und $F_9[8]$ nicht aktualisiert; \emph{Score} zwar erreicht, aber nicht übertroffen\\
	6 & " & " &  "  &  "  & \\
	7 & " & " &  "  &  "  & lösche $F_8[7]$, $F_9[8]$ wird nicht aktualisiert \\
	8 & " & " &  "  &  "  & 
\end{tabular}
 
\begin{tabular}{r|cc|cc|l}
	& \multicolumn{2}{c|}{\multirow{2}{*}{$Sc[i,j]$}} & \multicolumn{2}{c|}{\multirow{2}{*}{$Pr[i,j]$}} & \multicolumn{1}{c}{\texttt{ADGTCTCA}}\\
	& \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{1}{c}{\texttt{GTCADCTC\textcolor{red}{A}}} \\
	\hline \hline
	\diagbox{i}{j} & 8 & 9 & 8 & 9 & Hier beginnende \emph{Fragmente} und Kommentare \\
	\hline
	0 & 0 & 0 & NIL & NIL & \\
	1 & " & " &  "  &  "  & \\
	2 & 2 & 2 &  $f_{2,5,2}$  &  $f_{2,5,2}$  & \\
	3 & " & " &  "  &  "  & \\
	4 & 4 & 4 &  $f_{4,7,4}$  &  $f_{4,7,4}$  & \\
	5 & 7 & 7 &  $f_{5,8,5}$  &  $f_{5,8,5}$  & \\
	6 & " & " &  "  &  "  & \\
	7 & " & " &  "  &  "  & \\
	8 & " & \textcolor{red}{10} &  "  &  \textcolor{red}{$f_{9,8,4}$} & 
\end{tabular}

\normalsize	
\vspace{8pt}

$f_0 = f_{\max} = Pr[8,9] = f_{9,8,4}$, $f_1 = P(f_0) = f_{4,2,2}$ und zuletzt $f_2 = P(f_1) = \text{NIL}$.
Das paarweise Alignment zwischen \texttt{ADGTCTCA} und \texttt{GTCADCTCA} sieht also wie folgt aus: \\
\vspace{-10pt}
\begin{center}
	\texttt{adGT---CTCA} \\
	\texttt{--GTcadCTCA} 
\end{center}
Hierbei wurden alignierte \emph{Stellen} großgeschrieben und als \emph{Zuweisungsspalten} genau übereinander gereiht.

Dies sind die Ergebnisse der anderen \emph{Alignments}:
\vspace{8pt}

\begin{tabular}{r|c|c||r|c|c}
	Sequenzen & \emph{Alignments} & \emph{Score} & Sequenzen & \emph{Alignments} & \emph{Score}\\
	\hline
	1 & \texttt{adgTCTCA---} & \multirow{2}{*}{10} & 1 & \texttt{aDGTC---TCa} & \multirow{2}{*}{7}\\
	3 & \texttt{---TATCAdgg} & & 4 & \texttt{-DGTCadaTC-} \\
	\hline
	2 & \texttt{-gTCADctca}  & \multirow{2}{*}{8} & 2 & \texttt{-GTCADCTCa} & \multirow{2}{*}{16}\\
	3 & \texttt{taTCADgg--}  & &4 & \texttt{dGTCADATC-} & \\
	\hline
	3 & \texttt{taTCADgg-}   & \multirow{2}{*}{8} & \multicolumn{3}{c}{}     \\
	4 & \texttt{dgTCADatc}   &                    & \multicolumn{3}{c}{} 
\end{tabular}

\section{Überlappgewichte}

Beim multiplen Sequenzalignment werden normalerweise DNA- oder Proteinsequenzen miteinander verglichen bei denen man davon ausgeht, dass sie einen gemeinsamen evolutionären Ursprung haben. Gibt es diesen, dann sind fast ausnahmslos auch gemeinsame Motive erhalten geblieben, die in vielen oder sogar allen Sequenzen vorkommen. Für ein biologisch korrektes \emph{Alignment} ist es notwendig diese zu finden und über möglichst viele Sequenzen hinweg einander zuzuweisen. Hat man erstmal diese verwandten Abschnitte gefunden und miteinander aligniert, werden in der Regel auch die Zuweisungen zwischen diesen sogenannten \emph{Ankerpunkten} besser \citep{mpps06}.

Es ist jedoch nicht immer leicht diese Motive zu finden, weil es sein kann, dass sie im Vergleich zu zufälligen Übereinstimmungen klein sind. Dann bekommen diese nur geringe Gewichte durch unsere Gewichtsfunktion und wenn wir am Ende von DIALIGN	durch gieriges Auswählen der \emph{Fragmente} das multiple \emph{Alignment} bestimmen, kann es sein, dass sie nicht berücksichtigt werden, weil andere höher gewichteten Zuweisungen zu ihnen \emph{inkonsistent} sind. 

Um dieses Problem zu verhindern und Motive zu bevorzugen, die in möglichst vielen Sequenzen vorkommen, führen wir das Konzept der sogenannten \emph{Überlappgewichte} ein \citep{mdw96}. Betrachten wir dazu drei verschiedene Sequenzen $S_1$, $S_2$ und $S_3$ und zwei \emph{Fragmente} $f^{1,2}$ und $f^{2,3}$ zwischen diesen. Dann kann es sein, dass die beiden \emph{Fragmente} eine Überlappung in $S_2$ haben. In diesem Fall ist an dem \emph{Alignment} ein drittes implizites \emph{Fragment} $f^{1,3}$ zwischen $S_1$ und $S_3$ beteiligt, das auf ein gemeinsames Motiv zwischen allen drei Sequenzen hindeutet. Daher ist es angemessen die ursprünglichen \emph{Fragmente} stärker zu gewichten, indem wir zu ihnen das Gewicht der Überlappung addieren.

\begin{equation}
	\tilde{w}(f^{1,2},f^{2,3}) \coloneqq w(f^{1,3})
\end{equation}

Das \emph{Überlappgewicht} eines \emph{Fragments} mit sich selbst und zwischen zwei \emph{Fragmenten}, die sich nicht überschneiden, definieren wir als 0.

Analog definieren wir das \emph{Überlappgewicht} eines einzelnen \emph{Fragments} als sein Gewicht addiert mit der Summe aller \emph{Überlappgewichte} zwischen sich selbst und allen anderen \emph{Fragmenten}:

\begin{equation}
	\hat{w}(f)\coloneqq w^*(f)+\sum_{e \in F}\tilde{w}(f,e)
\end{equation} 

Benutzt man \emph{Überlappgewichte}, muss man jedoch die Zusammensetzung der Sequenzen stärker beachten. Hat man nämlich eine große Subfamilie von sehr ähnlichen Sequenzen, dann werden alle \emph{Fragmente} zwischen einer Sequenz innerhalb und einer Sequenz außerhalb dieser Familie durch hohe \emph{Überlappgewichte} gegenüber denen bevorzugt, die zwischen zwei Sequenzen berechnet wurden, die nicht aus der Sequenzfamilie stammen. \cite{vs93} stellen Methoden vor, die solchen Problemen vorbeugen. 
  
\subsection{Umsetzung im Programm und Laufzeit}

Bei DIALIGN	werden naiv alle \emph{Fragmente} der paarweisen \emph{Alignments} miteinander verglichen und auf Überschneidungen untersucht. Da es in den $\oh(n^2)$ \emph{Alignments} zwischen $n$ Sequenzen jeweils bis zu $\oh(L)$ \emph{Fragmente} gibt, kommt man so auf eine Gesamtlaufzeit von $\oh(n^4\cdot L^2)$ \citep{m99}.

Untersucht man das Problem jedoch genauer, stellt man fest, dass man für ein \emph{Fragment} $f^{k,l}$ gar nicht alle \emph{Fragmente} auf Überlappungen überprüfen muss, sondern nur die, an denen eine der beiden Sequenzen $S_k$ oder $S_l$ unseres \emph{Fragments} beteiligt ist. Außerdem müssen wir nicht jedes \emph{Fragment} eines anderen paarweisen \emph{Alignments} betrachten, sondern wir können in sortierten Fragmentketten durch die Start- und Endpunkte sehr genau abschätzen welche für Überlappungen in Frage kommen.

\begin{satz}
	Für eine Menge $S$ von n Sequenzen und eine Menge $F$ von paarweisen \emph{Fragmenten} zwischen diesen Sequenzen, lassen sich in $\oh(n^3\cdot L)$ Zeit die \emph{Überlappgewichte} berechnen.
\end{satz}


\begin{wraptable}{r}{6cm}
	\begin{tabular}{r|cccc}
		2 & $A_{2,1}$ & & & \\
		3 & $A_{3,1}$ & $A_{3,2}$ & & \\
		$\vdots$ & $\vdots$ & $\vdots$ & $\ddots$ & \\
		n & $A_{n,1}$ & $A_{n,2}$ & $\dots$ & $A_{n,n-1}$ \\
		\hline
		\diagbox[dir=NE]{i}{j} & 1 & 2 & $\dots$ & n-1
	\end{tabular}
	\caption{Jeder Tabelleneintrag $A_{i,j}$ enthält Liste von \emph{Fragmenten}}
\end{wraptable}

\begin{beweis}
	Zwischen den n Sequenzen gibt es ${{n}\choose{2}} \in \oh(n^2)$ paarweise \emph{Alignments}. Wir gehen davon aus, dass der vorherige Schritt unseres Verfahrens diese in einer Tabelle $A$ gespeichert hat, wobei $A_{i,j}$ die \emph{Fragmente} des paarweisen \emph{Alignments} zwischen $S_i$ und $S_j$ in einer sortierten Liste enthält. Das können wie o.B.d.A. annehmen, weil der Algorithmus diese ohnehin in sortierter Reihenfolge berechnet.
	
	Betrachten wir ein \emph{Alignment} zwischen den Sequenzen $S_i$ und $S_k$. Dann müssen wir für die \emph{Überlappgewichte} nur die Einträge $A_{i,k}$ und $A_{l,j}$ mit $1 \leq k,l \leq n$ betrachten, denn es sind nur die \emph{Alignments} relevant, bei denen eine der Sequenzen übereinstimmt. In einer vollständigen Tabelle sind das alle Listen, die in der selben Spalte oder Zeile stehen, also $\oh(n)$ viele.
	
	Seien $A_{i,k}$ und $A_{k,j}$ zwei \emph{Alignments} von denen wir die Überlappgewichte berechnen wollen. Dazu müssen wir die Überlappung zwischen allen \emph{Fragmenten} in $S_k$ bestimmen. Dies können wir in linearer Zeit machen, indem wir parallel über die beiden sortierten Listen traversieren und anhand der Start- und Endpunkte in $S_k$ die impliziten \emph{Fragmente} zwischen $S_i$ und $S_j$ bestimmen, sowie die Gewichte der \emph{Fragmente} aktualisieren. Dafür benötigen wir nur $\oh(L)$ Zeit, weil wir einmalig jedes Element der beiden Listen betrachten, es bis zu $\oh(L)$ \emph{Fragmente} pro \emph{Alignment} gibt und jedes von diesen in der Länge durch $l_{\max} \in \oh(1)$ beschränkt ist.
	Insgesamt haben wir also $\oh(n^2)$ paarweise \emph{Alignments} für die mit jeweils $\oh(n)$ anderen \emph{Alignments} \emph{Überlappgewichte} berechnet werden müssen, was jeweils $\oh(L)$ Zeit kostet. Es folgt die Gesamtlaufzeit von $\oh(n^3\cdot L)$.
\end{beweis}

Genau genommen brauchen wir keine quadratische Tabelle, weil der Eintrag $A_{i,j}$ aus Symmetriegründen identisch zu $A_{j,i}$ ist. Auch die Diagonale können wir uns sparen, denn das alignieren einer Sequenz mit sich selbst ist unnötig. Des Weiteren kann man sich beim obigen Algorithmus noch die Hälfte des Aufwands sparen, denn die \emph{Überlappgewicht} zwischen $A_{i,k}$ und $A_{k,j}$ müssen wir nicht doppelt berechnen, sondern können sie gleich zu den Gewichten in beiden \emph{Alignments} addieren. Obgleich das nichts an der asymptotischen Laufzeit ändert, macht es in der Praxis einen Unterschied. 

\subsection{Beispiel Überlappgewichte}

Widmen wir uns den \emph{Überlappgewichten} an unserem Beispiel und betrachten dazu das \emph{Alignment} zwischen den Sequenzen $S_1$ und $S_3$. Um das Gewicht zu aktualisieren, müssen wir alle \emph{Alignments} auf Überlappungen überprüfen, in denen eine der beiden Sequenzen vorkommt. 

\begin{wraptable}{r}{6cm}
	\begin{tabular}{r|ccc}
		2 & \cellcolor{red} $A_{2,1}$ & & \\
		3 & \cellcolor{yellow} $A_{3,1}$ & \cellcolor{red} $A_{3,2}$ & \\
		4 & \cellcolor{red} $A_{4,1}$ & $A_{4,2}$ & \cellcolor{red} $A_{4,3}$ \\
		\hline
		\diagbox[dir=NE]{i}{j} & 1 & 2 & 3 \\
	\end{tabular}
	\caption{Auf Überlappungen zu überprüfende \emph{Alignments}}
\end{wraptable}

Da unsere Tabelle nicht vollständig ist, reicht es nicht die Einträge der selben Spalte und Zeile zu überprüfen, weil diese unter Umständen nicht vollständig ist. Stattdessen müssen wir alle Einträge in der ersten und dritten Spalte oder Zeile betrachten. Dann gehen wir alle \emph{Fragmente} der Reihe nach durch und gucken anhand der Start- und Endpunkte in der gemeinsamen Sequenz, ob es Überschneidungen gibt. Falls ja, bestimmen wir diese und addieren das Gewicht zu dem unseres \emph{Fragments}.

Zur Erinnerung hier nochmal der bisherige Stand mit den paarweisen \emph{Alignments}:

\begin{tabular}{r|c|c||r|c|c}
	Sequenzen & \emph{Alignments} & \emph{Score} & Sequenzen & \emph{Alignments} & \emph{Score}\\
	\hline
	1 & \texttt{adgTCTCA---} & \multirow{2}{*}{10} & 1 & \texttt{aDGTC---TCa} & \multirow{2}{*}{7}\\
	3 & \texttt{---TATCAdgg} & & 4 & \texttt{-DGTCadaTC-} \\
	\hline
	2 & \texttt{-gTCADctca}  & \multirow{2}{*}{8} & 2 & \texttt{-GTCADCTCa} & \multirow{2}{*}{16}\\
	3 & \texttt{taTCADgg--}  & &4 & \texttt{dGTCADATC-} & \\
	\hline
	3 & \texttt{taTCADgg-}   & \multirow{2}{*}{8} & 1 & \texttt{adGT---CTCA}     \\
	4 & \texttt{dgTCADatc}   &                    & 2 & \texttt{--GTcadCTCA} 
\end{tabular}

Wie wir sehen enthält das von uns betrachtete \emph{Alignment} nur das eine Fragment $f_{8,5,5}$ mit drei Übereinstimmungen und einer Abweichung. Als erstes überprüfen wir die Überlappung mit $A_{2,1}$. Beide haben den gemeinsamen Abschnitt \texttt{CTCA} in $S_1$, woraus sich das neue \emph{Fragment} ${\texttt{CTCA}}\choose{\texttt{ATCA}}$ zwischen $S_2$ und $S_3$ ergibt. Dieses hat drei Übereinstimmungen, eine Abweichung und somit ein Gewicht von 8. In der Folge addieren wir diese Zahl zum Gewicht von $f_{8,5,5}^{1,3}$ und zu dem von $f_{8,9,4}^{1,2}$. Wenn wir diese Anweisungen auch mit und zwischen allen anderen \emph{Alignments} durchführen, kommen wir zu den folgenden \emph{Überlappgewichten}:

\begin{tabular}{r|c|c||r|c|c||r|c|c}
	Seq. & \emph{Frag.} & \emph{Ü-Gew.} & Seq. & \emph{Frag.} & \emph{Ü-Gew.} & Seq. & \emph{Frag.} & \emph{Ü-Gew.}\\
	\hline
	2 & \texttt{GTCADCTC} & \multirow{2}{*}{69} & 1 & \texttt{TCTCA} & \multirow{2}{*}{41} & 1 & \texttt{GT} &\multirow{2}{*}{20} \\
	4 & \texttt{GTCADATC} &                     & 3 & \texttt{TATCA} &                     & 2 & \texttt{GT} & \\
	3 & \texttt{TCAD} & \multirow{2}{*}{47} & 1 & \texttt{CTCA} & \multirow{2}{*}{34} & 1 & \texttt{TC} & \multirow{2}{*}{20} \\
	4 & \texttt{TCAD} &                     & 2 & \texttt{CTCA} &                          & 4 & \texttt{TC} & \\
	3 & \texttt{TCAD} & \multirow{2}{*}{41} & 1 & \texttt{DGTC} & \multirow{2}{*}{31} &    &   & \\
    4 & \texttt{TCAD} &                     & 4 & \texttt{DGTC} &                     &    &   & \\
\end{tabular}

Da wir im nächsten Schritt die \emph{Fragmente} für unser multiples \emph{Alignment} basierend auf ihren Gewichten gierig auswählen, wurden die Abschnitte bereits sortiert. Ein Algorithmus wird als \emph{gierig} bezeichnet, wenn er eine Entscheidung lokal optimal trifft und danach nicht wieder ändert. In unserem Fall bedeutet das, dass die \emph{Fragmente} mit höheren Gewichten früher gewählt werden und wir sie selbst dann nicht wieder aus unserem multiplen \emph{Alignment} entfernen, wenn sie durch \emph{Inkonsistenzen} verhindern, dass andere, zusammen möglicherweise bessere \emph{Fragment} gewählt werden können. Durch diese radikale Vorgehensweise haben gierige Algorithmen oft gute Laufzeiten, liefern aber nicht immer die bestmöglichen Ergebnisse. Zu bekannten Vertretern dieses Paradigmas gehören beispielsweise der Algorithmus von Dijkstra zur Bestimmung der kürzesten Pfade aus einem einzelnen Knoten oder die Algorithmen von Prim und Kruskal zur Bestimmung von minimalen Spannbäumen.

\section{Konsistenz}

Die nach ihrem Gewicht sortierten \emph{Fragmente} möchten wir der Reihe nach in unser multiples \emph{Alignment} einfügen, vorausgesetzt, das gerade gewählte ist nicht \emph{inkonsistent} zu den zuvor integrierten. Wenn wir uns an den Abschnitt über die theoretischen Grundlagen erinnern, dann hatten wir formal definiert, dass eine Relation $\mathcal{R}$ genau dann ein \emph{Alignment} ist, wenn \enquote{$\preceq_{\mathcal{R}}=(\preceq \cup\: \mathcal{R})_t$ die natürliche Ordnung auf jeder Sequenz erhält, also $x \preceq_{\mathcal{R}} y \implies x \preceq y$ für alle $x,y \in S_i \forall 1\leq i \leq n$ gilt.}

Mengentheoretisch können wir uns unser vorgehen so vorstellen, dass wir eine Menge von \emph{Fragmenten} $f_1, \cdot f_k$ haben, die wir der Reihe nach in unser wachsendes multiples \emph{Alignment} hinzufügen wollen, vorausgesetzt sie sind \emph{konsistent} zueinander. Die hinzugefügten \emph{Fragmente} bilden dabei für $i = 2, \dots, k$ eine monoton wachsende Menge $A_1 \subset \dots \subset A_k$:

\begin{equation}
\begin{split}
	\mathcal{A}_1 &= f_1 \\
	\mathcal{A}_i &= 
		\begin{cases}
			(\mathcal{A}_{i-1} \cup f_i) & \text{falls $f_i$ \emph{konsistent} ist zu $A_{i-1}$} \\
			A_{i-1} & sonst 
		\end{cases}
\end{split}
\end{equation} 

Das finale \emph{Alignment} $\mathcal{A}$ ist dann genau das resultierende größte \emph{Alignment} $\mathcal{A}_k$. Die Frage, die man sich natürlich jetzt stellt, lautet: \enquote{Wie kann ich bestimmen, ob ein \emph{Fragment} \emph{konsistent} zu einem \emph{Alignment} ist?} Und noch besser: \enquote{Wie kann ich das effizient bestimmen?}

\begin{definition}[Konsistenzgrenze]
	Gegeben seien ein \emph{Alignment} $\mathcal{A}$ auf einer Menge von Sequenzen $S$ mit Stellenraum $\mathcal{S}$. Dann existiert für eine Stelle $s \in \mathcal{S}$ und eine Sequenz $S_i \in S$ eine kleinste und größte Stelle in $S_i$, die mit $s$ alignierbar ist, ohne zu \emph{Inkonsistenzen} zu führen.
	\begin{equation}
	\begin{split}
	\underline{b}_\mathcal{A}(s,i) &= \min(p: (s,[i,p])\: \text{ist \emph{konsistent} zu} \mathcal{A}) \\
	\overline{b}_\mathcal{A}(s,i) &= \max(p: (s,[i,p])\: \text{ist \emph{konsistent} zu} \mathcal{A})
	\end{split} 
	\end{equation}
	Diese beiden \emph{Stellen} nennen wir die \emph{Konsistenzgrenzen} von $s$ in $S_i$. 
\end{definition}

In der ersten Version von DIALIGN wurden diese Konsistenzgrenzen für alle \emph{Stellen} gespeichert und jedes Mal aktualisiert, wenn eine neue Sequenz zum multiplen \emph{Alignment} hinzugefügt wurde \citep{mdw96}. Das bedeutete benötigten Speicherplatz in der Größenordnung $\theta(n^2\cdot L)$, denn für jede \emph{Stelle} aus jeder Sequenz ($\theta(n\cdot L)$ viele) mussten die \emph{Konsistenzgrenzen} für jede der n Sequenzen gespeichert werden. Noch schlechter ist die Laufzeit bei diesem naiven Ansatz, denn im schlimmsten Fall gibt es $\oh(n^2\cdot L)$ \emph{Fragmente}, die der Reihe nach zum \emph{Alignment} hinzugefügt werden, für die jeweils alle $\theta(n\cdot L)$ \emph{Konsistenzgrenzen} überprüft und gegebenenfalls angepasst werden müssen. Es folgt eine Laufzeit von $\oh(n^4\cdot L^2)$, die auch die Gesamtlaufzeit des DIALIGN-Verfahrens dominiert hat \citep{m99}. 

Weil die Laufzeit im Vergleich zu anderen Verfahren, wie beispielsweise Clustal W, sehr schlecht war, entschied man sich den von \cite{a97} veröffentlichten und in der GABIOS-LIB (\enquote{Greedy Alignment of BIOlogical Sequences LIBrary}) implementierten besseren Ansatz auch in DIALIGN	einzubauen. Wie wir im Folgenden sehen werden, ist es möglich das Problem der \emph{Konsistenzgrenzen} durch den Erhalt der transitiven Hülle eines Graphen abzubilden. Dadurch kann man die \emph{Fragmente} deutlich effizienter der Reihe nach in unser multiples \emph{Alignment} einfügen, wodurch sich die praktische Laufzeit in etwa um den Faktor zehn verbessern ließ \citep{am00}. 

\begin{definition}[Transitivitätsgrenzen]
	Die sogenannten \emph{Transitivitätsgrenzen} erlauben es uns die \emph{Konsistenzgrenzen} als graphtheoretisches Problem zu verstehen. Wir definieren zu unserer \emph{Stelle} $s$ die \emph{Vorgängergrenze} $Pred_{\mathcal{A}}(s,i)$ als die \emph{Stelle} $y$ aus der Sequenz $S_i$, die von allen \emph{Stellen} mit $y \preceq_{\mathcal{A}} s$ am weitesten rechts steht. Analog wird die \emph{Nachfolgergrenze} $Succ_{\mathcal{A}}(s,i)$ als am weitesten links stehende \emph{Stelle} mit $s \preceq_{\mathcal{A}} y$ festgelegt.
	\begin{equation}
	\begin{split}
		Pred_{\mathcal{A}}(s,i) &= \max(p: [i,p] \preceq_{\mathcal{A}} s) \\
		Succ_{\mathcal{A}}(s,i) &= \min(p: s \preceq_{\mathcal{A}} [i,p])
	\end{split}
	\end{equation}
\end{definition}

Zwischen \emph{Transitivitäts-} und \emph{Konsistenzgrenzen} herrscht ein direkter Zusammenhang. Ist unsere \emph{Stelle} $s$ bereits mit einer anderen aus der Sequenz $S_i$ aligniert, dann gibt es zwischen allen vier Grenzen keinen Unterschied.

\begin{equation}
	Pred_{\mathcal{A}}(s,i) = Succ_{\mathcal{A}}(s,i) = \underline{b}_\mathcal{A}(s,i) = \overline{b}_\mathcal{A}(s,i) = p
\end{equation}

Gibt es hingegen keine \emph{Stelle} in $S_i$, die bereits $s$ zugewiesen wurde, dann unterscheiden sich $Pred_{\mathcal{A}}(s,i)$ und $\underline{b}_\mathcal{A}(s,i)$, sowie $Succ_{\mathcal{A}}(s,i)$ und $\overline{b}_\mathcal{A}(s,i)$ jeweils nur um genau eine Position.

\begin{equation}
\begin{split}
	Pred_{\mathcal{A}}(s,i) &= \underline{b}_\mathcal{A}(s,i) - 1\\
	Succ_{\mathcal{A}}(s,i) &= \overline{b}_\mathcal{A}(s,i) + 1
\end{split}
\end{equation}

Man kann also sagen, dass \emph{Transitivitätsgrenzen} und \emph{Konsistenzgrenzen} äquivalent sind, denn wenn man das aktuelle \emph{Alignment} kennt, kann man aus dem einen das jeweils andere bestimmen. Daraus folgt auch, dass man mit beiden darstellen kann, ob zwei \emph{Stellen} miteinander alignierbar sind oder nicht. \improvement{Beispiel hinzufügen?}

\scriptsize
\begin{wrapfigure}{r}{7cm}
	\begin{tikzcd}[/tikz/commutative diagrams/sep=scriptsize]
	& s_1 \arrow[r] & s_2 \arrow[r] & s_3 \arrow[r] & s_4 &  \\
	s'_1 \arrow[r] & s'_2 \arrow[r] & s_3' \arrow[r] & s_4' \arrow[r] & s_5' \arrow[r] & s_6' \\
	s_1'' \arrow[r] & s_2'' \arrow[r] & s_3'' \arrow[r] & s_4'' \arrow[r] & s_5'' & 
	\end{tikzcd}
	\caption{Graph dreier Sequenzen mit den durch sie induzierten Pfaden}
\end{wrapfigure}
\normalsize

In den nächsten beiden Abschnitten zeige ich eine Technik mit der man in konstanter Zeit entscheiden kann, ob zwei \emph{Stellen} miteinander alignierbar sind und einen inkrementellen Algorithmus, der es uns in angemessener Zeit erlaubt ein \emph{Alignment} zwischen zwei \emph{Stellen} in unser multiples \emph{Alignment} hinzuzufügen.

Das wird erreicht, indem wir unseren Stellenraum $\mathcal{S}$ als gerichteten Graph auffassen, in dem die einzelnen \emph{Stellen} Knoten entsprechen und jede Sequenz einen Pfad durch den Graphen darstellt. Jedes mal, wenn eine Zuweisung zwischen zwei \emph{Stellen} ausgewählt wird, fügen wir eine neue Kante zu unserem Graphen hinzu. Ziel ist es in jedem Schritt unseres Verfahrens die transitive Hülle des Graphen zu kennen, denn mit ihr lässt sich entscheiden, ob das \emph{Fragment}, das wir gerade wählen wollen, \emph{konsistent} zum bisherigen \emph{Alignment} ist oder nicht.

\subsection{Berechnung der transitiven Hülle eines gerichteten Graphen}

Sei $G=(V,E)$ ein gerichteter Graph mit einer Menge Knoten $V$ und einer Menge an Kanten $E$ zwischen diesen Knoten. Unter einem Pfad $P$ auf $G$ verstehen wir ein k-Tupel von Knoten $(v_1, \dots, v_k)$, sodass $(v_i, v_{i+1}) \in E \forall 1 \leq i \leq k-1$, also eine Folge von Knoten, die alle direkt durch Kanten miteinander verbunden sind. Dabei nennen wir den Index eines Knotens innerhalb dieses Tupels seine \emph{Position} ($pos(x)$ für $x \in P$).

Die transitive Hülle eines Graphen $G$ ist der Graph $G^*$, in dem es eine Kante $(u,v) \in E^*$ gibt, falls es in $G$ einen Pfad von $u$ nach $v$ gibt. Sollte es $(u,v) \in E^*$ geben, dann nennen wir $u$ den Vorgänger von $v$ und $v$ den Nachfolger von $u$. Diese Vorgänger und Nachfolger sind nicht mit den gleichnamigen Definitionen aus dem Abschnitt über die paarweisen \emph{Alignments} zu verwechseln. Ich habe mich hier an den Begriffen der Quellen orientiert, die den selben Begriff an verschiedenen Stellen verwenden. Da die beiden Bedeutungen des Begriffs aber nur in zueinander disjunkten und klar getrennten Themengebieten vorkommen, hoffe ich hier nicht allzu viel Verwirrung zu stiften. 

Zunächst definieren wir ein paar Variablen für den Kontext dieses Abschnitts: Die Anzahl der Knoten $|V| = \nu$, die der Kanten $|E| = \mu$, die der Kanten in der transitiven Hülle $|E^*| = \mu^*$ und die Anzahl Kanten $\mu_0$, die sich vor dem Hinzufügen von neuen Verbindungen in unserem Graphen befinden. Zuletzt brauchen wir noch $\mu_p$ für die Anzahl der Kanten, über die ein Pfad $P$ traversiert.

Sei im Folgenden eine Menge $\mathcal{P} = \{P_1, \dots, P_k\}$ von Pfaden auf unserem ursprünglichen Graphen gegeben, für die gilt, dass jeder Knoten aus $V$ in genau einem der Pfade vorkommt. Eine solche Menge nennen wir SSDP (\emph{Spanning Set of Disjoint Paths}), also eine Menge von disjunkten Pfaden, die den ganzen Graphen aufspannen. Man kann sich vorstellen, dass man auf unserem Graphen sehr leicht einen solche Menge aufstellen kann, indem man jede einzelne dieser Sequenzen mit ihren Kanten als Pfad dieser Menge auffasst. 

\begin{satz}
	\label{satz:ssdp}
	Es sei ein SSDP mit $k$ disjunkten Pfaden gegeben. Dann lässt sich die transitive Hülle $G^*$ unseres Graphen in $\oh(k^2\cdot(\mu - \mu_0) + \nu \cdot \min\{\nu, (\mu - \mu_p)\})$ Zeit und mit $\oh(k\cdot \nu)$ Speicherplatz erhalten, nachdem Kanten zu ihm hinzugefügt wurden \citep{a97}.
\end{satz}

Für einen Knoten $x$ sei $P(x)$ das Tupel, das in jedem Eintrag $P(x)[i]$ für $1\leq i \leq k$ die Anzahl an Vorgängern von $x$ im Pfad $P_i$ angibt. In anderen Worten ist $P(x)[i]$ die maximale Position eines Vorgängers in $P_i$. Analog definieren wir $S(x)$, wobei  $S(x)[i]$ der minimale Nachfolger von $x$ in $S_i$ ist. Wie man sich denken kann, entsprechen $S(x)$ und $P(x)$ genau unseren \emph{Transitivitätsgrenzen} aus dem Kontext unseres \emph{Alignments} und wir werden diese Begriffe synonym verwenden. Gibt es Vorgänger oder Nachfolger nicht, setzen wir diese Werte auf 0 beziehungsweise die Länge des Pfads, um den es geht, addiert mit eins.

Für Elemente $x$ und $y$ auf zwei Pfaden $P_i$ und $P_j$ kann man sich leicht überlegen, dass aus $pos(x) \leq P(y)[i]$ folgt, dass $(x,y)\in E^*$ gilt. Die gleiche Aussage folgt aus $pos(y) \geq P(x)[j]$. Wie man sieht ist es also möglich die transitive Hülle auf $\oh(k \cdot \nu)$ Speicherplatz zu sichern, wenn man ein SSDP mit k Pfaden hat. Das kann signifikant weniger sein, als die $\oh(\nu^2)$ Kanten, die man im naiven Ansatz speichern muss.

\improvement{Beispiel S(x) und P(x)}

Als nächstes führen wir eine Funktion ein, die die \emph{Transitivitätsgrenzen} nach dem Hinzufügen einer einzelnen Kante aktualisiert. Wollen wir unseren Graphen um mehr als eine Kante ergänzen, fügen wir sie der Reihe nach hinzu und rufen jedes Mal inkrementell die Funktion auf. Das ist beispielsweise der Fall, wenn wir ein längeres \emph{Fragment} zu unserem \emph{Alignment} hinzufügen. Im Folgenden seien die transitive Hülle und die \emph{Transitivitätsgrenzen} unseres ursprünglichen Graphen gegeben. Sei außerdem $(x,y)$ die Kante, die wir ergänzen.

\scriptsize
\begin{wrapfigure}{r}{6cm}\label{abb:kante}
	\begin{tikzcd}[/tikz/commutative diagrams/sep=scriptsize]
	{} \arrow[rrr] &  &  & y \arrow[r] & \dots \arrow[r] & u \arrow[r] & {} \\
	{} \arrow[rr] &  & x \arrow[rrrr] \arrow[ru, red] &  &  &  & {} \\
	{} \arrow[r] & v \arrow[ru] \arrow[rrrrr] &  &  &  &  & {} \\
	{} \arrow[r] & w \arrow[u] \arrow[rrrrr] &  &  &  &  & {}
	\end{tikzcd}
	\caption{Füge $(x,y)$ ein.}
\end{wrapfigure}
\normalsize

Nun wählen wir einen beliebigen, aber festen Knoten $u \in V$, dessen \emph{Transitivitätsgrenzen} wir aktualisieren. $P(u)$ und $S(u)$ bezeichnen dabei die Grenzen vor und $P(u)'$ und $S(u)'$ die Grenzen nach dem Hinzufügen. Als erstes kann man sich überlegen, dass die \emph{Vorgängergrenze} immer nur wachsen kann, während die \emph{Nachfolgergrenze} höchstens sinkt. Des Weiteren kann sich durch eine Kante von $x$ nach $y$ nur die \emph{Vorgängergrenze} von $u$ in einer Sequenz verändern, wenn $u$ ein Nachfolger von $y$ war und die \emph{Nachfolgergrenze}, wenn es ein Vorgänger von $x$ war. Im ersten Fall, wählt man dann das Maximum der beiden möglichen Werte aus und in letzterem das Minimum.  

Mit diesen zwei Formeln können wir für ein $u \in P_i$ und jeden Pfad $P_j$ die neuen \emph{Transitivitätsgrenzen} von $u$ bestimmen:
\begin{equation}
	P'(u)[j] = \begin{cases}
			\max\{P(u)[j], P(x)[j]\}, & \text{falls $u$ Nachfolger von y war} \\
			P(u)[j], & sonst
		\end{cases}
\end{equation} 

\begin{equation}
	S'(u)[j] = \begin{cases}
			\min\{S(u)[j], S(y)[j]\}, & \text{falls $u$ Vorgänger von x war} \\
			S(u)[j], & sonst
		\end{cases}
\end{equation}

Falls bereits ein Pfad zwischen $x$ und $y$ existiert, wissen wir, dass sich die transitive Hülle nicht verändert und dass wir die \emph{Transitivitätsgrenzen} dementsprechend nicht anpassen müssen. Die obigen Beobachtungen können wir jetzt direkt in einen Algorithmus \textrm{EdgeAddition} münden lassen, indem wir über alle Paarkombinationen von Pfaden iterieren und dabei für jeden in Frage kommenden Knoten im jeweiligen Pfad die obigen Formeln anwenden. Wir wählen dabei die Knoten für die \emph{Nachfolgergrenze} in absteigender und die für die \emph{Vorgängergrenze} in aufsteigender Reihenfolge. Weil wir wissen, dass die \emph{Nachfolgergrenze} immer nur sinken kann und wir die in Frage kommenden Knoten sortiert betrachten, wissen wir, dass der aktuelle Schleifendurchlauf abgebrochen werden kann, wenn die \emph{Nachfolgergrenze} kleiner oder genauso groß ist, wie die von $y$. In diesem Fall würde sie eh nicht mehr aktualisiert werden und wir können uns die Berechnung sparen. Für die \emph{Vorgängergrenzen} gehen wir analog vor. Jetzt haben wir alles Rüstzeug zusammen, um Satz \ref{satz:ssdp} zu beweisen.

\begin{algorithm}
	\caption{EdgeAddition}
	\label{alg:edgeaddition}
	\begin{algorithmic}[1]
		\Require Gerichteter Graph $G$ mit SSDP $P_1, \dots, P_k$
		\Procedure{EdgeAddition}{$x,y$}
			\If{$(x,y) \notin E^*$}
				\NFor{Pfad $P_i$}
					\NFor{Pfad $P_j$}
						\NFor{$u$ in $P_i$ startend von $P(x)[i]$ in absteigender Reihenfolge}
							\If{$S(u)[j] > S(y)[j]$} \label{alg:succ_if}
								\State{$S(u)[j]	\gets S(y)[j]$}\Comment{\small{aktualisiere \emph{Nachfolgergrenze}}}
							\Else
								\State{breche den aktuellen Schleifendurchlauf für $u$ ab}						
							\EndIf
				\NFor{Pfad $P_i$}
					\NFor{Pfad $P_j$}
						\NFor{$u$ in $P_i$ startend von $S(y)[i]$ in aufsteigender Reihenfolge}
							\If{$P(u)[j] < P(x)[j]$} \label{alg:pred_if}
								\State{$P(u)[j]	\gets P(x)[j]$}\Comment{\small{aktualisiere \emph{Vorgängergrenze}}}
							\Else
								\State{breche den aktuellen Schleifendurchlauf für $u$ ab}						
							\EndIf
			\EndIf
		\EndProcedure
	\end{algorithmic}
\end{algorithm}
%\caption{Algorithmus zum Aktualisieren der transitiven Hülle, nachdem eine Kante $(x,y)$ zum Graphen hinzugefügt wurde}

\begin{beweis}
	Im schlimmsten Fall werden die ineinander verschachtelten Schleifen je $\oh(k^2 \cdot (\mu - \mu_0))$-mal durchlaufen. Das ergibt sich aus der Kombination aller $\oh(k^2)$ Paare von Pfaden und dadurch, dass es sein kann, dass nur für die ursprünglichen Kanten $\mu_0$ im Graphen und die sie verbindenden Knoten die if-Bedingungen \ref{alg:succ_if} und \ref{alg:pred_if} nicht erfüllt sind. \unsure{Ist das wirklich der Grund? Denk nochmal drüber nach.}
	
	Wenn wir darüber nachdenken wie oft es wirklich zu einer Aktualisierung der \emph{Transitivitätsgrenzen} kommen kann, stellen wir fest, dass diese je nach Graph möglicherweise viel geringer ist, als oben abgeschätzt. Um Redundanz zu vermeiden betrachten wir hier nur die \emph{Vorgängergrenzen}. Für \emph{Nachfolgergrenzen} gilt aus Symmetriegründen aber genau das selbe. Die einzige Situation, in der ein Knoten $v \in V$ die \emph{Vorgängergrenzen} eines anderen Knotens $u$ verändern kann, ist wenn $v$ ein Vorgänger von $x$, aber kein Vorgänger von $u$ ist, bevor die Kante $(x,y)$ hinzugefügt wird (vgl. \ref{abb:kante}). Gleichzeitig muss gelten, dass $u$ ein Nachfolger von $y$ ist. Das liegt daran, dass die Pfade $\mathcal{P}$ disjunkt sind. Also folgt, dass die \emph{Vorgängergrenzen} von $u$ höchstens $\nu$-mal angepasst werden und es insgesamt nicht mehr als $\nu^2$ Anpassungen gibt. 

	Sei $(w,v)$ eine Kante unseres Graphen, die auf keinem unserer Pfade aus dem SSDP liegt. Diese Kante kann die \emph{Vorgängergrenze} von $u$ in der Methode \textrm{EdgeAddition} nur dann verändern, wenn $v$ ein Vorgänger von $x$ ist, aber kein Vorgänger von $u$, bevor die Kante $(x,y)$ addiert wird. Nach dieser Aktualisierung kann die Kante $(w,v)$ die \emph{Transitivitätsgrenzen} von $u$ nie wieder anpassen. Das bedeutet, dass dies für einen Knoten $u$ höchstens so oft passieren, wie es Kanten gibt, die in keinem Pfad des SSDP liegen. Das sind genau $\oh(\mu - \mu_p)$ und es folgt, dass es insgesamt höchstens $\nu \cdot (\mu - \mu_p)$ solcher Aktualisierungen geben kann.
	
	Da sowohl die Anzahl dieser Knoten, als auch der Kanten im Graph die Anzahl der Aktualisierungen beschränken, kann es nicht zu mehr Aktualisierungen als dem Minimum dieser beiden Werte kommen, also $\oh(\nu \cdot \min\{\nu, \mu - \mu_p\})$. Fasst man alles zusammen, so folgt die behauptete Laufzeit von $\oh(k^2 \cdot (\mu - \mu_0) + \nu \cdot \min\{\nu, \mu - \mu_p\})$.
\end{beweis}

\subsection{Konsistenzgrenzen durch Berechnung der transitiven Hülle}

	Jetzt möchten wir den allgemeinen graphtheoretischen Ansatz auf unser multiples \emph{Alignment} anwenden. 
	
\begin{definition}[Alignmentgraph]
	Zunächst übertragen wir daher unsere Sequenzen $S = \{S_1, \dots, S_n\}$ auf einen Graphen mit SSDP. Hierbei ist jede \emph{Stelle} aus $\mathcal{S}$ ein Knoten und zwischen zwei Knoten $u$ und $v$ gibt es genau dann eine Kante $(u,v) \in E$, wenn die dazugehörigen \emph{Stellen} aus der selben Sequenz kommen und direkt aufeinanderfolgen. Dadurch ergibt sich automatisch unser SSDP mit n Pfaden, denn jede Sequenz liefert genau einen solchen und da jeder Knoten mit genau einer Sequenz assoziiert ist, spannen diese Pfade auch den ganzen Graphen. Den Pfad einer Sequenz $S_i$ bezeichnen wir als $P_i$.
	Jedes Mal, wenn wir in unserem \emph{Alignment} von $S$ zwei \emph{Stellen} $(i,p)$ und $(j,q)$ miteinander alignieren, fügen wir je eine Kante in beide Richtungen zwischen den dazugehörigen Knoten im Graphen ein.
\end{definition}

Gibt es zwischen $u$ und $v$ Pfade in beiden Richtungen ($(u,v)$ und $(v,u) \in E^*$), dann symbolisieren wir dies durch $u \rightleftharpoons^{*} v$. Wir sagen dann, dass $u$ und $v$ miteinander \emph{koinzidieren}. 

\subsection{Laufzeit}
$\oh(n^3*l + n^2*l^2)$

\section{Gieriges multiples Alignment}

\subsection{Laufzeit}
$\oh(n^2*l*log(n^2*l))$

\section{Gesamtkomplexität}
$\oh(n^3*l*log l + n^2*l^2)$

\section{Probleme}
